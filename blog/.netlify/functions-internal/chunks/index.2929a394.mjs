import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead, d as renderComponent } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           *//* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "1-language-by-use-case-models", "text": "1. Language-by-Use Case Models" }, { "depth": 2, "slug": "2-higher-accuracy-enhanced-models", "text": "2. Higher Accuracy Enhanced Models" }, { "depth": 2, "slug": "3-models-tailored-for-your-business", "text": "3. Models Tailored for Your Business" }, { "depth": 2, "slug": "deciding-which-asr-platform-is-best-for-you", "text": "Deciding Which ASR Platform is Best for You" }], "source": `\r
A funny thing happened when Deepgram first decided to use [end-to-end deep learning](https://blog.deepgram.com/deep-learning-speech-recognition/) (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn't have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don't currently offer. Let's take a look at the two types of models that we offer here at Deepgram and what each is good for.\r
\r
## 1\\. Language-by-Use Case Models\r
\r
All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding [the spoken languages we offer](https://deepgram.com/product/languages/). Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech's out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don't need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.\r
\r
<WhitepaperPromo whitepaper="latest"></WhitepaperPromo>\r
\r
\r
\r
## 2\\. Higher Accuracy Enhanced Models\r
\r
We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.\r
\r
## 3\\. Models Tailored for Your Business\r
\r
But what if we don't have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that's the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more "real world" audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we've seen good accuracy improvement with less than 10 hours of audio.\r
\r
## Deciding Which ASR Platform is Best for You\r
\r
There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you'd like to read more the factors that you should consider when shopping for an ASR platform, check out [How to Evaluate an ASR Platform](https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief), or fill out our free [Speech-to-Text Self Assessment](https://deepgram.typeform.com/to/d3zTk2eI). Still have questions? [Contact us](https://deepgram.com/contact-us) to talk through your use case and see which of our models is best for you.\r
`, "html": '<p>A funny thing happened when Deepgram first decided to use <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep learning</a> (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn\u2019t have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don\u2019t currently offer. Let\u2019s take a look at the two types of models that we offer here at Deepgram and what each is good for.</p>\n<h2 id="1-language-by-use-case-models">1. Language-by-Use Case Models</h2>\n<p>All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding <a href="https://deepgram.com/product/languages/">the spoken languages we offer</a>. Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech\u2019s out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don\u2019t need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.</p>\n<WhitepaperPromo whitepaper="latest" />\n<h2 id="2-higher-accuracy-enhanced-models">2. Higher Accuracy Enhanced Models</h2>\n<p>We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.</p>\n<h2 id="3-models-tailored-for-your-business">3. Models Tailored for Your Business</h2>\n<p>But what if we don\u2019t have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that\u2019s the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more \u201Creal world\u201D audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we\u2019ve seen good accuracy improvement with less than 10 hours of audio.</p>\n<h2 id="deciding-which-asr-platform-is-best-for-you">Deciding Which ASR Platform is Best for You</h2>\n<p>There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you\u2019d like to read more the factors that you should consider when shopping for an ASR platform, check out <a href="https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief">How to Evaluate an ASR Platform</a>, or fill out our free <a href="https://deepgram.typeform.com/to/d3zTk2eI">Speech-to-Text Self Assessment</a>. Still have questions? <a href="https://deepgram.com/contact-us">Contact us</a> to talk through your use case and see which of our models is best for you.</p>' };
const frontmatter = { "title": "Which Speech Recognition Model is Best for My Business?", "description": "If youre shopping for automatic speech recognition (ASR), you have options. Learn some of the features that make Deepgram the best choice.", "date": "2022-05-23T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661981408/blog/best-speech-recognition-model-business/which-speech-model-best-for-biz-thumb-554x220%402x.png", "authors": ["keith-lam"], "category": "product-news", "tags": ["deep-learning"], "seo": { "title": "Which Speech Recognition Model is Best for My Business?", "description": "If youre shopping for automatic speech recognition (ASR), you have options. Learn some of the features that make Deepgram the best choice." }, "shorturls": { "share": "https://dpgr.am/4c2774a", "twitter": "https://dpgr.am/ccd2306", "linkedin": "https://dpgr.am/a945e65", "reddit": "https://dpgr.am/83efd1c", "facebook": "https://dpgr.am/ecd2b58" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661981408/blog/best-speech-recognition-model-business/which-speech-model-best-for-biz-thumb-554x220%402x.png" }, "astro": { "headings": [{ "depth": 2, "slug": "1-language-by-use-case-models", "text": "1. Language-by-Use Case Models" }, { "depth": 2, "slug": "2-higher-accuracy-enhanced-models", "text": "2. Higher Accuracy Enhanced Models" }, { "depth": 2, "slug": "3-models-tailored-for-your-business", "text": "3. Models Tailored for Your Business" }, { "depth": 2, "slug": "deciding-which-asr-platform-is-best-for-you", "text": "Deciding Which ASR Platform is Best for You" }], "source": `\r
A funny thing happened when Deepgram first decided to use [end-to-end deep learning](https://blog.deepgram.com/deep-learning-speech-recognition/) (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn't have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don't currently offer. Let's take a look at the two types of models that we offer here at Deepgram and what each is good for.\r
\r
## 1\\. Language-by-Use Case Models\r
\r
All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding [the spoken languages we offer](https://deepgram.com/product/languages/). Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech's out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don't need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.\r
\r
<WhitepaperPromo whitepaper="latest"></WhitepaperPromo>\r
\r
\r
\r
## 2\\. Higher Accuracy Enhanced Models\r
\r
We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.\r
\r
## 3\\. Models Tailored for Your Business\r
\r
But what if we don't have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that's the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more "real world" audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we've seen good accuracy improvement with less than 10 hours of audio.\r
\r
## Deciding Which ASR Platform is Best for You\r
\r
There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you'd like to read more the factors that you should consider when shopping for an ASR platform, check out [How to Evaluate an ASR Platform](https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief), or fill out our free [Speech-to-Text Self Assessment](https://deepgram.typeform.com/to/d3zTk2eI). Still have questions? [Contact us](https://deepgram.com/contact-us) to talk through your use case and see which of our models is best for you.\r
`, "html": '<p>A funny thing happened when Deepgram first decided to use <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep learning</a> (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn\u2019t have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don\u2019t currently offer. Let\u2019s take a look at the two types of models that we offer here at Deepgram and what each is good for.</p>\n<h2 id="1-language-by-use-case-models">1. Language-by-Use Case Models</h2>\n<p>All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding <a href="https://deepgram.com/product/languages/">the spoken languages we offer</a>. Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech\u2019s out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don\u2019t need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.</p>\n<WhitepaperPromo whitepaper="latest" />\n<h2 id="2-higher-accuracy-enhanced-models">2. Higher Accuracy Enhanced Models</h2>\n<p>We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.</p>\n<h2 id="3-models-tailored-for-your-business">3. Models Tailored for Your Business</h2>\n<p>But what if we don\u2019t have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that\u2019s the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more \u201Creal world\u201D audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we\u2019ve seen good accuracy improvement with less than 10 hours of audio.</p>\n<h2 id="deciding-which-asr-platform-is-best-for-you">Deciding Which ASR Platform is Best for You</h2>\n<p>There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you\u2019d like to read more the factors that you should consider when shopping for an ASR platform, check out <a href="https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief">How to Evaluate an ASR Platform</a>, or fill out our free <a href="https://deepgram.typeform.com/to/d3zTk2eI">Speech-to-Text Self Assessment</a>. Still have questions? <a href="https://deepgram.com/contact-us">Contact us</a> to talk through your use case and see which of our models is best for you.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/best-speech-recognition-model-business/index.md" };
function rawContent() {
  return `\r
A funny thing happened when Deepgram first decided to use [end-to-end deep learning](https://blog.deepgram.com/deep-learning-speech-recognition/) (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn't have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don't currently offer. Let's take a look at the two types of models that we offer here at Deepgram and what each is good for.\r
\r
## 1\\. Language-by-Use Case Models\r
\r
All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding [the spoken languages we offer](https://deepgram.com/product/languages/). Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech's out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don't need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.\r
\r
<WhitepaperPromo whitepaper="latest"></WhitepaperPromo>\r
\r
\r
\r
## 2\\. Higher Accuracy Enhanced Models\r
\r
We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.\r
\r
## 3\\. Models Tailored for Your Business\r
\r
But what if we don't have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that's the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more "real world" audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we've seen good accuracy improvement with less than 10 hours of audio.\r
\r
## Deciding Which ASR Platform is Best for You\r
\r
There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you'd like to read more the factors that you should consider when shopping for an ASR platform, check out [How to Evaluate an ASR Platform](https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief), or fill out our free [Speech-to-Text Self Assessment](https://deepgram.typeform.com/to/d3zTk2eI). Still have questions? [Contact us](https://deepgram.com/contact-us) to talk through your use case and see which of our models is best for you.\r
`;
}
function compiledContent() {
  return '<p>A funny thing happened when Deepgram first decided to use <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep learning</a> (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn\u2019t have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don\u2019t currently offer. Let\u2019s take a look at the two types of models that we offer here at Deepgram and what each is good for.</p>\n<h2 id="1-language-by-use-case-models">1. Language-by-Use Case Models</h2>\n<p>All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding <a href="https://deepgram.com/product/languages/">the spoken languages we offer</a>. Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech\u2019s out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don\u2019t need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.</p>\n<WhitepaperPromo whitepaper="latest" />\n<h2 id="2-higher-accuracy-enhanced-models">2. Higher Accuracy Enhanced Models</h2>\n<p>We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.</p>\n<h2 id="3-models-tailored-for-your-business">3. Models Tailored for Your Business</h2>\n<p>But what if we don\u2019t have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that\u2019s the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more \u201Creal world\u201D audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we\u2019ve seen good accuracy improvement with less than 10 hours of audio.</p>\n<h2 id="deciding-which-asr-platform-is-best-for-you">Deciding Which ASR Platform is Best for You</h2>\n<p>There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you\u2019d like to read more the factors that you should consider when shopping for an ASR platform, check out <a href="https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief">How to Evaluate an ASR Platform</a>, or fill out our free <a href="https://deepgram.typeform.com/to/d3zTk2eI">Speech-to-Text Self Assessment</a>. Still have questions? <a href="https://deepgram.com/contact-us">Contact us</a> to talk through your use case and see which of our models is best for you.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/best-speech-recognition-model-business/index.md", "https://blog.deepgram.com/", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>A funny thing happened when Deepgram first decided to use <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep learning</a> (E2EDL) to design our next-generation speech-to-text (STT) solution. We found that this approach was hugely flexible and easier to optimize than traditional STT. We didn’t have to reconnect and optimize multiple models (acoustic, pronunciation, and language) every time we wanted to make a change. And we could retrain and enhance our speech models without starting from scratch. With transfer learning, we could build new speech models faster. This trait of our technology has allowed us to build different base speech models for different use cases and needs. It also allows us to tailor models in cases where a customer needs something specific that we don’t currently offer. Let’s take a look at the two types of models that we offer here at Deepgram and what each is good for.</p>
<h2 id="1-language-by-use-case-models">1. Language-by-Use Case Models</h2>
<p>All of our use case-specific models are available in various English dialects. We are expanding into different language-by-use case combinations as we continue to train and optimize our speech models for specific circumstances, such as call centers or meeting transcription, as well as expanding <a href="https://deepgram.com/product/languages/">the spoken languages we offer</a>. Our customers have found that combining a spoken language and use case to create a speech model that works specifically for their needs is more accurate than Big Tech’s out-of-the-box, one-size-fits-none models. These targeted models have the fastest speed and are optimized for the best scalability. Our models can transcribe one hour of pre-recorded audio in 30 seconds. These models are great for all applications, especially ones that need very high speeds or cost savings for on-prem use. You also don’t need to trade off speed or scalability for high accuracy and because we have multiple models for different use cases-unlike Big Tech-our models tend to be more accurate as well.</p>
${renderComponent($$result, "WhitepaperPromo", WhitepaperPromo, { "whitepaper": "latest" })}
<h2 id="2-higher-accuracy-enhanced-models">2. Higher Accuracy Enhanced Models</h2>
<p>We also built our next-generation architecture with the highest English language accuracy on long-tail words or words that are not as common in regular conversations. This new architecture was rebuilt from our current architecture to optimize accuracy on more words.  This new enhanced speech model architecture is best suited where you have keywords and terms that you must get correct but are not in normal conversations; like fiduciary, biodiversity, formulae. Some use cases can be Conversational AI for B2B, technical support contact centers, or technical meetings or seminars.</p>
<h2 id="3-models-tailored-for-your-business">3. Models Tailored for Your Business</h2>
<p>But what if we don’t have a use case model specifically for your needs? Maybe your audio has a lot of background noise, accents, jargon, or product and company names; all of this can sometimes create problems for off-the-shelf models. If that’s the case for you, here at Deepgram we can customize a model for your specific use case. These tailored models can be trained and deployed within weeks and are specifically targeted to address the characteristics of your use case that might make it hard for an off-the-shelf model. To make sure that the tailored model really does address your specific issues, the data for training these models requires audio from your specific business. The more “real world” audio from your business, the better the accuracy. Having an employee read off a script or list of terms creates poor data vs. recording your employee and customer having a conversation. Although we like to say that the more real-world audio you can provide, the better, we’ve seen good accuracy improvement with less than 10 hours of audio.</p>
<h2 id="deciding-which-asr-platform-is-best-for-you">Deciding Which ASR Platform is Best for You</h2>
<p>There are obviously a lot of factors that go into deciding which ASR system will work best for you, beyond the ability to tailor models. If you’d like to read more the factors that you should consider when shopping for an ASR platform, check out <a href="https://offers.deepgram.com/how-to-evaluate-deep-learning-asr-platform-solution-brief">How to Evaluate an ASR Platform</a>, or fill out our free <a href="https://deepgram.typeform.com/to/d3zTk2eI">Speech-to-Text Self Assessment</a>. Still have questions? <a href="https://deepgram.com/contact-us">Contact us</a> to talk through your use case and see which of our models is best for you.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/best-speech-recognition-model-business/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
