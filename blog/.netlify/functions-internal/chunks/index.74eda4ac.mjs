import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           */import '@storyblok/js';
/* empty css                          *//* empty css                              */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import 'camelcase';
/* empty css                              */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "the-project", "text": "The Project" }], "source": `\r
The team behind ARTiculate wanted to increase access to artistic expression for people who can't use traditional input devices. I sat down with [Dan Gooding](https://github.com/DanGooding), [Max McGuinness](https://github.com/mgm52), [Tatiana Sedelnikov](https://github.com/tatiana-s), and [Yi Chen Hock](https://github.com/yichenhock) to ask them about their project.\r
\r
Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.\r
\r
The team explained, "It was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address."\r
\r
Yi Chen found [a paper from researchers at the University of Washington detailing VoiceDraw](https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf) - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.\r
\r
## The Project\r
\r
ARTiculate introduces a hands-free drawing experience. Commands like "bold," "down," and "go" control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, "shortcuts" to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.\r
\r
![A browser showing a white canvas with a GitHub mascot drawn.](https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg)\r
\r
Thanks to Deepgram's Speech Recognition API and our [documentation](https://developers.deepgram.com/documentation/), the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our [search](https://developers.deepgram.com/documentation/features/search/) feature to find command words.\r
\r
The canvas was built with [P5.js](https://p5js.org), a library for creative coding in JavaScript. We just finished publishing a [three-part series on using P5.js](https://blog.deepgram.com/p5js-getting-started/) earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.\r
\r
The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.\r
\r
You can try ARTiculate by visiting [art-iculate.netlify.app](https://art-iculate.netlify.app).\r
\r
        `, "html": '<p>The team behind ARTiculate wanted to increase access to artistic expression for people who can\u2019t use traditional input devices. I sat down with <a href="https://github.com/DanGooding">Dan Gooding</a>, <a href="https://github.com/mgm52">Max McGuinness</a>, <a href="https://github.com/tatiana-s">Tatiana Sedelnikov</a>, and <a href="https://github.com/yichenhock">Yi Chen Hock</a> to ask them about their project.</p>\n<p>Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.</p>\n<p>The team explained, \u201CIt was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address.\u201D</p>\n<p>Yi Chen found <a href="https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf">a paper from researchers at the University of Washington detailing VoiceDraw</a> - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.</p>\n<h2 id="the-project">The Project</h2>\n<p>ARTiculate introduces a hands-free drawing experience. Commands like \u201Cbold,\u201D \u201Cdown,\u201D and \u201Cgo\u201D control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, \u201Cshortcuts\u201D to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg" alt="A browser showing a white canvas with a GitHub mascot drawn."></p>\n<p>Thanks to Deepgram\u2019s Speech Recognition API and our <a href="https://developers.deepgram.com/documentation/">documentation</a>, the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our <a href="https://developers.deepgram.com/documentation/features/search/">search</a> feature to find command words.</p>\n<p>The canvas was built with <a href="https://p5js.org">P5.js</a>, a library for creative coding in JavaScript. We just finished publishing a <a href="https://blog.deepgram.com/p5js-getting-started/">three-part series on using P5.js</a> earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.</p>\n<p>The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.</p>\n<p>You can try ARTiculate by visiting <a href="https://art-iculate.netlify.app">art-iculate.netlify.app</a>.</p>' };
const frontmatter = { "title": "Use Your Voice to Draw with ARTiculate", "description": "The team behind ARTiculate created a React and P5.js application for voice-based drawing to increase access to creative expression. Learn more here.", "date": "2022-03-24T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1646222951/blog/2022/03/draw-with-your-voice-articulate/cover.jpg", "authors": ["kevin-lewis"], "category": "project-showcase", "tags": ["hackathon", "accessibility"], "seo": { "title": "Use Your Voice to Draw with ARTiculate", "description": "The team behind ARTiculate created a React and P5.js application for voice-based drawing to increase access to creative expression. Learn more here." }, "shorturls": { "share": "https://dpgr.am/10d75a8", "twitter": "https://dpgr.am/934ac77", "linkedin": "https://dpgr.am/a928f85", "reddit": "https://dpgr.am/e27577b", "facebook": "https://dpgr.am/8e02298" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454024/blog/draw-with-your-voice-articulate/ograph.png" }, "astro": { "headings": [{ "depth": 2, "slug": "the-project", "text": "The Project" }], "source": `\r
The team behind ARTiculate wanted to increase access to artistic expression for people who can't use traditional input devices. I sat down with [Dan Gooding](https://github.com/DanGooding), [Max McGuinness](https://github.com/mgm52), [Tatiana Sedelnikov](https://github.com/tatiana-s), and [Yi Chen Hock](https://github.com/yichenhock) to ask them about their project.\r
\r
Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.\r
\r
The team explained, "It was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address."\r
\r
Yi Chen found [a paper from researchers at the University of Washington detailing VoiceDraw](https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf) - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.\r
\r
## The Project\r
\r
ARTiculate introduces a hands-free drawing experience. Commands like "bold," "down," and "go" control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, "shortcuts" to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.\r
\r
![A browser showing a white canvas with a GitHub mascot drawn.](https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg)\r
\r
Thanks to Deepgram's Speech Recognition API and our [documentation](https://developers.deepgram.com/documentation/), the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our [search](https://developers.deepgram.com/documentation/features/search/) feature to find command words.\r
\r
The canvas was built with [P5.js](https://p5js.org), a library for creative coding in JavaScript. We just finished publishing a [three-part series on using P5.js](https://blog.deepgram.com/p5js-getting-started/) earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.\r
\r
The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.\r
\r
You can try ARTiculate by visiting [art-iculate.netlify.app](https://art-iculate.netlify.app).\r
\r
        `, "html": '<p>The team behind ARTiculate wanted to increase access to artistic expression for people who can\u2019t use traditional input devices. I sat down with <a href="https://github.com/DanGooding">Dan Gooding</a>, <a href="https://github.com/mgm52">Max McGuinness</a>, <a href="https://github.com/tatiana-s">Tatiana Sedelnikov</a>, and <a href="https://github.com/yichenhock">Yi Chen Hock</a> to ask them about their project.</p>\n<p>Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.</p>\n<p>The team explained, \u201CIt was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address.\u201D</p>\n<p>Yi Chen found <a href="https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf">a paper from researchers at the University of Washington detailing VoiceDraw</a> - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.</p>\n<h2 id="the-project">The Project</h2>\n<p>ARTiculate introduces a hands-free drawing experience. Commands like \u201Cbold,\u201D \u201Cdown,\u201D and \u201Cgo\u201D control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, \u201Cshortcuts\u201D to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg" alt="A browser showing a white canvas with a GitHub mascot drawn."></p>\n<p>Thanks to Deepgram\u2019s Speech Recognition API and our <a href="https://developers.deepgram.com/documentation/">documentation</a>, the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our <a href="https://developers.deepgram.com/documentation/features/search/">search</a> feature to find command words.</p>\n<p>The canvas was built with <a href="https://p5js.org">P5.js</a>, a library for creative coding in JavaScript. We just finished publishing a <a href="https://blog.deepgram.com/p5js-getting-started/">three-part series on using P5.js</a> earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.</p>\n<p>The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.</p>\n<p>You can try ARTiculate by visiting <a href="https://art-iculate.netlify.app">art-iculate.netlify.app</a>.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/draw-with-your-voice-articulate/index.md" };
function rawContent() {
  return `\r
The team behind ARTiculate wanted to increase access to artistic expression for people who can't use traditional input devices. I sat down with [Dan Gooding](https://github.com/DanGooding), [Max McGuinness](https://github.com/mgm52), [Tatiana Sedelnikov](https://github.com/tatiana-s), and [Yi Chen Hock](https://github.com/yichenhock) to ask them about their project.\r
\r
Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.\r
\r
The team explained, "It was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address."\r
\r
Yi Chen found [a paper from researchers at the University of Washington detailing VoiceDraw](https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf) - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.\r
\r
## The Project\r
\r
ARTiculate introduces a hands-free drawing experience. Commands like "bold," "down," and "go" control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, "shortcuts" to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.\r
\r
![A browser showing a white canvas with a GitHub mascot drawn.](https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg)\r
\r
Thanks to Deepgram's Speech Recognition API and our [documentation](https://developers.deepgram.com/documentation/), the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our [search](https://developers.deepgram.com/documentation/features/search/) feature to find command words.\r
\r
The canvas was built with [P5.js](https://p5js.org), a library for creative coding in JavaScript. We just finished publishing a [three-part series on using P5.js](https://blog.deepgram.com/p5js-getting-started/) earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.\r
\r
The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.\r
\r
You can try ARTiculate by visiting [art-iculate.netlify.app](https://art-iculate.netlify.app).\r
\r
        `;
}
function compiledContent() {
  return '<p>The team behind ARTiculate wanted to increase access to artistic expression for people who can\u2019t use traditional input devices. I sat down with <a href="https://github.com/DanGooding">Dan Gooding</a>, <a href="https://github.com/mgm52">Max McGuinness</a>, <a href="https://github.com/tatiana-s">Tatiana Sedelnikov</a>, and <a href="https://github.com/yichenhock">Yi Chen Hock</a> to ask them about their project.</p>\n<p>Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.</p>\n<p>The team explained, \u201CIt was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address.\u201D</p>\n<p>Yi Chen found <a href="https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf">a paper from researchers at the University of Washington detailing VoiceDraw</a> - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.</p>\n<h2 id="the-project">The Project</h2>\n<p>ARTiculate introduces a hands-free drawing experience. Commands like \u201Cbold,\u201D \u201Cdown,\u201D and \u201Cgo\u201D control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, \u201Cshortcuts\u201D to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg" alt="A browser showing a white canvas with a GitHub mascot drawn."></p>\n<p>Thanks to Deepgram\u2019s Speech Recognition API and our <a href="https://developers.deepgram.com/documentation/">documentation</a>, the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our <a href="https://developers.deepgram.com/documentation/features/search/">search</a> feature to find command words.</p>\n<p>The canvas was built with <a href="https://p5js.org">P5.js</a>, a library for creative coding in JavaScript. We just finished publishing a <a href="https://blog.deepgram.com/p5js-getting-started/">three-part series on using P5.js</a> earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.</p>\n<p>The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.</p>\n<p>You can try ARTiculate by visiting <a href="https://art-iculate.netlify.app">art-iculate.netlify.app</a>.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/draw-with-your-voice-articulate/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>The team behind ARTiculate wanted to increase access to artistic expression for people who can’t use traditional input devices. I sat down with <a href="https://github.com/DanGooding">Dan Gooding</a>, <a href="https://github.com/mgm52">Max McGuinness</a>, <a href="https://github.com/tatiana-s">Tatiana Sedelnikov</a>, and <a href="https://github.com/yichenhock">Yi Chen Hock</a> to ask them about their project.</p>
<p>Since the pandemic began, drawing games and applications focused on creative expression have taken off as a way of connecting to people. However, these experiences rarely consider users with disabilities or provide a second-class experience.</p>
<p>The team explained, “It was apparent to us that in the domain of speech recognition for accessibility, there are many applications for practical matters like word processing and filling out forms, but far fewer for expressing yourself and creating art. We believe that this is an unfortunate missed opportunity and one we wanted to address.”</p>
<p>Yi Chen found <a href="https://faculty.washington.edu/wobbrock/pubs/assets-07.03.pdf">a paper from researchers at the University of Washington detailing VoiceDraw</a> - a drawing application for people with motor impairments. VoiceDraw uses sounds to control the experience, such as vowels for joysticks. It is complex, powerful, but hard to learn. And, with the inspiration to speak commands to improve the learning curve, ARTiculate was born.</p>
<h2 id="the-project">The Project</h2>
<p>ARTiculate introduces a hands-free drawing experience. Commands like “bold,” “down,” and “go” control the brush. Also baked into the project are making the most of a new input modality, advanced features include voice-controlled color mixing, “shortcuts” to jump between bounded regions of the painting, and a velocity-acceleration mode for the brush.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1646222952/blog/2022/03/draw-with-your-voice-articulate/screenshot.jpg" alt="A browser showing a white canvas with a GitHub mascot drawn."></p>
<p>Thanks to Deepgram’s Speech Recognition API and our <a href="https://developers.deepgram.com/documentation/">documentation</a>, the team got a minimal viable project completed very quickly. Then, they expanded the use of Deepgram to utilize our <a href="https://developers.deepgram.com/documentation/features/search/">search</a> feature to find command words.</p>
<p>The canvas was built with <a href="https://p5js.org">P5.js</a>, a library for creative coding in JavaScript. We just finished publishing a <a href="https://blog.deepgram.com/p5js-getting-started/">three-part series on using P5.js</a> earlier this week. The team also utilized React, enabling team members to work on their own components and easily glue them together into a complete application later. Because the team created a highly-visual application, they focused attention to detail on smaller elements, such as animations.</p>
<p>The team has plenty of extensions planned, including the ability to fluidly pull images from online and insert them into the canvas, and additional accessibility options such as custom voice commands and color-blindness options to assist with color mixing.</p>
<p>You can try ARTiculate by visiting <a href="https://art-iculate.netlify.app">art-iculate.netlify.app</a>.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/draw-with-your-voice-articulate/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
