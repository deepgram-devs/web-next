import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead, d as renderComponent } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
/* empty css                           */import 'axios';
/* empty css                          *//* empty css                           *//* empty css                          *//* empty css                              *//* empty css                              */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           *//* empty css                              */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "the-project", "text": "The Project" }, { "depth": 2, "slug": "command-and-control", "text": "Command and Control" }, { "depth": 2, "slug": "the-hours-tick-by", "text": "The Hours Tick By" }], "source": `\r
Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind St\xEBmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with [Benedek Der](https://www.linkedin.com/in/benedek-d\xE9r-b8b410200/), [Bianca Sandu](https://www.linkedin.com/in/bianca-sandu-89b364202), [Julius Weisser](https://www.linkedin.com/in/julius-weisser-4895a61b8), and [Siddharth Srivastava](http://siddharthsrivastava0501.github.io) to ask them about their project.\r
\r
The team behind St\xEBmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.\r
\r
Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.\r
\r
## The Project\r
\r
Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to [get started with Deepgram's Speech Recognition API in the browser](https://blog.deepgram.com/live-transcription-mic-browser/). While they had to decide which sponsored challenge categories they would incorporate into their project, the team "instantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects" says Sid.\r
\r
After bouncing around ideas, they chose to expand their knowledge from October's event. They landed on what would become St\xEBmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like "chrome, open tab," "chrome, search for recipes," and "chrome, add bookmark."\r
\r
<YouTube id="8w6rmlqOW6o"></YouTube>\r
\r
## Command and Control\r
\r
This use case category is very familiar to us at Deepgram - and we call it "command and control," which allows voice control of systems. Using Deepgram's [keywords](https://developers.deepgram.com/documentation/features/keywords/) and [search](https://developers.deepgram.com/documentation/features/search/) features, along with custom processing, you can build something similar in just a few lines of code.\r
\r
We've seen it used in web applications, as an interface for games, and dedicated devices.\r
\r
## The Hours Tick By\r
\r
As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the St\xEBmm team over several hours and wondering if they'd be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.\r
\r
Once the extension could access a user's microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.\r
\r
The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines [directly on GitHub](https://github.com/siddharthsrivastava0501/hackcambridge-2022).\r
\r
`, "html": '<p>Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind St\xEBmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with <a href="https://www.linkedin.com/in/benedek-d%C3%A9r-b8b410200/">Benedek Der</a>, <a href="https://www.linkedin.com/in/bianca-sandu-89b364202">Bianca Sandu</a>, <a href="https://www.linkedin.com/in/julius-weisser-4895a61b8">Julius Weisser</a>, and <a href="http://siddharthsrivastava0501.github.io">Siddharth Srivastava</a> to ask them about their project.</p>\n<p>The team behind St\xEBmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.</p>\n<p>Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.</p>\n<h2 id="the-project">The Project</h2>\n<p>Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to <a href="https://blog.deepgram.com/live-transcription-mic-browser/">get started with Deepgram\u2019s Speech Recognition API in the browser</a>. While they had to decide which sponsored challenge categories they would incorporate into their project, the team \u201Cinstantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects\u201D says Sid.</p>\n<p>After bouncing around ideas, they chose to expand their knowledge from October\u2019s event. They landed on what would become St\xEBmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like \u201Cchrome, open tab,\u201D \u201Cchrome, search for recipes,\u201D and \u201Cchrome, add bookmark.\u201D</p>\n<YouTube id="8w6rmlqOW6o" />\n<h2 id="command-and-control">Command and Control</h2>\n<p>This use case category is very familiar to us at Deepgram - and we call it \u201Ccommand and control,\u201D which allows voice control of systems. Using Deepgram\u2019s <a href="https://developers.deepgram.com/documentation/features/keywords/">keywords</a> and <a href="https://developers.deepgram.com/documentation/features/search/">search</a> features, along with custom processing, you can build something similar in just a few lines of code.</p>\n<p>We\u2019ve seen it used in web applications, as an interface for games, and dedicated devices.</p>\n<h2 id="the-hours-tick-by">The Hours Tick By</h2>\n<p>As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the St\xEBmm team over several hours and wondering if they\u2019d be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.</p>\n<p>Once the extension could access a user\u2019s microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.</p>\n<p>The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines <a href="https://github.com/siddharthsrivastava0501/hackcambridge-2022">directly on GitHub</a>.</p>' };
const frontmatter = { "title": "Voice Control Your Browser with St\xEBmm", "description": "Leveraging both the Deepgram API & Chrome APIs into a Chrome extension that lets users control the browser hands-free with voice commands. Learn how we did it here.", "date": "2022-03-07T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1646056012/blog/2022/03/voice-control-browser-stemm/stemm.jpg", "authors": ["kevin-lewis"], "category": "project-showcase", "tags": ["nodejs", "hackathon"], "seo": { "title": "Voice Control Your Browser with St\xEBmm", "description": "Leveraging both the Deepgram API & Chrome APIs into a Chrome extension that lets users control the browser hands-free with voice commands. Learn how we did it here." }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454056/blog/voice-control-browser-stemm/ograph.png" }, "shorturls": { "share": "https://dpgr.am/af2c780", "twitter": "https://dpgr.am/7bd62ea", "linkedin": "https://dpgr.am/57dae70", "reddit": "https://dpgr.am/6b556e8", "facebook": "https://dpgr.am/f8fce58" }, "astro": { "headings": [{ "depth": 2, "slug": "the-project", "text": "The Project" }, { "depth": 2, "slug": "command-and-control", "text": "Command and Control" }, { "depth": 2, "slug": "the-hours-tick-by", "text": "The Hours Tick By" }], "source": `\r
Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind St\xEBmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with [Benedek Der](https://www.linkedin.com/in/benedek-d\xE9r-b8b410200/), [Bianca Sandu](https://www.linkedin.com/in/bianca-sandu-89b364202), [Julius Weisser](https://www.linkedin.com/in/julius-weisser-4895a61b8), and [Siddharth Srivastava](http://siddharthsrivastava0501.github.io) to ask them about their project.\r
\r
The team behind St\xEBmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.\r
\r
Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.\r
\r
## The Project\r
\r
Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to [get started with Deepgram's Speech Recognition API in the browser](https://blog.deepgram.com/live-transcription-mic-browser/). While they had to decide which sponsored challenge categories they would incorporate into their project, the team "instantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects" says Sid.\r
\r
After bouncing around ideas, they chose to expand their knowledge from October's event. They landed on what would become St\xEBmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like "chrome, open tab," "chrome, search for recipes," and "chrome, add bookmark."\r
\r
<YouTube id="8w6rmlqOW6o"></YouTube>\r
\r
## Command and Control\r
\r
This use case category is very familiar to us at Deepgram - and we call it "command and control," which allows voice control of systems. Using Deepgram's [keywords](https://developers.deepgram.com/documentation/features/keywords/) and [search](https://developers.deepgram.com/documentation/features/search/) features, along with custom processing, you can build something similar in just a few lines of code.\r
\r
We've seen it used in web applications, as an interface for games, and dedicated devices.\r
\r
## The Hours Tick By\r
\r
As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the St\xEBmm team over several hours and wondering if they'd be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.\r
\r
Once the extension could access a user's microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.\r
\r
The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines [directly on GitHub](https://github.com/siddharthsrivastava0501/hackcambridge-2022).\r
\r
`, "html": '<p>Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind St\xEBmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with <a href="https://www.linkedin.com/in/benedek-d%C3%A9r-b8b410200/">Benedek Der</a>, <a href="https://www.linkedin.com/in/bianca-sandu-89b364202">Bianca Sandu</a>, <a href="https://www.linkedin.com/in/julius-weisser-4895a61b8">Julius Weisser</a>, and <a href="http://siddharthsrivastava0501.github.io">Siddharth Srivastava</a> to ask them about their project.</p>\n<p>The team behind St\xEBmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.</p>\n<p>Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.</p>\n<h2 id="the-project">The Project</h2>\n<p>Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to <a href="https://blog.deepgram.com/live-transcription-mic-browser/">get started with Deepgram\u2019s Speech Recognition API in the browser</a>. While they had to decide which sponsored challenge categories they would incorporate into their project, the team \u201Cinstantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects\u201D says Sid.</p>\n<p>After bouncing around ideas, they chose to expand their knowledge from October\u2019s event. They landed on what would become St\xEBmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like \u201Cchrome, open tab,\u201D \u201Cchrome, search for recipes,\u201D and \u201Cchrome, add bookmark.\u201D</p>\n<YouTube id="8w6rmlqOW6o" />\n<h2 id="command-and-control">Command and Control</h2>\n<p>This use case category is very familiar to us at Deepgram - and we call it \u201Ccommand and control,\u201D which allows voice control of systems. Using Deepgram\u2019s <a href="https://developers.deepgram.com/documentation/features/keywords/">keywords</a> and <a href="https://developers.deepgram.com/documentation/features/search/">search</a> features, along with custom processing, you can build something similar in just a few lines of code.</p>\n<p>We\u2019ve seen it used in web applications, as an interface for games, and dedicated devices.</p>\n<h2 id="the-hours-tick-by">The Hours Tick By</h2>\n<p>As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the St\xEBmm team over several hours and wondering if they\u2019d be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.</p>\n<p>Once the extension could access a user\u2019s microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.</p>\n<p>The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines <a href="https://github.com/siddharthsrivastava0501/hackcambridge-2022">directly on GitHub</a>.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/voice-control-browser-stemm/index.md" };
function rawContent() {
  return `\r
Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind St\xEBmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with [Benedek Der](https://www.linkedin.com/in/benedek-d\xE9r-b8b410200/), [Bianca Sandu](https://www.linkedin.com/in/bianca-sandu-89b364202), [Julius Weisser](https://www.linkedin.com/in/julius-weisser-4895a61b8), and [Siddharth Srivastava](http://siddharthsrivastava0501.github.io) to ask them about their project.\r
\r
The team behind St\xEBmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.\r
\r
Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.\r
\r
## The Project\r
\r
Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to [get started with Deepgram's Speech Recognition API in the browser](https://blog.deepgram.com/live-transcription-mic-browser/). While they had to decide which sponsored challenge categories they would incorporate into their project, the team "instantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects" says Sid.\r
\r
After bouncing around ideas, they chose to expand their knowledge from October's event. They landed on what would become St\xEBmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like "chrome, open tab," "chrome, search for recipes," and "chrome, add bookmark."\r
\r
<YouTube id="8w6rmlqOW6o"></YouTube>\r
\r
## Command and Control\r
\r
This use case category is very familiar to us at Deepgram - and we call it "command and control," which allows voice control of systems. Using Deepgram's [keywords](https://developers.deepgram.com/documentation/features/keywords/) and [search](https://developers.deepgram.com/documentation/features/search/) features, along with custom processing, you can build something similar in just a few lines of code.\r
\r
We've seen it used in web applications, as an interface for games, and dedicated devices.\r
\r
## The Hours Tick By\r
\r
As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the St\xEBmm team over several hours and wondering if they'd be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.\r
\r
Once the extension could access a user's microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.\r
\r
The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines [directly on GitHub](https://github.com/siddharthsrivastava0501/hackcambridge-2022).\r
\r
`;
}
function compiledContent() {
  return '<p>Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind St\xEBmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with <a href="https://www.linkedin.com/in/benedek-d%C3%A9r-b8b410200/">Benedek Der</a>, <a href="https://www.linkedin.com/in/bianca-sandu-89b364202">Bianca Sandu</a>, <a href="https://www.linkedin.com/in/julius-weisser-4895a61b8">Julius Weisser</a>, and <a href="http://siddharthsrivastava0501.github.io">Siddharth Srivastava</a> to ask them about their project.</p>\n<p>The team behind St\xEBmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.</p>\n<p>Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.</p>\n<h2 id="the-project">The Project</h2>\n<p>Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to <a href="https://blog.deepgram.com/live-transcription-mic-browser/">get started with Deepgram\u2019s Speech Recognition API in the browser</a>. While they had to decide which sponsored challenge categories they would incorporate into their project, the team \u201Cinstantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects\u201D says Sid.</p>\n<p>After bouncing around ideas, they chose to expand their knowledge from October\u2019s event. They landed on what would become St\xEBmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like \u201Cchrome, open tab,\u201D \u201Cchrome, search for recipes,\u201D and \u201Cchrome, add bookmark.\u201D</p>\n<YouTube id="8w6rmlqOW6o" />\n<h2 id="command-and-control">Command and Control</h2>\n<p>This use case category is very familiar to us at Deepgram - and we call it \u201Ccommand and control,\u201D which allows voice control of systems. Using Deepgram\u2019s <a href="https://developers.deepgram.com/documentation/features/keywords/">keywords</a> and <a href="https://developers.deepgram.com/documentation/features/search/">search</a> features, along with custom processing, you can build something similar in just a few lines of code.</p>\n<p>We\u2019ve seen it used in web applications, as an interface for games, and dedicated devices.</p>\n<h2 id="the-hours-tick-by">The Hours Tick By</h2>\n<p>As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the St\xEBmm team over several hours and wondering if they\u2019d be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.</p>\n<p>Once the extension could access a user\u2019s microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.</p>\n<p>The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines <a href="https://github.com/siddharthsrivastava0501/hackcambridge-2022">directly on GitHub</a>.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/voice-control-browser-stemm/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>Back in January, we supported Hack Cambridge - a 24-hour student hackathon. The team behind Stëmm wanted to bring voice control to one of the most used applications globally - Google Chrome. I sat down with <a href="https://www.linkedin.com/in/benedek-d%C3%A9r-b8b410200/">Benedek Der</a>, <a href="https://www.linkedin.com/in/bianca-sandu-89b364202">Bianca Sandu</a>, <a href="https://www.linkedin.com/in/julius-weisser-4895a61b8">Julius Weisser</a>, and <a href="http://siddharthsrivastava0501.github.io">Siddharth Srivastava</a> to ask them about their project.</p>
<p>The team behind Stëmm all study Computer Science at the University of Warwick, are friends, and most of them are also flatmates. While Hack Cambridge was their first in-person hackathon, at Hack Duke in October 2021, they built a Chrome extension that identified COVID facts in a webpage.</p>
<p>Most of the team met up a week before Hack Cambridge to start brainstorming ideas, not aware that themes would be announced on the morning. They marched down to the venue, electronics kit in hand, and realized they would need to rethink their game plan as soon as the opening ceremony took place.</p>
<h2 id="the-project">The Project</h2>
<p>Fortunately, some of the team saw our live demo at the event that highlighted how easy it is to <a href="https://blog.deepgram.com/live-transcription-mic-browser/">get started with Deepgram’s Speech Recognition API in the browser</a>. While they had to decide which sponsored challenge categories they would incorporate into their project, the team “instantly recognized the vast potential the Deepgram API gives developers by allowing us to use speech recognition in innovative ways within our projects” says Sid.</p>
<p>After bouncing around ideas, they chose to expand their knowledge from October’s event. They landed on what would become Stëmm - the aim was to build a browser interface for users with motor disabilities. The team leveraged both the Deepgram API and Chrome API into a Chrome extension that, once installed and given microphone permissions, lets users control Chrome hands-free with voice commands like “chrome, open tab,” “chrome, search for recipes,” and “chrome, add bookmark.”</p>
${renderComponent($$result, "YouTube", YouTube, { "id": "8w6rmlqOW6o" })}
<h2 id="command-and-control">Command and Control</h2>
<p>This use case category is very familiar to us at Deepgram - and we call it “command and control,” which allows voice control of systems. Using Deepgram’s <a href="https://developers.deepgram.com/documentation/features/keywords/">keywords</a> and <a href="https://developers.deepgram.com/documentation/features/search/">search</a> features, along with custom processing, you can build something similar in just a few lines of code.</p>
<p>We’ve seen it used in web applications, as an interface for games, and dedicated devices.</p>
<h2 id="the-hours-tick-by">The Hours Tick By</h2>
<p>As you might imagine, Google has a strict set of security provisions for extensions, and during the hackathon this became the main challenge to overcome. I remember having multiple conversations with the Stëmm team over several hours and wondering if they’d be able to overcome the blockers and get their project working, especially given the vague error messages they were battling. Thankfully, they managed to work out the right configuration that allowed their extension to operate.</p>
<p>Once the extension could access a user’s microphone and get transcripts from Deepgram, the result used a language processing algorithm built by Benedek & Bianca to identify the commands in the recorded text, and by integrating these commands with the Chrome developer tools, it executes them to control the browser.</p>
<p>The extension is still somewhat limited in terms of commands, but the team directly welcomes contributions to their project repository to add new features. You can find setup and contribution guidelines <a href="https://github.com/siddharthsrivastava0501/hackcambridge-2022">directly on GitHub</a>.</p>`;
});

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
