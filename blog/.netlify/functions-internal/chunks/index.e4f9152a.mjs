import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead, d as renderComponent } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           */import '@storyblok/js';
/* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import 'camelcase';
import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "what-is-closed-captioning", "text": "What is Closed Captioning?" }, { "depth": 2, "slug": "use-cases-for-speech-to-text-in-closed-captioning", "text": "Use Cases for Speech-to-Text in Closed Captioning" }, { "depth": 3, "slug": "live-events", "text": "Live Events" }, { "depth": 3, "slug": "live-television", "text": "Live Television" }, { "depth": 3, "slug": "education-and-training", "text": "Education and Training" }, { "depth": 3, "slug": "podcasts", "text": "Podcasts" }, { "depth": 2, "slug": "benefits-of-ai-powered-asr-for-closed-captioning", "text": "Benefits of AI-Powered ASR for Closed Captioning" }, { "depth": 3, "slug": "speed", "text": "Speed" }, { "depth": 3, "slug": "accuracy", "text": "Accuracy" }, { "depth": 3, "slug": "automatically-align-audio-and-captions", "text": "Automatically Align Audio and Captions" }, { "depth": 3, "slug": "cost-savings", "text": "Cost Savings" }, { "depth": 2, "slug": "one-problem-with-using-asr-for-closed-captioning", "text": "One Problem with Using ASR for Closed Captioning" }, { "depth": 2, "slug": "wrapping-up", "text": "Wrapping Up" }], "source": `\r
There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we'll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We'll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let's define what exactly closed captioning is.\r
\r
## What is Closed Captioning?\r
\r
Closed captioning is a means of adding a transcript of what is said to video files. It's similar to subtitles, but while subtitles are usually intended for someone who doesn't speak or understand the language used in the video, closed captions are intended for those who might be [deaf or hard of hearing](https://blog.deepgram.com/asr-important-deaf-hoh-community/). However, [Verizon Media](https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?) found that 80% of closed caption users aren't hearing impaired, so this is a feature that's expanding in use. And, in case you're curious-"closed" here means that the captions aren't visible to the viewer until they turn them on.\r
\r
## Use Cases for Speech-to-Text in Closed Captioning\r
\r
It might seem like there's just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.\r
\r
### Live Events\r
\r
Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it's important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.\r
\r
### Live Television\r
\r
Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you've ever tried to watch something live with closed captions turned on, you know that they're often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.\r
\r
### Education and Training\r
\r
Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.\r
\r
### Podcasts\r
\r
Although you might mostly associate captions with video content, they're also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it's one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who'd rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at [Podcast Accessibility](https://podcast-accessibility.com/).\r
\r
<WhitepaperPromo whitepaper="latest"></WhitepaperPromo>\r
\r
## Benefits of AI-Powered ASR for Closed Captioning\r
\r
It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, [end-to-end deep-learning ASR solutions like Deepgram](https://blog.deepgram.com/deep-learning-speech-recognition/) can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let's take a look.\r
\r
### Speed\r
\r
As noted above, if you've ever tried to watch a sporting event in a bar, for example, it's very obvious that the captions are delayed-oftentimes so delayed it's hard to match them up to what's happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what's being said in time.\r
\r
### Accuracy\r
\r
Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with [custom model training](https://deepgram.com/product/custom-training/), you can use audio from your particular domain to further improve a model thanks to [transfer learning](https://blog.deepgram.com/transfer-learning-spanish-portuguese/)-something that's not possible with older speech-to-text systems.\r
\r
### Automatically Align Audio and Captions\r
\r
If you're working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it's much easier to correctly align captions with the audio.\r
\r
### Cost Savings\r
\r
Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.\r
\r
## One Problem with Using ASR for Closed Captioning\r
\r
Before we wrap up, it's worth noting that there's one issue that you can run into if you're trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won't be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what's happening on-screen. In these cases, you'd still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.\r
\r
## Wrapping Up\r
\r
And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you're curious how Deepgram's speech-to-text API can help your captioning use case, [give us a try and get $150 in free credits](https://console.deepgram.com/signup). Have questions? Reach out and we'll be happy to talk through your use case with you and see how we can help.\r
`, "html": '<p>There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we\u2019ll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We\u2019ll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let\u2019s define what exactly closed captioning is.</p>\n<h2 id="what-is-closed-captioning">What is Closed Captioning?</h2>\n<p>Closed captioning is a means of adding a transcript of what is said to video files. It\u2019s similar to subtitles, but while subtitles are usually intended for someone who doesn\u2019t speak or understand the language used in the video, closed captions are intended for those who might be <a href="https://blog.deepgram.com/asr-important-deaf-hoh-community/">deaf or hard of hearing</a>. However, <a href="https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?">Verizon Media</a> found that 80% of closed caption users aren\u2019t hearing impaired, so this is a feature that\u2019s expanding in use. And, in case you\u2019re curious-\u201Dclosed\u201D here means that the captions aren\u2019t visible to the viewer until they turn them on.</p>\n<h2 id="use-cases-for-speech-to-text-in-closed-captioning">Use Cases for Speech-to-Text in Closed Captioning</h2>\n<p>It might seem like there\u2019s just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.</p>\n<h3 id="live-events">Live Events</h3>\n<p>Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it\u2019s important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.</p>\n<h3 id="live-television">Live Television</h3>\n<p>Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you\u2019ve ever tried to watch something live with closed captions turned on, you know that they\u2019re often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.</p>\n<h3 id="education-and-training">Education and Training</h3>\n<p>Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.</p>\n<h3 id="podcasts">Podcasts</h3>\n<p>Although you might mostly associate captions with video content, they\u2019re also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it\u2019s one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who\u2019d rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at <a href="https://podcast-accessibility.com/">Podcast Accessibility</a>.</p>\n<WhitepaperPromo whitepaper="latest" />\n<h2 id="benefits-of-ai-powered-asr-for-closed-captioning">Benefits of AI-Powered ASR for Closed Captioning</h2>\n<p>It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep-learning ASR solutions like Deepgram</a> can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let\u2019s take a look.</p>\n<h3 id="speed">Speed</h3>\n<p>As noted above, if you\u2019ve ever tried to watch a sporting event in a bar, for example, it\u2019s very obvious that the captions are delayed-oftentimes so delayed it\u2019s hard to match them up to what\u2019s happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what\u2019s being said in time.</p>\n<h3 id="accuracy">Accuracy</h3>\n<p>Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with <a href="https://deepgram.com/product/custom-training/">custom model training</a>, you can use audio from your particular domain to further improve a model thanks to <a href="https://blog.deepgram.com/transfer-learning-spanish-portuguese/">transfer learning</a>-something that\u2019s not possible with older speech-to-text systems.</p>\n<h3 id="automatically-align-audio-and-captions">Automatically Align Audio and Captions</h3>\n<p>If you\u2019re working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it\u2019s much easier to correctly align captions with the audio.</p>\n<h3 id="cost-savings">Cost Savings</h3>\n<p>Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.</p>\n<h2 id="one-problem-with-using-asr-for-closed-captioning">One Problem with Using ASR for Closed Captioning</h2>\n<p>Before we wrap up, it\u2019s worth noting that there\u2019s one issue that you can run into if you\u2019re trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won\u2019t be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what\u2019s happening on-screen. In these cases, you\u2019d still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.</p>\n<h2 id="wrapping-up">Wrapping Up</h2>\n<p>And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you\u2019re curious how Deepgram\u2019s speech-to-text API can help your captioning use case, <a href="https://console.deepgram.com/signup">give us a try and get $150 in free credits</a>. Have questions? Reach out and we\u2019ll be happy to talk through your use case with you and see how we can help.</p>' };
const frontmatter = { "title": "How Closed Captioning is Enabled by ASR", "description": "Closed captioning provides accessibility to people who have trouble hearing audio\u2014and with ASR, it\u2019s getting faster and more powerful.", "date": "2022-08-10T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661981430/blog/closed-captioning-companies-use-asr/how-closed-captioning-is-enabled-by-ASR-thumb-554x.png", "authors": ["chris-doty"], "category": "speech-trends", "tags": ["voice-strategy"], "seo": { "title": "How Closed Captioning is Enabled by ASR", "description": "Closed captioning provides accessibility to people who have trouble hearing audio\u2014and with ASR, it\u2019s getting faster and more powerful." }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661981430/blog/closed-captioning-companies-use-asr/how-closed-captioning-is-enabled-by-ASR-thumb-554x.png" }, "shorturls": { "share": "https://dpgr.am/d8cecee", "twitter": "https://dpgr.am/1474e89", "linkedin": "https://dpgr.am/289671c", "reddit": "https://dpgr.am/d2c4efd", "facebook": "https://dpgr.am/3318e59" }, "astro": { "headings": [{ "depth": 2, "slug": "what-is-closed-captioning", "text": "What is Closed Captioning?" }, { "depth": 2, "slug": "use-cases-for-speech-to-text-in-closed-captioning", "text": "Use Cases for Speech-to-Text in Closed Captioning" }, { "depth": 3, "slug": "live-events", "text": "Live Events" }, { "depth": 3, "slug": "live-television", "text": "Live Television" }, { "depth": 3, "slug": "education-and-training", "text": "Education and Training" }, { "depth": 3, "slug": "podcasts", "text": "Podcasts" }, { "depth": 2, "slug": "benefits-of-ai-powered-asr-for-closed-captioning", "text": "Benefits of AI-Powered ASR for Closed Captioning" }, { "depth": 3, "slug": "speed", "text": "Speed" }, { "depth": 3, "slug": "accuracy", "text": "Accuracy" }, { "depth": 3, "slug": "automatically-align-audio-and-captions", "text": "Automatically Align Audio and Captions" }, { "depth": 3, "slug": "cost-savings", "text": "Cost Savings" }, { "depth": 2, "slug": "one-problem-with-using-asr-for-closed-captioning", "text": "One Problem with Using ASR for Closed Captioning" }, { "depth": 2, "slug": "wrapping-up", "text": "Wrapping Up" }], "source": `\r
There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we'll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We'll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let's define what exactly closed captioning is.\r
\r
## What is Closed Captioning?\r
\r
Closed captioning is a means of adding a transcript of what is said to video files. It's similar to subtitles, but while subtitles are usually intended for someone who doesn't speak or understand the language used in the video, closed captions are intended for those who might be [deaf or hard of hearing](https://blog.deepgram.com/asr-important-deaf-hoh-community/). However, [Verizon Media](https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?) found that 80% of closed caption users aren't hearing impaired, so this is a feature that's expanding in use. And, in case you're curious-"closed" here means that the captions aren't visible to the viewer until they turn them on.\r
\r
## Use Cases for Speech-to-Text in Closed Captioning\r
\r
It might seem like there's just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.\r
\r
### Live Events\r
\r
Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it's important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.\r
\r
### Live Television\r
\r
Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you've ever tried to watch something live with closed captions turned on, you know that they're often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.\r
\r
### Education and Training\r
\r
Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.\r
\r
### Podcasts\r
\r
Although you might mostly associate captions with video content, they're also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it's one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who'd rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at [Podcast Accessibility](https://podcast-accessibility.com/).\r
\r
<WhitepaperPromo whitepaper="latest"></WhitepaperPromo>\r
\r
## Benefits of AI-Powered ASR for Closed Captioning\r
\r
It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, [end-to-end deep-learning ASR solutions like Deepgram](https://blog.deepgram.com/deep-learning-speech-recognition/) can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let's take a look.\r
\r
### Speed\r
\r
As noted above, if you've ever tried to watch a sporting event in a bar, for example, it's very obvious that the captions are delayed-oftentimes so delayed it's hard to match them up to what's happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what's being said in time.\r
\r
### Accuracy\r
\r
Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with [custom model training](https://deepgram.com/product/custom-training/), you can use audio from your particular domain to further improve a model thanks to [transfer learning](https://blog.deepgram.com/transfer-learning-spanish-portuguese/)-something that's not possible with older speech-to-text systems.\r
\r
### Automatically Align Audio and Captions\r
\r
If you're working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it's much easier to correctly align captions with the audio.\r
\r
### Cost Savings\r
\r
Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.\r
\r
## One Problem with Using ASR for Closed Captioning\r
\r
Before we wrap up, it's worth noting that there's one issue that you can run into if you're trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won't be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what's happening on-screen. In these cases, you'd still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.\r
\r
## Wrapping Up\r
\r
And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you're curious how Deepgram's speech-to-text API can help your captioning use case, [give us a try and get $150 in free credits](https://console.deepgram.com/signup). Have questions? Reach out and we'll be happy to talk through your use case with you and see how we can help.\r
`, "html": '<p>There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we\u2019ll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We\u2019ll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let\u2019s define what exactly closed captioning is.</p>\n<h2 id="what-is-closed-captioning">What is Closed Captioning?</h2>\n<p>Closed captioning is a means of adding a transcript of what is said to video files. It\u2019s similar to subtitles, but while subtitles are usually intended for someone who doesn\u2019t speak or understand the language used in the video, closed captions are intended for those who might be <a href="https://blog.deepgram.com/asr-important-deaf-hoh-community/">deaf or hard of hearing</a>. However, <a href="https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?">Verizon Media</a> found that 80% of closed caption users aren\u2019t hearing impaired, so this is a feature that\u2019s expanding in use. And, in case you\u2019re curious-\u201Dclosed\u201D here means that the captions aren\u2019t visible to the viewer until they turn them on.</p>\n<h2 id="use-cases-for-speech-to-text-in-closed-captioning">Use Cases for Speech-to-Text in Closed Captioning</h2>\n<p>It might seem like there\u2019s just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.</p>\n<h3 id="live-events">Live Events</h3>\n<p>Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it\u2019s important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.</p>\n<h3 id="live-television">Live Television</h3>\n<p>Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you\u2019ve ever tried to watch something live with closed captions turned on, you know that they\u2019re often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.</p>\n<h3 id="education-and-training">Education and Training</h3>\n<p>Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.</p>\n<h3 id="podcasts">Podcasts</h3>\n<p>Although you might mostly associate captions with video content, they\u2019re also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it\u2019s one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who\u2019d rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at <a href="https://podcast-accessibility.com/">Podcast Accessibility</a>.</p>\n<WhitepaperPromo whitepaper="latest" />\n<h2 id="benefits-of-ai-powered-asr-for-closed-captioning">Benefits of AI-Powered ASR for Closed Captioning</h2>\n<p>It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep-learning ASR solutions like Deepgram</a> can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let\u2019s take a look.</p>\n<h3 id="speed">Speed</h3>\n<p>As noted above, if you\u2019ve ever tried to watch a sporting event in a bar, for example, it\u2019s very obvious that the captions are delayed-oftentimes so delayed it\u2019s hard to match them up to what\u2019s happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what\u2019s being said in time.</p>\n<h3 id="accuracy">Accuracy</h3>\n<p>Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with <a href="https://deepgram.com/product/custom-training/">custom model training</a>, you can use audio from your particular domain to further improve a model thanks to <a href="https://blog.deepgram.com/transfer-learning-spanish-portuguese/">transfer learning</a>-something that\u2019s not possible with older speech-to-text systems.</p>\n<h3 id="automatically-align-audio-and-captions">Automatically Align Audio and Captions</h3>\n<p>If you\u2019re working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it\u2019s much easier to correctly align captions with the audio.</p>\n<h3 id="cost-savings">Cost Savings</h3>\n<p>Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.</p>\n<h2 id="one-problem-with-using-asr-for-closed-captioning">One Problem with Using ASR for Closed Captioning</h2>\n<p>Before we wrap up, it\u2019s worth noting that there\u2019s one issue that you can run into if you\u2019re trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won\u2019t be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what\u2019s happening on-screen. In these cases, you\u2019d still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.</p>\n<h2 id="wrapping-up">Wrapping Up</h2>\n<p>And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you\u2019re curious how Deepgram\u2019s speech-to-text API can help your captioning use case, <a href="https://console.deepgram.com/signup">give us a try and get $150 in free credits</a>. Have questions? Reach out and we\u2019ll be happy to talk through your use case with you and see how we can help.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/closed-captioning-companies-use-asr/index.md" };
function rawContent() {
  return `\r
There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we'll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We'll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let's define what exactly closed captioning is.\r
\r
## What is Closed Captioning?\r
\r
Closed captioning is a means of adding a transcript of what is said to video files. It's similar to subtitles, but while subtitles are usually intended for someone who doesn't speak or understand the language used in the video, closed captions are intended for those who might be [deaf or hard of hearing](https://blog.deepgram.com/asr-important-deaf-hoh-community/). However, [Verizon Media](https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?) found that 80% of closed caption users aren't hearing impaired, so this is a feature that's expanding in use. And, in case you're curious-"closed" here means that the captions aren't visible to the viewer until they turn them on.\r
\r
## Use Cases for Speech-to-Text in Closed Captioning\r
\r
It might seem like there's just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.\r
\r
### Live Events\r
\r
Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it's important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.\r
\r
### Live Television\r
\r
Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you've ever tried to watch something live with closed captions turned on, you know that they're often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.\r
\r
### Education and Training\r
\r
Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.\r
\r
### Podcasts\r
\r
Although you might mostly associate captions with video content, they're also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it's one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who'd rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at [Podcast Accessibility](https://podcast-accessibility.com/).\r
\r
<WhitepaperPromo whitepaper="latest"></WhitepaperPromo>\r
\r
## Benefits of AI-Powered ASR for Closed Captioning\r
\r
It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, [end-to-end deep-learning ASR solutions like Deepgram](https://blog.deepgram.com/deep-learning-speech-recognition/) can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let's take a look.\r
\r
### Speed\r
\r
As noted above, if you've ever tried to watch a sporting event in a bar, for example, it's very obvious that the captions are delayed-oftentimes so delayed it's hard to match them up to what's happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what's being said in time.\r
\r
### Accuracy\r
\r
Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with [custom model training](https://deepgram.com/product/custom-training/), you can use audio from your particular domain to further improve a model thanks to [transfer learning](https://blog.deepgram.com/transfer-learning-spanish-portuguese/)-something that's not possible with older speech-to-text systems.\r
\r
### Automatically Align Audio and Captions\r
\r
If you're working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it's much easier to correctly align captions with the audio.\r
\r
### Cost Savings\r
\r
Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.\r
\r
## One Problem with Using ASR for Closed Captioning\r
\r
Before we wrap up, it's worth noting that there's one issue that you can run into if you're trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won't be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what's happening on-screen. In these cases, you'd still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.\r
\r
## Wrapping Up\r
\r
And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you're curious how Deepgram's speech-to-text API can help your captioning use case, [give us a try and get $150 in free credits](https://console.deepgram.com/signup). Have questions? Reach out and we'll be happy to talk through your use case with you and see how we can help.\r
`;
}
function compiledContent() {
  return '<p>There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we\u2019ll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We\u2019ll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let\u2019s define what exactly closed captioning is.</p>\n<h2 id="what-is-closed-captioning">What is Closed Captioning?</h2>\n<p>Closed captioning is a means of adding a transcript of what is said to video files. It\u2019s similar to subtitles, but while subtitles are usually intended for someone who doesn\u2019t speak or understand the language used in the video, closed captions are intended for those who might be <a href="https://blog.deepgram.com/asr-important-deaf-hoh-community/">deaf or hard of hearing</a>. However, <a href="https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?">Verizon Media</a> found that 80% of closed caption users aren\u2019t hearing impaired, so this is a feature that\u2019s expanding in use. And, in case you\u2019re curious-\u201Dclosed\u201D here means that the captions aren\u2019t visible to the viewer until they turn them on.</p>\n<h2 id="use-cases-for-speech-to-text-in-closed-captioning">Use Cases for Speech-to-Text in Closed Captioning</h2>\n<p>It might seem like there\u2019s just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.</p>\n<h3 id="live-events">Live Events</h3>\n<p>Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it\u2019s important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.</p>\n<h3 id="live-television">Live Television</h3>\n<p>Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you\u2019ve ever tried to watch something live with closed captions turned on, you know that they\u2019re often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.</p>\n<h3 id="education-and-training">Education and Training</h3>\n<p>Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.</p>\n<h3 id="podcasts">Podcasts</h3>\n<p>Although you might mostly associate captions with video content, they\u2019re also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it\u2019s one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who\u2019d rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at <a href="https://podcast-accessibility.com/">Podcast Accessibility</a>.</p>\n<WhitepaperPromo whitepaper="latest" />\n<h2 id="benefits-of-ai-powered-asr-for-closed-captioning">Benefits of AI-Powered ASR for Closed Captioning</h2>\n<p>It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep-learning ASR solutions like Deepgram</a> can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let\u2019s take a look.</p>\n<h3 id="speed">Speed</h3>\n<p>As noted above, if you\u2019ve ever tried to watch a sporting event in a bar, for example, it\u2019s very obvious that the captions are delayed-oftentimes so delayed it\u2019s hard to match them up to what\u2019s happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what\u2019s being said in time.</p>\n<h3 id="accuracy">Accuracy</h3>\n<p>Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with <a href="https://deepgram.com/product/custom-training/">custom model training</a>, you can use audio from your particular domain to further improve a model thanks to <a href="https://blog.deepgram.com/transfer-learning-spanish-portuguese/">transfer learning</a>-something that\u2019s not possible with older speech-to-text systems.</p>\n<h3 id="automatically-align-audio-and-captions">Automatically Align Audio and Captions</h3>\n<p>If you\u2019re working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it\u2019s much easier to correctly align captions with the audio.</p>\n<h3 id="cost-savings">Cost Savings</h3>\n<p>Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.</p>\n<h2 id="one-problem-with-using-asr-for-closed-captioning">One Problem with Using ASR for Closed Captioning</h2>\n<p>Before we wrap up, it\u2019s worth noting that there\u2019s one issue that you can run into if you\u2019re trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won\u2019t be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what\u2019s happening on-screen. In these cases, you\u2019d still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.</p>\n<h2 id="wrapping-up">Wrapping Up</h2>\n<p>And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you\u2019re curious how Deepgram\u2019s speech-to-text API can help your captioning use case, <a href="https://console.deepgram.com/signup">give us a try and get $150 in free credits</a>. Have questions? Reach out and we\u2019ll be happy to talk through your use case with you and see how we can help.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/closed-captioning-companies-use-asr/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>There are many different ways that closed captioning is enabled by speech-to-text and automatic speech recognition (ASR). In this blog post, we’ll discuss some of the most common of these use cases, including creating captions for live events, podcasts, and transcribing videos. We’ll also explore the benefits that state-of-the-art, AI-powered speech-to-text solutions like Deepgram can provide to closed captioning companies. But before we start, let’s define what exactly closed captioning is.</p>
<h2 id="what-is-closed-captioning">What is Closed Captioning?</h2>
<p>Closed captioning is a means of adding a transcript of what is said to video files. It’s similar to subtitles, but while subtitles are usually intended for someone who doesn’t speak or understand the language used in the video, closed captions are intended for those who might be <a href="https://blog.deepgram.com/asr-important-deaf-hoh-community/">deaf or hard of hearing</a>. However, <a href="https://www.streamingmedia.com/Articles/News/Online-Video-News/80-of-Video-Caption-Users-Arent-Hearing-Impaired-Finds-Verizon-131860.aspx?">Verizon Media</a> found that 80% of closed caption users aren’t hearing impaired, so this is a feature that’s expanding in use. And, in case you’re curious-”closed” here means that the captions aren’t visible to the viewer until they turn them on.</p>
<h2 id="use-cases-for-speech-to-text-in-closed-captioning">Use Cases for Speech-to-Text in Closed Captioning</h2>
<p>It might seem like there’s just one use case for ASR in closed captioning-namely, providing a transcript of what was said-but we can think about several different domains where captions can be generated with speech-to-text solutions, and that have real advantages over using human transcriptionists.</p>
<h3 id="live-events">Live Events</h3>
<p>Speech-to-text for live captioning is one of the prime use cases for ASR solutions. These captions are especially important for live events because they allow people who are deaf or hard of hearing to follow along with what is happening and be included in the event. And, these captions can also help others-those too far away from the speaker to hear clearly, for example, can also benefit. This type of captioning can be done with or without human intervention, but it’s important to have someone who is familiar with ASR monitoring the captioning process to ensure accuracy.</p>
<h3 id="live-television">Live Television</h3>
<p>Similar to live events, live television is another place where closed captions powered by AI speech-to-text can have a big impact. If you’ve ever tried to watch something live with closed captions turned on, you know that they’re often delayed several seconds while humans transcribe what was said. But by using speech-to-text for captioning, transcriptions can be generated in real time, removing delays and lag.</p>
<h3 id="education-and-training">Education and Training</h3>
<p>Captioning can also be used to transcribe pre-recorded videos or podcasts. This is often done for educational or training videos, but it can also be used for other types of video content. ASR can be used to create a transcript of the video, which can then be used to create captions. This type of captioning is important for making sure that all viewers can access the information in the video, regardless of whether they are able to hear the audio.</p>
<h3 id="podcasts">Podcasts</h3>
<p>Although you might mostly associate captions with video content, they’re also a critical component of accessibility for podcasts. Podcast content has exploded in recent years and has become a major type of media. But it’s one that can be difficult or impossible for people who are deaf or hard-of-hearing to access without captions. These captions can help other people, too-non-native speakers, people listening with background noise, and those who’d rather read content than listen to it, to name a few. You can read more about the importance of captioning for podcasts at <a href="https://podcast-accessibility.com/">Podcast Accessibility</a>.</p>
${renderComponent($$result, "WhitepaperPromo", WhitepaperPromo, { "whitepaper": "latest" })}
<h2 id="benefits-of-ai-powered-asr-for-closed-captioning">Benefits of AI-Powered ASR for Closed Captioning</h2>
<p>It should be clear from the above that closed captioning powered by AI speech recognition has a lot of potential use cases. But not all speech-to-text solutions can be used for real-time closed captioning. Older systems that rely on a legacy approach are typically too slow for live use cases. However, <a href="https://blog.deepgram.com/deep-learning-speech-recognition/">end-to-end deep-learning ASR solutions like Deepgram</a> can turn around transcriptions in fractions of a second, creating a truly real-time experience. So what are some of the specific benefits that AI-powered speech-to-text tools can provide when compared to a human? Let’s take a look.</p>
<h3 id="speed">Speed</h3>
<p>As noted above, if you’ve ever tried to watch a sporting event in a bar, for example, it’s very obvious that the captions are delayed-oftentimes so delayed it’s hard to match them up to what’s happening. With a speech-to-text system that runs in real time, these delays can be reduced to fractions of a second so that transcriptions more closely match what’s being said in time.</p>
<h3 id="accuracy">Accuracy</h3>
<p>Another issue you might have seen with live events is that the accuracy of the captions can suffer. This can be anything from small typos to misheard words to complete gibberish. AI-powered speech recognition systems can have accuracies of over 90%. And, with <a href="https://deepgram.com/product/custom-training/">custom model training</a>, you can use audio from your particular domain to further improve a model thanks to <a href="https://blog.deepgram.com/transfer-learning-spanish-portuguese/">transfer learning</a>-something that’s not possible with older speech-to-text systems.</p>
<h3 id="automatically-align-audio-and-captions">Automatically Align Audio and Captions</h3>
<p>If you’re working with human-created transcripts on pre-recorded audio, someone-usually the transcriptionist-has to manually align each caption to the right part of a video, which can be a tedious and time-consuming process. Because ASR transcriptions output start and end times, it’s much easier to correctly align captions with the audio.</p>
<h3 id="cost-savings">Cost Savings</h3>
<p>Paying to have a video transcribed can be quite expensive. But with ASR, the cost savings over human transcriptionists can be substantial. And, with AI-powered solutions, you can run multiple audio streams at the same time without losing speed or accuracy, allowing for more things to be transcribed for less.</p>
<h2 id="one-problem-with-using-asr-for-closed-captioning">One Problem with Using ASR for Closed Captioning</h2>
<p>Before we wrap up, it’s worth noting that there’s one issue that you can run into if you’re trying to use only ASR for your transcriptions of things like TV shows or movies: even the most sophisticated system won’t be able to tell which [door creaks] or [spooky whispering] should be included in the captions to help those who are deaf or hard-of-hearing understand what’s happening on-screen. In these cases, you’d still want a human in the loop to make sure that any important, non-speech audio is included in the captions. But the ASR transcript can still be used as the base, providing many of the features above, like speed and time syncing, even if a human needs to be included.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>And there you have it-some of the main ways that ASR tools can deliver strong benefits for anyone who needs to generate closed captions. If you’re curious how Deepgram’s speech-to-text API can help your captioning use case, <a href="https://console.deepgram.com/signup">give us a try and get $150 in free credits</a>. Have questions? Reach out and we’ll be happy to talk through your use case with you and see how we can help.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/closed-captioning-companies-use-asr/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
