import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           *//* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "what-is-deepgram", "text": "What is Deepgram?" }, { "depth": 2, "slug": "the-deepgram-python-sdk-project-with-matplotlib-visualization", "text": "The Deepgram Python SDK Project With Matplotlib Visualization" }, { "depth": 2, "slug": "setting-up-the-deepgram-speech-to-text-python-project", "text": "Setting Up the Deepgram Speech-to-Text Python Project" }, { "depth": 2, "slug": "the-code-for-the-deepgram-speech-to-text-python-project-with-matplotlib-graphing", "text": "The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing" }, { "depth": 3, "slug": "the-python-imports", "text": "The Python Imports" }, { "depth": 3, "slug": "the-python-globals", "text": "The Python Globals" }, { "depth": 3, "slug": "get-the-deepgram-speech-to-text-transcript", "text": "Get the Deepgram Speech-to-Text Transcript" }, { "depth": 3, "slug": "data-visualization-with-matplotlib", "text": "Data Visualization with Matplotlib" }, { "depth": 2, "slug": "conclusion-of-deepgram-speech-to-text-with-python-and-matplotlib", "text": "Conclusion of Deepgram Speech-to-Text with Python and Matplotlib" }], "source": "240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.\n\nIt\u2019s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they\u2019re having an emergency?\n\nThe answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let's see why these two technologies are a perfect match.\n\n## What is Deepgram?\n\n\u200B\u200BDeepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You\u2019ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.\n\nWe offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including [FastAPI](https://blog.deepgram.com/live-transcription-fastapi/), [Flask](https://blog.deepgram.com/live-transcription-flask/), [Django](https://blog.deepgram.com/live-transcription-django/), and [Quart](https://blog.deepgram.com/live-transcription-quart/).\n\n## The Deepgram Python SDK Project With Matplotlib Visualization\n\nNow that you have a better understanding of Deepgram, let\u2019s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let\u2019s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.\n\n## Setting Up the Deepgram Speech-to-Text Python Project\n\nBefore we start, it\u2019s essential to generate a Deepgram API key to use in our project. We can go to the [Deepgram Console](https://console.deepgram.com/signup?jump=keys). We'll make sure to copy it and keep it in a safe place, as we won\u2019t be able to retrieve it again and will have to create a new one. In this tutorial, we\u2019ll use Python 3.10, but Deepgram supports some earlier versions of Python.\n\nNext, we'll make a directory anywhere we\u2019d like.\n\n```\nmkdir deepgram-dashboard\n```\n\nThen we'll change into that directory to start adding things to it.\n\n```\ncd deepgram-dashboard\n```\n\nWe\u2019ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those [here](https://blog.deepgram.com/python-virtual-environments/) and how to create one. It\u2019s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.\nWe need to ensure the virtual environment is activated because we\u2019ll install dependencies inside. If the virtual environment is named `venv`, we'll need to activate it.\n\n```\nsource venv/bin/activate\n```\n\nWe'll install the dependencies for the project by running the below `pip` installs from the terminal inside the virtual environment.\n\n```\npip install deepgram-sdk\npip install python-dotenv\npip install matplotlib\n```\n\nWe now can open up an editor and create an environment variable file to store the Deepgram API Key from the [Deepgram Console](https://console.deepgram.com/). Create a new file called `.env` at the project level and add the following Python environment variable, replacing `[YOUR_API_KEY]` with the API Key from the console:\n\n```\nDEEPGRAM_API_KEY=\u201D[YOUR_API_KEY]\u201D\n```\n\nLastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for [Apple](https://apps.apple.com/us/app/pcm-recorder-lite/id439572045) or [Android](https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&hl=en_US&gl=US). This app will create `.wav`audio files but please note that Deepgram supports over [100+ audio formats and encodings](https://developers.deepgram.com/documentation/getting-started/audio-formats/).\n\n## The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing\n\nNow to the fun part! Let\u2019s create a file called `transcribe-with-deepgram.py`, which holds all of the code in this project.\n\nThe project structure looks like this:\n\n![Deepgram speech-to-text project structure](https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png)\n\n### The Python Imports\n\nLet\u2019s open the file `transcribe-with-deepgram.py` and add the following imports:\n\n```python\nimport asyncio\nimport os\nfrom collections import Counter\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom matplotlib import pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n```\n\n* `import asyncio` helps with writing asynchronous code in Python with the `async` and `await` keywords.\n* `import os` helps working with files and directories.\n* `from collections import Counter` helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.\n* `from deepgram import Deepgram` allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.\n* `from dotenv import load_dotenv` reads the key/value pairs from the `.env` file and sets them as environment variables.\n* `from matplotlib import pyplot as plt` creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.\n* `from matplotlib.ticker import MaxNLocator` helps provide the graph with friendly integer tick values.\n\n### The Python Globals\n\nLet\u2019s add this code underneath the imports:\n\n```python\nload_dotenv()\n\nDEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')\n\nfiles = [filename for filename in os.listdir() if filename.endswith('.wav')]\n\nwords_list = []\n```\n\nThe first line `load_dotenv()` loads the environment variables from the `.env` file and makes them available in the project.\n\nThis line `DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')` uses `os.getenv()` to return the value of the environment variable key, if it exists, and sets it to a variable.\n\nThe `files` variable holds all of the files in our directory that end in `wav` as we loop through each, indicated by the list comprehension `[filename for filename in os.listdir() if filename.endswith('.wav')]`.\n\nFinally, an empty list called `words_list` is created, storing the words extracted from the JSON response Deepgram returns.\n\n### Get the Deepgram Speech-to-Text Transcript\n\nLet\u2019s add our first function to the `transcribe-with-deepgram.py` file.\n\n```python\nasync def get_transcript():\n    deepgram = Deepgram(DEEPGRAM_API_KEY)\n\n    words_count = Counter()\n\n    for file in files:\n        with open(file, 'rb') as audio:\n            source = {'buffer': audio, 'mimetype': 'audio/wav'}\n            response = await deepgram.transcription.prerecorded(source, {'punctuate': True})\n\n            if 'results' in response:\n                get_words = response['results']['channels'][0]['alternatives'][0]['words']\n                for words in get_words:\n                    word = words['word']\n                    words_list.append(word)\n\n\n        words_count += Counter([w.lower() for w in words_list if w.lower() not in ['a', 'the', 'is', 'this', 'i', 'to', 'and']])\n\n    return words_count\n```\n\nHere `deepgram = Deepgram(DEEPGRAM_API_KEY)` Deepgram is initialized by providing the API Key from variable `DEEPGRAM_API_KEY` below the imports.\n\n`words_count = Counter()` creates a `Counter` object that holds key/value pairs of the words spoken in the transcript and how many times they appear.\n\nIn the below code snippet, we iterate through the `.wav` audio files in our directory and open each one. The source is set to a dictionary with the `buffer` value as `audio` and `mimetype` as `audio/wav`. If we were using `.mp3` files the `mimetype` would be `audio/mp3`. The next line is where the actual Deepgram transcription happens with the pre-recorded audio `await deepgram.transcription.prerecorded(source, {'punctuate': True})`. Notice the `source` is passed in along with a dictionary `{'punctuate': True}`, which is a Deepgram feature that adds punctuation and capitalization to the transcript.\n\n```python\nfor file in files:\n    with open(file, 'rb') as audio:\n        source = {'buffer': audio, 'mimetype': 'audio/wav'}\n        response = await deepgram.transcription.prerecorded(source, {'punctuate': True)\n```\n\nTo get the words from the transcript, let\u2019s check the JSON response object for `results`. Then we loop through the response and parse it to find each word in the transcript and append it to our list called `words_list` that was defined earlier.\n\n```python\nif 'results' in response:\n    get_words = response['results']['channels'][0]['alternatives'][0]['words']\n    for words in get_words:\n        word = words['word']\n        words_list.append(word)\n```\n\nIn the last part of the function, we take our `words_count` Counter and create a list comprehension that appends all the words in the list `words_list` with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, `return words_count` returns it, so it\u2019s accessible outside our function when we need it.\n\n```python\nwords_count += Counter([w.lower() for w in words_list if w.lower() not in ['a', 'the', 'is', 'this', 'i', 'to', 'and']])\n\nreturn words_count\n```\n\n### Data Visualization with Matplotlib\n\nLet\u2019s look at turning transcripts into data visualizations by creating a function called `get_graph()`.\n\n```python\nasync def get_graph():\n    words = await get_transcript()\n\n    x = range(len(words.keys()))\n    width = 0.35\n\n    fig, ax = plt.subplots()\n\n    ax.set_ylabel('Word Count')\n    ax.set_xlabel('Emergency Call Types')\n    ax.set_title('Deepgram Transcript')\n    ax.set_xticks(x)\n    ax.set_xticklabels(words.keys())\n    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n\n    pps = ax.bar([i - width/2 for i in x], words.values(), width, label='words')\n    for p in pps:\n        height = p.get_height()\n        ax.annotate('{}'.format(height),\n            xy=(p.get_x() + p.get_width() / 2, height),\n            xytext=(0, 3),\n            textcoords='offset points',\n            ha='center', va='bottom')\n\n    plt.show()\n```\n\nA lot is going on in this function, so let\u2019s simplify it by looking at the code in bigger chunks.\n\nLet\u2019s get the returned value of `words_count` from the previous function by creating a new object `words = await get_transcript()`.\n\nThe code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the `word` object. Then it places each in the chart.\n\n```python\nax.set_ylabel('Word Count')\nax.set_xlabel('Emergency Call Types')\nax.set_title('Deepgram Transcript')\nax.set_xticks(x)\nax.set_xticklabels(words.keys())\nax.yaxis.set_major_locator(MaxNLocator(integer=True))\n```\n\nLastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. `plt.show()` will display the bar graph.\n\n```python\npps = ax.bar([i - width/2 for i in x], words.values(), width, label='words')\n\n    for p in pps:\n        height = p.get_height()\n        ax.annotate('{}'.format(height),\n            xy=(p.get_x() + p.get_width() / 2, height),\n            xytext=(0, 3),\n            textcoords='offset points',\n            ha='center', va='bottom')\n\n    plt.show()\n```\n\nNow, run the project by going to a command line prompt in the terminal and type:\n\n```\npython3 transcribe-with-deepgram.py\n```\n\nA beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):\n\n![Deepgram speech-to-text transcript with matplotlib data visualization dashboard](https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png)\n\n## Conclusion of Deepgram Speech-to-Text with Python and Matplotlib\n\nThere are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it\u2019s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at [@deepgramdevs](https://twitter.com/DeepgramDevs). We would love to hear from you!", "html": `<p>240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.</p>
<p>It\u2019s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they\u2019re having an emergency?</p>
<p>The answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let\u2019s see why these two technologies are a perfect match.</p>
<h2 id="what-is-deepgram">What is Deepgram?</h2>
<p>\u200B\u200BDeepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You\u2019ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.</p>
<p>We offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including <a href="https://blog.deepgram.com/live-transcription-fastapi/">FastAPI</a>, <a href="https://blog.deepgram.com/live-transcription-flask/">Flask</a>, <a href="https://blog.deepgram.com/live-transcription-django/">Django</a>, and <a href="https://blog.deepgram.com/live-transcription-quart/">Quart</a>.</p>
<h2 id="the-deepgram-python-sdk-project-with-matplotlib-visualization">The Deepgram Python SDK Project With Matplotlib Visualization</h2>
<p>Now that you have a better understanding of Deepgram, let\u2019s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let\u2019s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.</p>
<h2 id="setting-up-the-deepgram-speech-to-text-python-project">Setting Up the Deepgram Speech-to-Text Python Project</h2>
<p>Before we start, it\u2019s essential to generate a Deepgram API key to use in our project. We can go to the <a href="https://console.deepgram.com/signup?jump=keys">Deepgram Console</a>. We\u2019ll make sure to copy it and keep it in a safe place, as we won\u2019t be able to retrieve it again and will have to create a new one. In this tutorial, we\u2019ll use Python 3.10, but Deepgram supports some earlier versions of Python.</p>
<p>Next, we\u2019ll make a directory anywhere we\u2019d like.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">mkdir deepgram-dashboard</span></span></code></pre>
<p>Then we\u2019ll change into that directory to start adding things to it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">cd deepgram-dashboard</span></span></code></pre>
<p>We\u2019ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those <a href="https://blog.deepgram.com/python-virtual-environments/">here</a> and how to create one. It\u2019s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.
We need to ensure the virtual environment is activated because we\u2019ll install dependencies inside. If the virtual environment is named <code is:raw>venv</code>, we\u2019ll need to activate it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">source venv/bin/activate</span></span></code></pre>
<p>We\u2019ll install the dependencies for the project by running the below <code is:raw>pip</code> installs from the terminal inside the virtual environment.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>
<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>
<span class="line"><span style="color: #c9d1d9">pip install matplotlib</span></span></code></pre>
<p>We now can open up an editor and create an environment variable file to store the Deepgram API Key from the <a href="https://console.deepgram.com/">Deepgram Console</a>. Create a new file called <code is:raw>.env</code> at the project level and add the following Python environment variable, replacing <code is:raw>[YOUR_API_KEY]</code> with the API Key from the console:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_API_KEY=\u201D[YOUR_API_KEY]\u201D</span></span></code></pre>
<p>Lastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for <a href="https://apps.apple.com/us/app/pcm-recorder-lite/id439572045">Apple</a> or <a href="https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&#x26;hl=en_US&#x26;gl=US">Android</a>. This app will create <code is:raw>.wav</code>audio files but please note that Deepgram supports over <a href="https://developers.deepgram.com/documentation/getting-started/audio-formats/">100+ audio formats and encodings</a>.</p>
<h2 id="the-code-for-the-deepgram-speech-to-text-python-project-with-matplotlib-graphing">The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing</h2>
<p>Now to the fun part! Let\u2019s create a file called <code is:raw>transcribe-with-deepgram.py</code>, which holds all of the code in this project.</p>
<p>The project structure looks like this:</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png" alt="Deepgram speech-to-text project structure"></p>
<h3 id="the-python-imports">The Python Imports</h3>
<p>Let\u2019s open the file <code is:raw>transcribe-with-deepgram.py</code> and add the following imports:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> collections </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Counter</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib.ticker </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> MaxNLocator</span></span></code></pre>
<ul>
<li><code is:raw>import asyncio</code> helps with writing asynchronous code in Python with the <code is:raw>async</code> and <code is:raw>await</code> keywords.</li>
<li><code is:raw>import os</code> helps working with files and directories.</li>
<li><code is:raw>from collections import Counter</code> helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.</li>
<li><code is:raw>from deepgram import Deepgram</code> allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.</li>
<li><code is:raw>from dotenv import load_dotenv</code> reads the key/value pairs from the <code is:raw>.env</code> file and sets them as environment variables.</li>
<li><code is:raw>from matplotlib import pyplot as plt</code> creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.</li>
<li><code is:raw>from matplotlib.ticker import MaxNLocator</code> helps provide the graph with friendly integer tick values.</li>
</ul>
<h3 id="the-python-globals">The Python Globals</h3>
<p>Let\u2019s add this code underneath the imports:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.getenv(</span><span style="color: #A5D6FF">&#39;DEEPGRAM_API_KEY&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">files </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [filename </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> filename </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> os.listdir() </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> filename.endswith(</span><span style="color: #A5D6FF">&#39;.wav&#39;</span><span style="color: #C9D1D9">)]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">words_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span></code></pre>
<p>The first line <code is:raw>load_dotenv()</code> loads the environment variables from the <code is:raw>.env</code> file and makes them available in the project.</p>
<p>This line <code is:raw>DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')</code> uses <code is:raw>os.getenv()</code> to return the value of the environment variable key, if it exists, and sets it to a variable.</p>
<p>The <code is:raw>files</code> variable holds all of the files in our directory that end in <code is:raw>wav</code> as we loop through each, indicated by the list comprehension <code is:raw>[filename for filename in os.listdir() if filename.endswith('.wav')]</code>.</p>
<p>Finally, an empty list called <code is:raw>words_list</code> is created, storing the words extracted from the JSON response Deepgram returns.</p>
<h3 id="get-the-deepgram-speech-to-text-transcript">Get the Deepgram Speech-to-Text Transcript</h3>
<p>Let\u2019s add our first function to the <code is:raw>transcribe-with-deepgram.py</code> file.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_transcript</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    words_count </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Counter()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">            source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">            response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">                get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">                    word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                    words_list.append(word)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">        words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<p>Here <code is:raw>deepgram = Deepgram(DEEPGRAM_API_KEY)</code> Deepgram is initialized by providing the API Key from variable <code is:raw>DEEPGRAM_API_KEY</code> below the imports.</p>
<p><code is:raw>words_count = Counter()</code> creates a <code is:raw>Counter</code> object that holds key/value pairs of the words spoken in the transcript and how many times they appear.</p>
<p>In the below code snippet, we iterate through the <code is:raw>.wav</code> audio files in our directory and open each one. The source is set to a dictionary with the <code is:raw>buffer</code> value as <code is:raw>audio</code> and <code is:raw>mimetype</code> as <code is:raw>audio/wav</code>. If we were using <code is:raw>.mp3</code> files the <code is:raw>mimetype</code> would be <code is:raw>audio/mp3</code>. The next line is where the actual Deepgram transcription happens with the pre-recorded audio <code is:raw>await deepgram.transcription.prerecorded(source, {'punctuate': True})</code>. Notice the <code is:raw>source</code> is passed in along with a dictionary <code is:raw>{'punctuate': True}</code>, which is a Deepgram feature that adds punctuation and capitalization to the transcript.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p>To get the words from the transcript, let\u2019s check the JSON response object for <code is:raw>results</code>. Then we loop through the response and parse it to find each word in the transcript and append it to our list called <code is:raw>words_list</code> that was defined earlier.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">    get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">        word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">        words_list.append(word)</span></span></code></pre>
<p>In the last part of the function, we take our <code is:raw>words_count</code> Counter and create a list comprehension that appends all the words in the list <code is:raw>words_list</code> with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, <code is:raw>return words_count</code> returns it, so it\u2019s accessible outside our function when we need it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<h3 id="data-visualization-with-matplotlib">Data Visualization with Matplotlib</h3>
<p>Let\u2019s look at turning transcripts into data visualizations by creating a function called <code is:raw>get_graph()</code>.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_graph</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> get_transcript()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(words.keys()))</span></span>
<span class="line"><span style="color: #C9D1D9">    width </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.35</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    fig, ax </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>A lot is going on in this function, so let\u2019s simplify it by looking at the code in bigger chunks.</p>
<p>Let\u2019s get the returned value of <code is:raw>words_count</code> from the previous function by creating a new object <code is:raw>words = await get_transcript()</code>.</p>
<p>The code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the <code is:raw>word</code> object. Then it places each in the chart.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span></code></pre>
<p>Lastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. <code is:raw>plt.show()</code> will display the bar graph.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>Now, run the project by going to a command line prompt in the terminal and type:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">python3 transcribe-with-deepgram.py</span></span></code></pre>
<p>A beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png" alt="Deepgram speech-to-text transcript with matplotlib data visualization dashboard"></p>
<h2 id="conclusion-of-deepgram-speech-to-text-with-python-and-matplotlib">Conclusion of Deepgram Speech-to-Text with Python and Matplotlib</h2>
<p>There are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it\u2019s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at <a href="https://twitter.com/DeepgramDevs">@deepgramdevs</a>. We would love to hear from you!</p>` };
const frontmatter = { "title": "How to Turn Transcripts into Data Visualizations with Python", "description": "Use Deepgram's speech-to-text features with Python to transcribe audio and graphing library Matplotlib to create a data visualization dashboard.", "date": "2022-05-12T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1652286544/blog/2022/05/python-graphing-transcripts/Build-Dashboard-Visualize-Real-Time-Speech-Python%402x.jpg", "authors": ["tonya-sims"], "category": "tutorial", "tags": ["python", "data-visualization"], "seo": { "title": "How to Turn Transcripts into Data Visualizations with Python", "description": "Use Deepgram's speech-to-text features with Python to transcribe audio and graphing library Matplotlib to create a data visualization dashboard." }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454089/blog/python-graphing-transcripts/ograph.png" }, "shorturls": { "share": "https://dpgr.am/19fc3de", "twitter": "https://dpgr.am/cae50e6", "linkedin": "https://dpgr.am/a9a4fcf", "reddit": "https://dpgr.am/983a9bf", "facebook": "https://dpgr.am/3e7c681" }, "astro": { "headings": [{ "depth": 2, "slug": "what-is-deepgram", "text": "What is Deepgram?" }, { "depth": 2, "slug": "the-deepgram-python-sdk-project-with-matplotlib-visualization", "text": "The Deepgram Python SDK Project With Matplotlib Visualization" }, { "depth": 2, "slug": "setting-up-the-deepgram-speech-to-text-python-project", "text": "Setting Up the Deepgram Speech-to-Text Python Project" }, { "depth": 2, "slug": "the-code-for-the-deepgram-speech-to-text-python-project-with-matplotlib-graphing", "text": "The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing" }, { "depth": 3, "slug": "the-python-imports", "text": "The Python Imports" }, { "depth": 3, "slug": "the-python-globals", "text": "The Python Globals" }, { "depth": 3, "slug": "get-the-deepgram-speech-to-text-transcript", "text": "Get the Deepgram Speech-to-Text Transcript" }, { "depth": 3, "slug": "data-visualization-with-matplotlib", "text": "Data Visualization with Matplotlib" }, { "depth": 2, "slug": "conclusion-of-deepgram-speech-to-text-with-python-and-matplotlib", "text": "Conclusion of Deepgram Speech-to-Text with Python and Matplotlib" }], "source": "240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.\n\nIt\u2019s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they\u2019re having an emergency?\n\nThe answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let's see why these two technologies are a perfect match.\n\n## What is Deepgram?\n\n\u200B\u200BDeepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You\u2019ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.\n\nWe offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including [FastAPI](https://blog.deepgram.com/live-transcription-fastapi/), [Flask](https://blog.deepgram.com/live-transcription-flask/), [Django](https://blog.deepgram.com/live-transcription-django/), and [Quart](https://blog.deepgram.com/live-transcription-quart/).\n\n## The Deepgram Python SDK Project With Matplotlib Visualization\n\nNow that you have a better understanding of Deepgram, let\u2019s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let\u2019s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.\n\n## Setting Up the Deepgram Speech-to-Text Python Project\n\nBefore we start, it\u2019s essential to generate a Deepgram API key to use in our project. We can go to the [Deepgram Console](https://console.deepgram.com/signup?jump=keys). We'll make sure to copy it and keep it in a safe place, as we won\u2019t be able to retrieve it again and will have to create a new one. In this tutorial, we\u2019ll use Python 3.10, but Deepgram supports some earlier versions of Python.\n\nNext, we'll make a directory anywhere we\u2019d like.\n\n```\nmkdir deepgram-dashboard\n```\n\nThen we'll change into that directory to start adding things to it.\n\n```\ncd deepgram-dashboard\n```\n\nWe\u2019ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those [here](https://blog.deepgram.com/python-virtual-environments/) and how to create one. It\u2019s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.\nWe need to ensure the virtual environment is activated because we\u2019ll install dependencies inside. If the virtual environment is named `venv`, we'll need to activate it.\n\n```\nsource venv/bin/activate\n```\n\nWe'll install the dependencies for the project by running the below `pip` installs from the terminal inside the virtual environment.\n\n```\npip install deepgram-sdk\npip install python-dotenv\npip install matplotlib\n```\n\nWe now can open up an editor and create an environment variable file to store the Deepgram API Key from the [Deepgram Console](https://console.deepgram.com/). Create a new file called `.env` at the project level and add the following Python environment variable, replacing `[YOUR_API_KEY]` with the API Key from the console:\n\n```\nDEEPGRAM_API_KEY=\u201D[YOUR_API_KEY]\u201D\n```\n\nLastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for [Apple](https://apps.apple.com/us/app/pcm-recorder-lite/id439572045) or [Android](https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&hl=en_US&gl=US). This app will create `.wav`audio files but please note that Deepgram supports over [100+ audio formats and encodings](https://developers.deepgram.com/documentation/getting-started/audio-formats/).\n\n## The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing\n\nNow to the fun part! Let\u2019s create a file called `transcribe-with-deepgram.py`, which holds all of the code in this project.\n\nThe project structure looks like this:\n\n![Deepgram speech-to-text project structure](https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png)\n\n### The Python Imports\n\nLet\u2019s open the file `transcribe-with-deepgram.py` and add the following imports:\n\n```python\nimport asyncio\nimport os\nfrom collections import Counter\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom matplotlib import pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n```\n\n* `import asyncio` helps with writing asynchronous code in Python with the `async` and `await` keywords.\n* `import os` helps working with files and directories.\n* `from collections import Counter` helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.\n* `from deepgram import Deepgram` allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.\n* `from dotenv import load_dotenv` reads the key/value pairs from the `.env` file and sets them as environment variables.\n* `from matplotlib import pyplot as plt` creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.\n* `from matplotlib.ticker import MaxNLocator` helps provide the graph with friendly integer tick values.\n\n### The Python Globals\n\nLet\u2019s add this code underneath the imports:\n\n```python\nload_dotenv()\n\nDEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')\n\nfiles = [filename for filename in os.listdir() if filename.endswith('.wav')]\n\nwords_list = []\n```\n\nThe first line `load_dotenv()` loads the environment variables from the `.env` file and makes them available in the project.\n\nThis line `DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')` uses `os.getenv()` to return the value of the environment variable key, if it exists, and sets it to a variable.\n\nThe `files` variable holds all of the files in our directory that end in `wav` as we loop through each, indicated by the list comprehension `[filename for filename in os.listdir() if filename.endswith('.wav')]`.\n\nFinally, an empty list called `words_list` is created, storing the words extracted from the JSON response Deepgram returns.\n\n### Get the Deepgram Speech-to-Text Transcript\n\nLet\u2019s add our first function to the `transcribe-with-deepgram.py` file.\n\n```python\nasync def get_transcript():\n    deepgram = Deepgram(DEEPGRAM_API_KEY)\n\n    words_count = Counter()\n\n    for file in files:\n        with open(file, 'rb') as audio:\n            source = {'buffer': audio, 'mimetype': 'audio/wav'}\n            response = await deepgram.transcription.prerecorded(source, {'punctuate': True})\n\n            if 'results' in response:\n                get_words = response['results']['channels'][0]['alternatives'][0]['words']\n                for words in get_words:\n                    word = words['word']\n                    words_list.append(word)\n\n\n        words_count += Counter([w.lower() for w in words_list if w.lower() not in ['a', 'the', 'is', 'this', 'i', 'to', 'and']])\n\n    return words_count\n```\n\nHere `deepgram = Deepgram(DEEPGRAM_API_KEY)` Deepgram is initialized by providing the API Key from variable `DEEPGRAM_API_KEY` below the imports.\n\n`words_count = Counter()` creates a `Counter` object that holds key/value pairs of the words spoken in the transcript and how many times they appear.\n\nIn the below code snippet, we iterate through the `.wav` audio files in our directory and open each one. The source is set to a dictionary with the `buffer` value as `audio` and `mimetype` as `audio/wav`. If we were using `.mp3` files the `mimetype` would be `audio/mp3`. The next line is where the actual Deepgram transcription happens with the pre-recorded audio `await deepgram.transcription.prerecorded(source, {'punctuate': True})`. Notice the `source` is passed in along with a dictionary `{'punctuate': True}`, which is a Deepgram feature that adds punctuation and capitalization to the transcript.\n\n```python\nfor file in files:\n    with open(file, 'rb') as audio:\n        source = {'buffer': audio, 'mimetype': 'audio/wav'}\n        response = await deepgram.transcription.prerecorded(source, {'punctuate': True)\n```\n\nTo get the words from the transcript, let\u2019s check the JSON response object for `results`. Then we loop through the response and parse it to find each word in the transcript and append it to our list called `words_list` that was defined earlier.\n\n```python\nif 'results' in response:\n    get_words = response['results']['channels'][0]['alternatives'][0]['words']\n    for words in get_words:\n        word = words['word']\n        words_list.append(word)\n```\n\nIn the last part of the function, we take our `words_count` Counter and create a list comprehension that appends all the words in the list `words_list` with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, `return words_count` returns it, so it\u2019s accessible outside our function when we need it.\n\n```python\nwords_count += Counter([w.lower() for w in words_list if w.lower() not in ['a', 'the', 'is', 'this', 'i', 'to', 'and']])\n\nreturn words_count\n```\n\n### Data Visualization with Matplotlib\n\nLet\u2019s look at turning transcripts into data visualizations by creating a function called `get_graph()`.\n\n```python\nasync def get_graph():\n    words = await get_transcript()\n\n    x = range(len(words.keys()))\n    width = 0.35\n\n    fig, ax = plt.subplots()\n\n    ax.set_ylabel('Word Count')\n    ax.set_xlabel('Emergency Call Types')\n    ax.set_title('Deepgram Transcript')\n    ax.set_xticks(x)\n    ax.set_xticklabels(words.keys())\n    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n\n    pps = ax.bar([i - width/2 for i in x], words.values(), width, label='words')\n    for p in pps:\n        height = p.get_height()\n        ax.annotate('{}'.format(height),\n            xy=(p.get_x() + p.get_width() / 2, height),\n            xytext=(0, 3),\n            textcoords='offset points',\n            ha='center', va='bottom')\n\n    plt.show()\n```\n\nA lot is going on in this function, so let\u2019s simplify it by looking at the code in bigger chunks.\n\nLet\u2019s get the returned value of `words_count` from the previous function by creating a new object `words = await get_transcript()`.\n\nThe code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the `word` object. Then it places each in the chart.\n\n```python\nax.set_ylabel('Word Count')\nax.set_xlabel('Emergency Call Types')\nax.set_title('Deepgram Transcript')\nax.set_xticks(x)\nax.set_xticklabels(words.keys())\nax.yaxis.set_major_locator(MaxNLocator(integer=True))\n```\n\nLastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. `plt.show()` will display the bar graph.\n\n```python\npps = ax.bar([i - width/2 for i in x], words.values(), width, label='words')\n\n    for p in pps:\n        height = p.get_height()\n        ax.annotate('{}'.format(height),\n            xy=(p.get_x() + p.get_width() / 2, height),\n            xytext=(0, 3),\n            textcoords='offset points',\n            ha='center', va='bottom')\n\n    plt.show()\n```\n\nNow, run the project by going to a command line prompt in the terminal and type:\n\n```\npython3 transcribe-with-deepgram.py\n```\n\nA beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):\n\n![Deepgram speech-to-text transcript with matplotlib data visualization dashboard](https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png)\n\n## Conclusion of Deepgram Speech-to-Text with Python and Matplotlib\n\nThere are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it\u2019s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at [@deepgramdevs](https://twitter.com/DeepgramDevs). We would love to hear from you!", "html": `<p>240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.</p>
<p>It\u2019s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they\u2019re having an emergency?</p>
<p>The answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let\u2019s see why these two technologies are a perfect match.</p>
<h2 id="what-is-deepgram">What is Deepgram?</h2>
<p>\u200B\u200BDeepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You\u2019ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.</p>
<p>We offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including <a href="https://blog.deepgram.com/live-transcription-fastapi/">FastAPI</a>, <a href="https://blog.deepgram.com/live-transcription-flask/">Flask</a>, <a href="https://blog.deepgram.com/live-transcription-django/">Django</a>, and <a href="https://blog.deepgram.com/live-transcription-quart/">Quart</a>.</p>
<h2 id="the-deepgram-python-sdk-project-with-matplotlib-visualization">The Deepgram Python SDK Project With Matplotlib Visualization</h2>
<p>Now that you have a better understanding of Deepgram, let\u2019s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let\u2019s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.</p>
<h2 id="setting-up-the-deepgram-speech-to-text-python-project">Setting Up the Deepgram Speech-to-Text Python Project</h2>
<p>Before we start, it\u2019s essential to generate a Deepgram API key to use in our project. We can go to the <a href="https://console.deepgram.com/signup?jump=keys">Deepgram Console</a>. We\u2019ll make sure to copy it and keep it in a safe place, as we won\u2019t be able to retrieve it again and will have to create a new one. In this tutorial, we\u2019ll use Python 3.10, but Deepgram supports some earlier versions of Python.</p>
<p>Next, we\u2019ll make a directory anywhere we\u2019d like.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">mkdir deepgram-dashboard</span></span></code></pre>
<p>Then we\u2019ll change into that directory to start adding things to it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">cd deepgram-dashboard</span></span></code></pre>
<p>We\u2019ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those <a href="https://blog.deepgram.com/python-virtual-environments/">here</a> and how to create one. It\u2019s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.
We need to ensure the virtual environment is activated because we\u2019ll install dependencies inside. If the virtual environment is named <code is:raw>venv</code>, we\u2019ll need to activate it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">source venv/bin/activate</span></span></code></pre>
<p>We\u2019ll install the dependencies for the project by running the below <code is:raw>pip</code> installs from the terminal inside the virtual environment.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>
<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>
<span class="line"><span style="color: #c9d1d9">pip install matplotlib</span></span></code></pre>
<p>We now can open up an editor and create an environment variable file to store the Deepgram API Key from the <a href="https://console.deepgram.com/">Deepgram Console</a>. Create a new file called <code is:raw>.env</code> at the project level and add the following Python environment variable, replacing <code is:raw>[YOUR_API_KEY]</code> with the API Key from the console:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_API_KEY=\u201D[YOUR_API_KEY]\u201D</span></span></code></pre>
<p>Lastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for <a href="https://apps.apple.com/us/app/pcm-recorder-lite/id439572045">Apple</a> or <a href="https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&#x26;hl=en_US&#x26;gl=US">Android</a>. This app will create <code is:raw>.wav</code>audio files but please note that Deepgram supports over <a href="https://developers.deepgram.com/documentation/getting-started/audio-formats/">100+ audio formats and encodings</a>.</p>
<h2 id="the-code-for-the-deepgram-speech-to-text-python-project-with-matplotlib-graphing">The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing</h2>
<p>Now to the fun part! Let\u2019s create a file called <code is:raw>transcribe-with-deepgram.py</code>, which holds all of the code in this project.</p>
<p>The project structure looks like this:</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png" alt="Deepgram speech-to-text project structure"></p>
<h3 id="the-python-imports">The Python Imports</h3>
<p>Let\u2019s open the file <code is:raw>transcribe-with-deepgram.py</code> and add the following imports:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> collections </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Counter</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib.ticker </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> MaxNLocator</span></span></code></pre>
<ul>
<li><code is:raw>import asyncio</code> helps with writing asynchronous code in Python with the <code is:raw>async</code> and <code is:raw>await</code> keywords.</li>
<li><code is:raw>import os</code> helps working with files and directories.</li>
<li><code is:raw>from collections import Counter</code> helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.</li>
<li><code is:raw>from deepgram import Deepgram</code> allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.</li>
<li><code is:raw>from dotenv import load_dotenv</code> reads the key/value pairs from the <code is:raw>.env</code> file and sets them as environment variables.</li>
<li><code is:raw>from matplotlib import pyplot as plt</code> creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.</li>
<li><code is:raw>from matplotlib.ticker import MaxNLocator</code> helps provide the graph with friendly integer tick values.</li>
</ul>
<h3 id="the-python-globals">The Python Globals</h3>
<p>Let\u2019s add this code underneath the imports:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.getenv(</span><span style="color: #A5D6FF">&#39;DEEPGRAM_API_KEY&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">files </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [filename </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> filename </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> os.listdir() </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> filename.endswith(</span><span style="color: #A5D6FF">&#39;.wav&#39;</span><span style="color: #C9D1D9">)]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">words_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span></code></pre>
<p>The first line <code is:raw>load_dotenv()</code> loads the environment variables from the <code is:raw>.env</code> file and makes them available in the project.</p>
<p>This line <code is:raw>DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')</code> uses <code is:raw>os.getenv()</code> to return the value of the environment variable key, if it exists, and sets it to a variable.</p>
<p>The <code is:raw>files</code> variable holds all of the files in our directory that end in <code is:raw>wav</code> as we loop through each, indicated by the list comprehension <code is:raw>[filename for filename in os.listdir() if filename.endswith('.wav')]</code>.</p>
<p>Finally, an empty list called <code is:raw>words_list</code> is created, storing the words extracted from the JSON response Deepgram returns.</p>
<h3 id="get-the-deepgram-speech-to-text-transcript">Get the Deepgram Speech-to-Text Transcript</h3>
<p>Let\u2019s add our first function to the <code is:raw>transcribe-with-deepgram.py</code> file.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_transcript</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    words_count </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Counter()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">            source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">            response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">                get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">                    word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                    words_list.append(word)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">        words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<p>Here <code is:raw>deepgram = Deepgram(DEEPGRAM_API_KEY)</code> Deepgram is initialized by providing the API Key from variable <code is:raw>DEEPGRAM_API_KEY</code> below the imports.</p>
<p><code is:raw>words_count = Counter()</code> creates a <code is:raw>Counter</code> object that holds key/value pairs of the words spoken in the transcript and how many times they appear.</p>
<p>In the below code snippet, we iterate through the <code is:raw>.wav</code> audio files in our directory and open each one. The source is set to a dictionary with the <code is:raw>buffer</code> value as <code is:raw>audio</code> and <code is:raw>mimetype</code> as <code is:raw>audio/wav</code>. If we were using <code is:raw>.mp3</code> files the <code is:raw>mimetype</code> would be <code is:raw>audio/mp3</code>. The next line is where the actual Deepgram transcription happens with the pre-recorded audio <code is:raw>await deepgram.transcription.prerecorded(source, {'punctuate': True})</code>. Notice the <code is:raw>source</code> is passed in along with a dictionary <code is:raw>{'punctuate': True}</code>, which is a Deepgram feature that adds punctuation and capitalization to the transcript.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p>To get the words from the transcript, let\u2019s check the JSON response object for <code is:raw>results</code>. Then we loop through the response and parse it to find each word in the transcript and append it to our list called <code is:raw>words_list</code> that was defined earlier.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">    get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">        word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">        words_list.append(word)</span></span></code></pre>
<p>In the last part of the function, we take our <code is:raw>words_count</code> Counter and create a list comprehension that appends all the words in the list <code is:raw>words_list</code> with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, <code is:raw>return words_count</code> returns it, so it\u2019s accessible outside our function when we need it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<h3 id="data-visualization-with-matplotlib">Data Visualization with Matplotlib</h3>
<p>Let\u2019s look at turning transcripts into data visualizations by creating a function called <code is:raw>get_graph()</code>.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_graph</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> get_transcript()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(words.keys()))</span></span>
<span class="line"><span style="color: #C9D1D9">    width </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.35</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    fig, ax </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>A lot is going on in this function, so let\u2019s simplify it by looking at the code in bigger chunks.</p>
<p>Let\u2019s get the returned value of <code is:raw>words_count</code> from the previous function by creating a new object <code is:raw>words = await get_transcript()</code>.</p>
<p>The code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the <code is:raw>word</code> object. Then it places each in the chart.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span></code></pre>
<p>Lastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. <code is:raw>plt.show()</code> will display the bar graph.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>Now, run the project by going to a command line prompt in the terminal and type:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">python3 transcribe-with-deepgram.py</span></span></code></pre>
<p>A beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png" alt="Deepgram speech-to-text transcript with matplotlib data visualization dashboard"></p>
<h2 id="conclusion-of-deepgram-speech-to-text-with-python-and-matplotlib">Conclusion of Deepgram Speech-to-Text with Python and Matplotlib</h2>
<p>There are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it\u2019s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at <a href="https://twitter.com/DeepgramDevs">@deepgramdevs</a>. We would love to hear from you!</p>` }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/python-graphing-transcripts/index.md" };
function rawContent() {
  return "240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.\n\nIt\u2019s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they\u2019re having an emergency?\n\nThe answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let's see why these two technologies are a perfect match.\n\n## What is Deepgram?\n\n\u200B\u200BDeepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You\u2019ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.\n\nWe offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including [FastAPI](https://blog.deepgram.com/live-transcription-fastapi/), [Flask](https://blog.deepgram.com/live-transcription-flask/), [Django](https://blog.deepgram.com/live-transcription-django/), and [Quart](https://blog.deepgram.com/live-transcription-quart/).\n\n## The Deepgram Python SDK Project With Matplotlib Visualization\n\nNow that you have a better understanding of Deepgram, let\u2019s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let\u2019s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.\n\n## Setting Up the Deepgram Speech-to-Text Python Project\n\nBefore we start, it\u2019s essential to generate a Deepgram API key to use in our project. We can go to the [Deepgram Console](https://console.deepgram.com/signup?jump=keys). We'll make sure to copy it and keep it in a safe place, as we won\u2019t be able to retrieve it again and will have to create a new one. In this tutorial, we\u2019ll use Python 3.10, but Deepgram supports some earlier versions of Python.\n\nNext, we'll make a directory anywhere we\u2019d like.\n\n```\nmkdir deepgram-dashboard\n```\n\nThen we'll change into that directory to start adding things to it.\n\n```\ncd deepgram-dashboard\n```\n\nWe\u2019ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those [here](https://blog.deepgram.com/python-virtual-environments/) and how to create one. It\u2019s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.\nWe need to ensure the virtual environment is activated because we\u2019ll install dependencies inside. If the virtual environment is named `venv`, we'll need to activate it.\n\n```\nsource venv/bin/activate\n```\n\nWe'll install the dependencies for the project by running the below `pip` installs from the terminal inside the virtual environment.\n\n```\npip install deepgram-sdk\npip install python-dotenv\npip install matplotlib\n```\n\nWe now can open up an editor and create an environment variable file to store the Deepgram API Key from the [Deepgram Console](https://console.deepgram.com/). Create a new file called `.env` at the project level and add the following Python environment variable, replacing `[YOUR_API_KEY]` with the API Key from the console:\n\n```\nDEEPGRAM_API_KEY=\u201D[YOUR_API_KEY]\u201D\n```\n\nLastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for [Apple](https://apps.apple.com/us/app/pcm-recorder-lite/id439572045) or [Android](https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&hl=en_US&gl=US). This app will create `.wav`audio files but please note that Deepgram supports over [100+ audio formats and encodings](https://developers.deepgram.com/documentation/getting-started/audio-formats/).\n\n## The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing\n\nNow to the fun part! Let\u2019s create a file called `transcribe-with-deepgram.py`, which holds all of the code in this project.\n\nThe project structure looks like this:\n\n![Deepgram speech-to-text project structure](https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png)\n\n### The Python Imports\n\nLet\u2019s open the file `transcribe-with-deepgram.py` and add the following imports:\n\n```python\nimport asyncio\nimport os\nfrom collections import Counter\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom matplotlib import pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n```\n\n* `import asyncio` helps with writing asynchronous code in Python with the `async` and `await` keywords.\n* `import os` helps working with files and directories.\n* `from collections import Counter` helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.\n* `from deepgram import Deepgram` allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.\n* `from dotenv import load_dotenv` reads the key/value pairs from the `.env` file and sets them as environment variables.\n* `from matplotlib import pyplot as plt` creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.\n* `from matplotlib.ticker import MaxNLocator` helps provide the graph with friendly integer tick values.\n\n### The Python Globals\n\nLet\u2019s add this code underneath the imports:\n\n```python\nload_dotenv()\n\nDEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')\n\nfiles = [filename for filename in os.listdir() if filename.endswith('.wav')]\n\nwords_list = []\n```\n\nThe first line `load_dotenv()` loads the environment variables from the `.env` file and makes them available in the project.\n\nThis line `DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')` uses `os.getenv()` to return the value of the environment variable key, if it exists, and sets it to a variable.\n\nThe `files` variable holds all of the files in our directory that end in `wav` as we loop through each, indicated by the list comprehension `[filename for filename in os.listdir() if filename.endswith('.wav')]`.\n\nFinally, an empty list called `words_list` is created, storing the words extracted from the JSON response Deepgram returns.\n\n### Get the Deepgram Speech-to-Text Transcript\n\nLet\u2019s add our first function to the `transcribe-with-deepgram.py` file.\n\n```python\nasync def get_transcript():\n    deepgram = Deepgram(DEEPGRAM_API_KEY)\n\n    words_count = Counter()\n\n    for file in files:\n        with open(file, 'rb') as audio:\n            source = {'buffer': audio, 'mimetype': 'audio/wav'}\n            response = await deepgram.transcription.prerecorded(source, {'punctuate': True})\n\n            if 'results' in response:\n                get_words = response['results']['channels'][0]['alternatives'][0]['words']\n                for words in get_words:\n                    word = words['word']\n                    words_list.append(word)\n\n\n        words_count += Counter([w.lower() for w in words_list if w.lower() not in ['a', 'the', 'is', 'this', 'i', 'to', 'and']])\n\n    return words_count\n```\n\nHere `deepgram = Deepgram(DEEPGRAM_API_KEY)` Deepgram is initialized by providing the API Key from variable `DEEPGRAM_API_KEY` below the imports.\n\n`words_count = Counter()` creates a `Counter` object that holds key/value pairs of the words spoken in the transcript and how many times they appear.\n\nIn the below code snippet, we iterate through the `.wav` audio files in our directory and open each one. The source is set to a dictionary with the `buffer` value as `audio` and `mimetype` as `audio/wav`. If we were using `.mp3` files the `mimetype` would be `audio/mp3`. The next line is where the actual Deepgram transcription happens with the pre-recorded audio `await deepgram.transcription.prerecorded(source, {'punctuate': True})`. Notice the `source` is passed in along with a dictionary `{'punctuate': True}`, which is a Deepgram feature that adds punctuation and capitalization to the transcript.\n\n```python\nfor file in files:\n    with open(file, 'rb') as audio:\n        source = {'buffer': audio, 'mimetype': 'audio/wav'}\n        response = await deepgram.transcription.prerecorded(source, {'punctuate': True)\n```\n\nTo get the words from the transcript, let\u2019s check the JSON response object for `results`. Then we loop through the response and parse it to find each word in the transcript and append it to our list called `words_list` that was defined earlier.\n\n```python\nif 'results' in response:\n    get_words = response['results']['channels'][0]['alternatives'][0]['words']\n    for words in get_words:\n        word = words['word']\n        words_list.append(word)\n```\n\nIn the last part of the function, we take our `words_count` Counter and create a list comprehension that appends all the words in the list `words_list` with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, `return words_count` returns it, so it\u2019s accessible outside our function when we need it.\n\n```python\nwords_count += Counter([w.lower() for w in words_list if w.lower() not in ['a', 'the', 'is', 'this', 'i', 'to', 'and']])\n\nreturn words_count\n```\n\n### Data Visualization with Matplotlib\n\nLet\u2019s look at turning transcripts into data visualizations by creating a function called `get_graph()`.\n\n```python\nasync def get_graph():\n    words = await get_transcript()\n\n    x = range(len(words.keys()))\n    width = 0.35\n\n    fig, ax = plt.subplots()\n\n    ax.set_ylabel('Word Count')\n    ax.set_xlabel('Emergency Call Types')\n    ax.set_title('Deepgram Transcript')\n    ax.set_xticks(x)\n    ax.set_xticklabels(words.keys())\n    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n\n    pps = ax.bar([i - width/2 for i in x], words.values(), width, label='words')\n    for p in pps:\n        height = p.get_height()\n        ax.annotate('{}'.format(height),\n            xy=(p.get_x() + p.get_width() / 2, height),\n            xytext=(0, 3),\n            textcoords='offset points',\n            ha='center', va='bottom')\n\n    plt.show()\n```\n\nA lot is going on in this function, so let\u2019s simplify it by looking at the code in bigger chunks.\n\nLet\u2019s get the returned value of `words_count` from the previous function by creating a new object `words = await get_transcript()`.\n\nThe code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the `word` object. Then it places each in the chart.\n\n```python\nax.set_ylabel('Word Count')\nax.set_xlabel('Emergency Call Types')\nax.set_title('Deepgram Transcript')\nax.set_xticks(x)\nax.set_xticklabels(words.keys())\nax.yaxis.set_major_locator(MaxNLocator(integer=True))\n```\n\nLastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. `plt.show()` will display the bar graph.\n\n```python\npps = ax.bar([i - width/2 for i in x], words.values(), width, label='words')\n\n    for p in pps:\n        height = p.get_height()\n        ax.annotate('{}'.format(height),\n            xy=(p.get_x() + p.get_width() / 2, height),\n            xytext=(0, 3),\n            textcoords='offset points',\n            ha='center', va='bottom')\n\n    plt.show()\n```\n\nNow, run the project by going to a command line prompt in the terminal and type:\n\n```\npython3 transcribe-with-deepgram.py\n```\n\nA beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):\n\n![Deepgram speech-to-text transcript with matplotlib data visualization dashboard](https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png)\n\n## Conclusion of Deepgram Speech-to-Text with Python and Matplotlib\n\nThere are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it\u2019s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at [@deepgramdevs](https://twitter.com/DeepgramDevs). We would love to hear from you!";
}
function compiledContent() {
  return `<p>240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.</p>
<p>It\u2019s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they\u2019re having an emergency?</p>
<p>The answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let\u2019s see why these two technologies are a perfect match.</p>
<h2 id="what-is-deepgram">What is Deepgram?</h2>
<p>\u200B\u200BDeepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You\u2019ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.</p>
<p>We offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including <a href="https://blog.deepgram.com/live-transcription-fastapi/">FastAPI</a>, <a href="https://blog.deepgram.com/live-transcription-flask/">Flask</a>, <a href="https://blog.deepgram.com/live-transcription-django/">Django</a>, and <a href="https://blog.deepgram.com/live-transcription-quart/">Quart</a>.</p>
<h2 id="the-deepgram-python-sdk-project-with-matplotlib-visualization">The Deepgram Python SDK Project With Matplotlib Visualization</h2>
<p>Now that you have a better understanding of Deepgram, let\u2019s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let\u2019s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.</p>
<h2 id="setting-up-the-deepgram-speech-to-text-python-project">Setting Up the Deepgram Speech-to-Text Python Project</h2>
<p>Before we start, it\u2019s essential to generate a Deepgram API key to use in our project. We can go to the <a href="https://console.deepgram.com/signup?jump=keys">Deepgram Console</a>. We\u2019ll make sure to copy it and keep it in a safe place, as we won\u2019t be able to retrieve it again and will have to create a new one. In this tutorial, we\u2019ll use Python 3.10, but Deepgram supports some earlier versions of Python.</p>
<p>Next, we\u2019ll make a directory anywhere we\u2019d like.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">mkdir deepgram-dashboard</span></span></code></pre>
<p>Then we\u2019ll change into that directory to start adding things to it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">cd deepgram-dashboard</span></span></code></pre>
<p>We\u2019ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those <a href="https://blog.deepgram.com/python-virtual-environments/">here</a> and how to create one. It\u2019s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.
We need to ensure the virtual environment is activated because we\u2019ll install dependencies inside. If the virtual environment is named <code is:raw>venv</code>, we\u2019ll need to activate it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">source venv/bin/activate</span></span></code></pre>
<p>We\u2019ll install the dependencies for the project by running the below <code is:raw>pip</code> installs from the terminal inside the virtual environment.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>
<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>
<span class="line"><span style="color: #c9d1d9">pip install matplotlib</span></span></code></pre>
<p>We now can open up an editor and create an environment variable file to store the Deepgram API Key from the <a href="https://console.deepgram.com/">Deepgram Console</a>. Create a new file called <code is:raw>.env</code> at the project level and add the following Python environment variable, replacing <code is:raw>[YOUR_API_KEY]</code> with the API Key from the console:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_API_KEY=\u201D[YOUR_API_KEY]\u201D</span></span></code></pre>
<p>Lastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for <a href="https://apps.apple.com/us/app/pcm-recorder-lite/id439572045">Apple</a> or <a href="https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&#x26;hl=en_US&#x26;gl=US">Android</a>. This app will create <code is:raw>.wav</code>audio files but please note that Deepgram supports over <a href="https://developers.deepgram.com/documentation/getting-started/audio-formats/">100+ audio formats and encodings</a>.</p>
<h2 id="the-code-for-the-deepgram-speech-to-text-python-project-with-matplotlib-graphing">The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing</h2>
<p>Now to the fun part! Let\u2019s create a file called <code is:raw>transcribe-with-deepgram.py</code>, which holds all of the code in this project.</p>
<p>The project structure looks like this:</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png" alt="Deepgram speech-to-text project structure"></p>
<h3 id="the-python-imports">The Python Imports</h3>
<p>Let\u2019s open the file <code is:raw>transcribe-with-deepgram.py</code> and add the following imports:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> collections </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Counter</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib.ticker </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> MaxNLocator</span></span></code></pre>
<ul>
<li><code is:raw>import asyncio</code> helps with writing asynchronous code in Python with the <code is:raw>async</code> and <code is:raw>await</code> keywords.</li>
<li><code is:raw>import os</code> helps working with files and directories.</li>
<li><code is:raw>from collections import Counter</code> helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.</li>
<li><code is:raw>from deepgram import Deepgram</code> allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.</li>
<li><code is:raw>from dotenv import load_dotenv</code> reads the key/value pairs from the <code is:raw>.env</code> file and sets them as environment variables.</li>
<li><code is:raw>from matplotlib import pyplot as plt</code> creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.</li>
<li><code is:raw>from matplotlib.ticker import MaxNLocator</code> helps provide the graph with friendly integer tick values.</li>
</ul>
<h3 id="the-python-globals">The Python Globals</h3>
<p>Let\u2019s add this code underneath the imports:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.getenv(</span><span style="color: #A5D6FF">&#39;DEEPGRAM_API_KEY&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">files </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [filename </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> filename </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> os.listdir() </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> filename.endswith(</span><span style="color: #A5D6FF">&#39;.wav&#39;</span><span style="color: #C9D1D9">)]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">words_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span></code></pre>
<p>The first line <code is:raw>load_dotenv()</code> loads the environment variables from the <code is:raw>.env</code> file and makes them available in the project.</p>
<p>This line <code is:raw>DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')</code> uses <code is:raw>os.getenv()</code> to return the value of the environment variable key, if it exists, and sets it to a variable.</p>
<p>The <code is:raw>files</code> variable holds all of the files in our directory that end in <code is:raw>wav</code> as we loop through each, indicated by the list comprehension <code is:raw>[filename for filename in os.listdir() if filename.endswith('.wav')]</code>.</p>
<p>Finally, an empty list called <code is:raw>words_list</code> is created, storing the words extracted from the JSON response Deepgram returns.</p>
<h3 id="get-the-deepgram-speech-to-text-transcript">Get the Deepgram Speech-to-Text Transcript</h3>
<p>Let\u2019s add our first function to the <code is:raw>transcribe-with-deepgram.py</code> file.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_transcript</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    words_count </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Counter()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">            source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">            response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">                get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">                    word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                    words_list.append(word)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">        words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<p>Here <code is:raw>deepgram = Deepgram(DEEPGRAM_API_KEY)</code> Deepgram is initialized by providing the API Key from variable <code is:raw>DEEPGRAM_API_KEY</code> below the imports.</p>
<p><code is:raw>words_count = Counter()</code> creates a <code is:raw>Counter</code> object that holds key/value pairs of the words spoken in the transcript and how many times they appear.</p>
<p>In the below code snippet, we iterate through the <code is:raw>.wav</code> audio files in our directory and open each one. The source is set to a dictionary with the <code is:raw>buffer</code> value as <code is:raw>audio</code> and <code is:raw>mimetype</code> as <code is:raw>audio/wav</code>. If we were using <code is:raw>.mp3</code> files the <code is:raw>mimetype</code> would be <code is:raw>audio/mp3</code>. The next line is where the actual Deepgram transcription happens with the pre-recorded audio <code is:raw>await deepgram.transcription.prerecorded(source, {'punctuate': True})</code>. Notice the <code is:raw>source</code> is passed in along with a dictionary <code is:raw>{'punctuate': True}</code>, which is a Deepgram feature that adds punctuation and capitalization to the transcript.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p>To get the words from the transcript, let\u2019s check the JSON response object for <code is:raw>results</code>. Then we loop through the response and parse it to find each word in the transcript and append it to our list called <code is:raw>words_list</code> that was defined earlier.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">    get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">        word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">        words_list.append(word)</span></span></code></pre>
<p>In the last part of the function, we take our <code is:raw>words_count</code> Counter and create a list comprehension that appends all the words in the list <code is:raw>words_list</code> with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, <code is:raw>return words_count</code> returns it, so it\u2019s accessible outside our function when we need it.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<h3 id="data-visualization-with-matplotlib">Data Visualization with Matplotlib</h3>
<p>Let\u2019s look at turning transcripts into data visualizations by creating a function called <code is:raw>get_graph()</code>.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_graph</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> get_transcript()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(words.keys()))</span></span>
<span class="line"><span style="color: #C9D1D9">    width </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.35</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    fig, ax </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>A lot is going on in this function, so let\u2019s simplify it by looking at the code in bigger chunks.</p>
<p>Let\u2019s get the returned value of <code is:raw>words_count</code> from the previous function by creating a new object <code is:raw>words = await get_transcript()</code>.</p>
<p>The code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the <code is:raw>word</code> object. Then it places each in the chart.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span></code></pre>
<p>Lastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. <code is:raw>plt.show()</code> will display the bar graph.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>Now, run the project by going to a command line prompt in the terminal and type:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">python3 transcribe-with-deepgram.py</span></span></code></pre>
<p>A beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png" alt="Deepgram speech-to-text transcript with matplotlib data visualization dashboard"></p>
<h2 id="conclusion-of-deepgram-speech-to-text-with-python-and-matplotlib">Conclusion of Deepgram Speech-to-Text with Python and Matplotlib</h2>
<p>There are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it\u2019s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at <a href="https://twitter.com/DeepgramDevs">@deepgramdevs</a>. We would love to hear from you!</p>`;
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/python-graphing-transcripts/index.md", "https://blog.deepgram.com/", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>240 million emergency 911 calls are made in the United States per year. That averages out to roughly 600,000 calls per day. However, many of those calls are not emergencies. First responders often respond to barking dog complaints when people in need could use those resources.</p>
<p>It’s estimated that nearly 10,000 lives could be saved every year if emergency response times were reduced by one minute. Is there a way to visualize emergency calls by their type? Can we analyze the result and measure how to limit wasting resources on non-emergencies? Can we help increase the well-being of others when they’re having an emergency?</p>
<p>The answers are Yes, Yes, and Yes! We can combine speech-to-text using Deepgram and turn transcripts into data visualizations using a Python package like Matplotlib. Let’s see why these two technologies are a perfect match.</p>
<h2 id="what-is-deepgram">What is Deepgram?</h2>
<p>​​Deepgram is an automated speech recognition voice-to-text company that allows you to build applications that transcribe speech-to-text. You’ll receive an actual transcript of the person speaking or a conversation between multiple people. One of the many reasons to choose Deepgram over other providers is that we build better voice applications with faster, more accurate transcription through AI Speech Recognition.</p>
<p>We offer real-time transcription and pre-recorded speech-to-text. The latter allows uploading of a file that contains audio voice data to be transcribed. We recently published a few blog posts on using our Python SDK to do live transcription with some of the most popular Python web frameworks, including <a href="https://blog.deepgram.com/live-transcription-fastapi/">FastAPI</a>, <a href="https://blog.deepgram.com/live-transcription-flask/">Flask</a>, <a href="https://blog.deepgram.com/live-transcription-django/">Django</a>, and <a href="https://blog.deepgram.com/live-transcription-quart/">Quart</a>.</p>
<h2 id="the-deepgram-python-sdk-project-with-matplotlib-visualization">The Deepgram Python SDK Project With Matplotlib Visualization</h2>
<p>Now that you have a better understanding of Deepgram, let’s see how we can use the Deepgram speech-to-text Python SDK to turn transcripts into data visualizations with a package like Matplotlib. In the following project, let’s transcribe pre-recorded audio with Deepgram and use a bar graph to analyze the types of emergency calls and how many of those calls are received.</p>
<h2 id="setting-up-the-deepgram-speech-to-text-python-project">Setting Up the Deepgram Speech-to-Text Python Project</h2>
<p>Before we start, it’s essential to generate a Deepgram API key to use in our project. We can go to the <a href="https://console.deepgram.com/signup?jump=keys">Deepgram Console</a>. We’ll make sure to copy it and keep it in a safe place, as we won’t be able to retrieve it again and will have to create a new one. In this tutorial, we’ll use Python 3.10, but Deepgram supports some earlier versions of Python.</p>
<p>Next, we’ll make a directory anywhere we’d like.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">mkdir deepgram-dashboard</span></span></code></pre>
<p>Then we’ll change into that directory to start adding things to it.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">cd deepgram-dashboard</span></span></code></pre>
<p>We’ll also need to set up a virtual environment to hold the project and its dependencies. We can read more about those <a href="https://blog.deepgram.com/python-virtual-environments/">here</a> and how to create one. It’s recommended in Python to use a virtual environment so the project can be installed inside a container rather than installing it system-wide.
We need to ensure the virtual environment is activated because we’ll install dependencies inside. If the virtual environment is named <code>venv</code>, we’ll need to activate it.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">source venv/bin/activate</span></span></code></pre>
<p>We’ll install the dependencies for the project by running the below <code>pip</code> installs from the terminal inside the virtual environment.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>
<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>
<span class="line"><span style="color: #c9d1d9">pip install matplotlib</span></span></code></pre>
<p>We now can open up an editor and create an environment variable file to store the Deepgram API Key from the <a href="https://console.deepgram.com/">Deepgram Console</a>. Create a new file called <code>.env</code> at the project level and add the following Python environment variable, replacing <code>[YOUR_API_KEY]</code> with the API Key from the console:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_API_KEY=”[YOUR_API_KEY]”</span></span></code></pre>
<p>Lastly, files with audio need to be added to the project so Deepgram can transcribe them. This project uses small audio-created samples using the PCM recorder lite for <a href="https://apps.apple.com/us/app/pcm-recorder-lite/id439572045">Apple</a> or <a href="https://play.google.com/store/apps/details?id=com.kohei.android.pcmrecorder&hl=en_US&gl=US">Android</a>. This app will create <code>.wav</code>audio files but please note that Deepgram supports over <a href="https://developers.deepgram.com/documentation/getting-started/audio-formats/">100+ audio formats and encodings</a>.</p>
<h2 id="the-code-for-the-deepgram-speech-to-text-python-project-with-matplotlib-graphing">The Code for the Deepgram Speech-to-Text Python Project with Matplotlib Graphing</h2>
<p>Now to the fun part! Let’s create a file called <code>transcribe-with-deepgram.py</code>, which holds all of the code in this project.</p>
<p>The project structure looks like this:</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286550/blog/2022/05/python-graphing-transcripts/deepgram-project.png" alt="Deepgram speech-to-text project structure"></p>
<h3 id="the-python-imports">The Python Imports</h3>
<p>Let’s open the file <code>transcribe-with-deepgram.py</code> and add the following imports:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> collections </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Counter</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> matplotlib.ticker </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> MaxNLocator</span></span></code></pre>
<ul>
<li><code>import asyncio</code> helps with writing asynchronous code in Python with the <code>async</code> and <code>await</code> keywords.</li>
<li><code>import os</code> helps working with files and directories.</li>
<li><code>from collections import Counter</code> helps to count key/value pairs in an object which is needed to track the words from the transcript and how many times they were spoken.</li>
<li><code>from deepgram import Deepgram</code> allows access to the Deepgram Python SDK and its types like pre-recorded and live streaming transcription.</li>
<li><code>from dotenv import load_dotenv</code> reads the key/value pairs from the <code>.env</code> file and sets them as environment variables.</li>
<li><code>from matplotlib import pyplot as plt</code> creates a figure, a plotting area in a figure, plots some lines in a plotting area and decorates the plot with labels.</li>
<li><code>from matplotlib.ticker import MaxNLocator</code> helps provide the graph with friendly integer tick values.</li>
</ul>
<h3 id="the-python-globals">The Python Globals</h3>
<p>Let’s add this code underneath the imports:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.getenv(</span><span style="color: #A5D6FF">&#39;DEEPGRAM_API_KEY&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">files </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [filename </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> filename </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> os.listdir() </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> filename.endswith(</span><span style="color: #A5D6FF">&#39;.wav&#39;</span><span style="color: #C9D1D9">)]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">words_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span></code></pre>
<p>The first line <code>load_dotenv()</code> loads the environment variables from the <code>.env</code> file and makes them available in the project.</p>
<p>This line <code>DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')</code> uses <code>os.getenv()</code> to return the value of the environment variable key, if it exists, and sets it to a variable.</p>
<p>The <code>files</code> variable holds all of the files in our directory that end in <code>wav</code> as we loop through each, indicated by the list comprehension <code>[filename for filename in os.listdir() if filename.endswith('.wav')]</code>.</p>
<p>Finally, an empty list called <code>words_list</code> is created, storing the words extracted from the JSON response Deepgram returns.</p>
<h3 id="get-the-deepgram-speech-to-text-transcript">Get the Deepgram Speech-to-Text Transcript</h3>
<p>Let’s add our first function to the <code>transcribe-with-deepgram.py</code> file.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_transcript</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    words_count </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Counter()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">            source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">            response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">                get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">                    word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                    words_list.append(word)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">        words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<p>Here <code>deepgram = Deepgram(DEEPGRAM_API_KEY)</code> Deepgram is initialized by providing the API Key from variable <code>DEEPGRAM_API_KEY</code> below the imports.</p>
<p><code>words_count = Counter()</code> creates a <code>Counter</code> object that holds key/value pairs of the words spoken in the transcript and how many times they appear.</p>
<p>In the below code snippet, we iterate through the <code>.wav</code> audio files in our directory and open each one. The source is set to a dictionary with the <code>buffer</code> value as <code>audio</code> and <code>mimetype</code> as <code>audio/wav</code>. If we were using <code>.mp3</code> files the <code>mimetype</code> would be <code>audio/mp3</code>. The next line is where the actual Deepgram transcription happens with the pre-recorded audio <code>await deepgram.transcription.prerecorded(source, {'punctuate': True})</code>. Notice the <code>source</code> is passed in along with a dictionary <code>{'punctuate': True}</code>, which is a Deepgram feature that adds punctuation and capitalization to the transcript.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> </span><span style="color: #FFA657">file</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> files:</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #FFA657">file</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p>To get the words from the transcript, let’s check the JSON response object for <code>results</code>. Then we loop through the response and parse it to find each word in the transcript and append it to our list called <code>words_list</code> that was defined earlier.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response:</span></span>
<span class="line"><span style="color: #C9D1D9">    get_words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> words </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> get_words:</span></span>
<span class="line"><span style="color: #C9D1D9">        word </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> words[</span><span style="color: #A5D6FF">&#39;word&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">        words_list.append(word)</span></span></code></pre>
<p>In the last part of the function, we take our <code>words_count</code> Counter and create a list comprehension that appends all the words in the list <code>words_list</code> with counts. For example, it will have key/value pairs with each word from the transcript and how many times they appeared. The last line, <code>return words_count</code> returns it, so it’s accessible outside our function when we need it.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">words_count </span><span style="color: #FF7B72">+=</span><span style="color: #C9D1D9"> Counter([w.lower() </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> w </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words_list </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> w.lower() </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> [</span><span style="color: #A5D6FF">&#39;a&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;the&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;is&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;this&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;i&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;to&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;and&#39;</span><span style="color: #C9D1D9">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> words_count</span></span></code></pre>
<h3 id="data-visualization-with-matplotlib">Data Visualization with Matplotlib</h3>
<p>Let’s look at turning transcripts into data visualizations by creating a function called <code>get_graph()</code>.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_graph</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> get_transcript()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(words.keys()))</span></span>
<span class="line"><span style="color: #C9D1D9">    width </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.35</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    fig, ax </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">    ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>A lot is going on in this function, so let’s simplify it by looking at the code in bigger chunks.</p>
<p>Let’s get the returned value of <code>words_count</code> from the previous function by creating a new object <code>words = await get_transcript()</code>.</p>
<p>The code below sets the labels on the x and y-axis, sets the title of the bar graph, and grabs the keys. The keys are the words in the transcript from the <code>word</code> object. Then it places each in the chart.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">ax.set_ylabel(</span><span style="color: #A5D6FF">&#39;Word Count&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xlabel(</span><span style="color: #A5D6FF">&#39;Emergency Call Types&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_title(</span><span style="color: #A5D6FF">&#39;Deepgram Transcript&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticks(x)</span></span>
<span class="line"><span style="color: #C9D1D9">ax.set_xticklabels(words.keys())</span></span>
<span class="line"><span style="color: #C9D1D9">ax.yaxis.set_major_locator(MaxNLocator(</span><span style="color: #FFA657">integer</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">))</span></span></code></pre>
<p>Lastly, we get the exact word count above each bar in the graph, loop through the graph, and create the height and width of the bars. <code>plt.show()</code> will display the bar graph.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">pps </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ax.bar([i </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> width</span><span style="color: #FF7B72">/</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x], words.values(), width, </span><span style="color: #FFA657">label</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> p </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> pps:</span></span>
<span class="line"><span style="color: #C9D1D9">        height </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.get_height()</span></span>
<span class="line"><span style="color: #C9D1D9">        ax.annotate(</span><span style="color: #A5D6FF">&#39;</span><span style="color: #79C0FF">{}</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9">.format(height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xy</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(p.get_x() </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> p.get_width() </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, height),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">xytext</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">textcoords</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;offset points&#39;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">            </span><span style="color: #FFA657">ha</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;center&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">va</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;bottom&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    plt.show()</span></span></code></pre>
<p>Now, run the project by going to a command line prompt in the terminal and type:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">python3 transcribe-with-deepgram.py</span></span></code></pre>
<p>A beautiful bar graph with Deepgram Python speech-to-text transcription and Matplotlib data visualization will get generated and look something like this (depending on the audio files used):</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1652286552/blog/2022/05/python-graphing-transcripts/deepgram-transcript-with-matplotlib.png" alt="Deepgram speech-to-text transcript with matplotlib data visualization dashboard"></p>
<h2 id="conclusion-of-deepgram-speech-to-text-with-python-and-matplotlib">Conclusion of Deepgram Speech-to-Text with Python and Matplotlib</h2>
<p>There are many other use cases for why one might want to use Python with Deepgram for voice-to-text transcription and data visualization. This project is just an example, and it’s encouraged to continue brainstorming innovative and game-changing ideas for speech-to-text and graphing. Can you think of other use cases for Deepgram and our Python SDK? To let us know, you can Tweet us at <a href="https://twitter.com/DeepgramDevs">@deepgramdevs</a>. We would love to hear from you!</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/python-graphing-transcripts/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
