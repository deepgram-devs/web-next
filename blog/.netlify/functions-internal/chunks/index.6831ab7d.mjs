import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           */import '@storyblok/js';
/* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import 'camelcase';
import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [], "source": "*This is the transcript for \u201CAccuracy Matters: Improving Speech Recognition Through Data Processes,\u201D presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.*\xA0\n\n*The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0**94% accurate.**\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0[contact us](https://deepgram.com/contact-us/).*\n\n\\[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy\u2026 or better say, the lack of accuracy. And when I speak about accuracy, I\u2019m not only speaking about the word error rate.\n\nI\u2019m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.\n\nBut, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users\u2026 or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat\u2026 allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.\n\nFor example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It\u2019s related also to to the distance to the microphone. It\u2019s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it\u2019s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don\u2019t need to define\u2026 to design a UI to perform this kind of task. They don\u2019t need to design a workflow. They don\u2019t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate\u2026 will filtrate the correct utterances, and we\u2019ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come\u2026 can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be\u2026 fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I\u2026 I\u2019m the last one on the stage today, and brevity is a\u2026 is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we\u2026 not only we\u2019ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.", "html": '<p><em>This is the transcript for \u201CAccuracy Matters: Improving Speech Recognition Through Data Processes,\u201D presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.</em>\xA0</p>\n<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0<strong>94% accurate.</strong>\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>\n<p>[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy\u2026 or better say, the lack of accuracy. And when I speak about accuracy, I\u2019m not only speaking about the word error rate.</p>\n<p>I\u2019m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.</p>\n<p>But, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users\u2026 or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat\u2026 allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.</p>\n<p>For example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It\u2019s related also to to the distance to the microphone. It\u2019s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it\u2019s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don\u2019t need to define\u2026 to design a UI to perform this kind of task. They don\u2019t need to design a workflow. They don\u2019t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate\u2026 will filtrate the correct utterances, and we\u2019ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come\u2026 can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be\u2026 fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I\u2026 I\u2019m the last one on the stage today, and brevity is a\u2026 is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we\u2026 not only we\u2019ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.</p>' };
const frontmatter = { "title": "Accuracy Matters: Improving Speech Recognition Through Data Processes - Esteban Gorupicz, CEO, Atexto- Project Voice X", "description": "Accuracy Matters: Improving Speech Recognition Through Data Processes presented by Esteban Gorupicz, CEO of Atexto, presented on day one of Project Voice X.\xA0", "date": "2021-12-09T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661981396/blog/accuracy-matters-improving-speech-recognition-through-data-processes-esteban-gorupicz-ceo-atexto-project-voice-x/proj-voice-x-session-esteban-gorupicz-blog-thumb-5.png", "authors": ["claudia-ring"], "category": "speech-trends", "tags": ["accuracy", "project-voice-x"], "seo": { "title": "Accuracy Matters: Improving Speech Recognition Through Data Processes - Esteban Gorupicz, CEO, Atexto- Project Voice X", "description": "Accuracy Matters: Improving Speech Recognition Through Data Processes presented by Esteban Gorupicz, CEO of Atexto, presented on day one of Project Voice X.\xA0" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661981396/blog/accuracy-matters-improving-speech-recognition-through-data-processes-esteban-gorupicz-ceo-atexto-project-voice-x/proj-voice-x-session-esteban-gorupicz-blog-thumb-5.png" }, "shorturls": { "share": "https://dpgr.am/8ecf923", "twitter": "https://dpgr.am/2b2ddce", "linkedin": "https://dpgr.am/55a483e", "reddit": "https://dpgr.am/220264b", "facebook": "https://dpgr.am/a79aaba" }, "astro": { "headings": [], "source": "*This is the transcript for \u201CAccuracy Matters: Improving Speech Recognition Through Data Processes,\u201D presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.*\xA0\n\n*The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0**94% accurate.**\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0[contact us](https://deepgram.com/contact-us/).*\n\n\\[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy\u2026 or better say, the lack of accuracy. And when I speak about accuracy, I\u2019m not only speaking about the word error rate.\n\nI\u2019m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.\n\nBut, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users\u2026 or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat\u2026 allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.\n\nFor example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It\u2019s related also to to the distance to the microphone. It\u2019s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it\u2019s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don\u2019t need to define\u2026 to design a UI to perform this kind of task. They don\u2019t need to design a workflow. They don\u2019t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate\u2026 will filtrate the correct utterances, and we\u2019ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come\u2026 can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be\u2026 fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I\u2026 I\u2019m the last one on the stage today, and brevity is a\u2026 is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we\u2026 not only we\u2019ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.", "html": '<p><em>This is the transcript for \u201CAccuracy Matters: Improving Speech Recognition Through Data Processes,\u201D presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.</em>\xA0</p>\n<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0<strong>94% accurate.</strong>\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>\n<p>[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy\u2026 or better say, the lack of accuracy. And when I speak about accuracy, I\u2019m not only speaking about the word error rate.</p>\n<p>I\u2019m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.</p>\n<p>But, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users\u2026 or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat\u2026 allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.</p>\n<p>For example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It\u2019s related also to to the distance to the microphone. It\u2019s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it\u2019s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don\u2019t need to define\u2026 to design a UI to perform this kind of task. They don\u2019t need to design a workflow. They don\u2019t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate\u2026 will filtrate the correct utterances, and we\u2019ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come\u2026 can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be\u2026 fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I\u2026 I\u2019m the last one on the stage today, and brevity is a\u2026 is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we\u2026 not only we\u2019ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/accuracy-matters-improving-speech-recognition-through-data-processes-esteban-gorupicz-ceo-atexto-project-voice-x/index.md" };
function rawContent() {
  return "*This is the transcript for \u201CAccuracy Matters: Improving Speech Recognition Through Data Processes,\u201D presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.*\xA0\n\n*The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0**94% accurate.**\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0[contact us](https://deepgram.com/contact-us/).*\n\n\\[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy\u2026 or better say, the lack of accuracy. And when I speak about accuracy, I\u2019m not only speaking about the word error rate.\n\nI\u2019m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.\n\nBut, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users\u2026 or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat\u2026 allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.\n\nFor example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It\u2019s related also to to the distance to the microphone. It\u2019s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it\u2019s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don\u2019t need to define\u2026 to design a UI to perform this kind of task. They don\u2019t need to design a workflow. They don\u2019t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate\u2026 will filtrate the correct utterances, and we\u2019ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come\u2026 can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be\u2026 fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I\u2026 I\u2019m the last one on the stage today, and brevity is a\u2026 is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we\u2026 not only we\u2019ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.";
}
function compiledContent() {
  return '<p><em>This is the transcript for \u201CAccuracy Matters: Improving Speech Recognition Through Data Processes,\u201D presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.</em>\xA0</p>\n<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0<strong>94% accurate.</strong>\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>\n<p>[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy\u2026 or better say, the lack of accuracy. And when I speak about accuracy, I\u2019m not only speaking about the word error rate.</p>\n<p>I\u2019m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.</p>\n<p>But, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users\u2026 or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat\u2026 allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.</p>\n<p>For example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It\u2019s related also to to the distance to the microphone. It\u2019s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it\u2019s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don\u2019t need to define\u2026 to design a UI to perform this kind of task. They don\u2019t need to design a workflow. They don\u2019t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate\u2026 will filtrate the correct utterances, and we\u2019ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come\u2026 can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be\u2026 fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I\u2026 I\u2019m the last one on the stage today, and brevity is a\u2026 is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we\u2026 not only we\u2019ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/accuracy-matters-improving-speech-recognition-through-data-processes-esteban-gorupicz-ceo-atexto-project-voice-x/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p><em>This is the transcript for “Accuracy Matters: Improving Speech Recognition Through Data Processes,” presented by Esteban Gorupicz, CEO at Atexto, presented on day one of Project Voice X.</em> </p>
<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was <strong>94% accurate.</strong>  Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram’s API.  If you want to see if Deepgram is right for your use case, <a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>
<p>[Esteban Gorupicz:] Hi, everyone. I am Esteban Gorupicz, founder and CEO of Atexto. Let me introduce myself. I started to work with speech processing technologies fifteen years ago and with crowd sourcing technologies, and I founded Atexto four years ago to help companies solve the main problem related to voice technologies adoption worldwide. That is the problem of accuracy… or better say, the lack of accuracy. And when I speak about accuracy, I’m not only speaking about the word error rate.</p>
<p>I’m talking about bias or fairness and also talking about language support. And these kind of problems are the ones our company is trying to solve, and to do that, we built a software platform that is code free, tool website for machine learning teams, for data science teams, to help them visualize, label, and collect speech training data faster. For example, related to labeling speech, we are the only platform that allows data managers to label, not only text, but also sounds in recordings. And these teams can do it by themself.</p>
<p>But, also, we have a crowdsourcing facility, a crowdsourcing platform fully automated with more than one point five million users… or rather registered from more than fifty countries to perform micro-tasks related to annotation speech, annotation text, audio transcription to build curated datasets to train machine learning models and improve the accuracy of these kind of products. Also, through our data manager platform, data managers can run voice data collection projects, and they can, for example, select the country of residents of the people they need to repeat… allow different training phrases, pronouncing brands, pronouncing product names, and and this kind of information. And they can select their mother tongue, their country of residents, the gender distribution, also the kind of frequency they need for the recordings.</p>
<p>For example, as you know, if you need data to train a speech recognition model for a call center, you need recordings from from the telephone. That is not only related to an eight kilohertz frequency. It’s related also to to the distance to the microphone. It’s very important to to better train the model, but they can select a collection project utilizing a a desktop computer where you can utilize another kind of microphone, and it’s useful for for voice assistance in the car, for example. The the cool thing about our platform is our clients don’t need to define… to design a UI to perform this kind of task. They don’t need to design a workflow. They don’t need to set up golden questions, consensus algorithms to curate the information, to curate the the data we are collecting. They only need to provide the prompt. Our users will pronounce, and our software will curate… will filtrate the correct utterances, and we’ll send to to our clients only the best ones. Also, we have another module that is a ASR benchmark module where you can run experiments to measure the word error rate, but also token error rate related to punctuation, related to capitalization, inverse text normalization. And you can come… can compare different brands of your own speech recognition engine against the main vendors that is Amazon Transcribe, IBM Watson, Google, and and all all of them, not only by recording, but also by gender, by age, by ethnic origin. So our platform are helping big companies to measure the fairness of the the voice-based products they are releasing to production environments in a way to be… fairness with all of their clients, and that that is a a very important thing, I think. The last, I I will be very, very brief because I… I’m the last one on the stage today, and brevity is a… is the soul of wit. We are helping our clients, and this is very important for us, to feel their own long-term defensibilities around data. We ambition a future where every company will be a voice-based company. And in this future world, we not only accelerate, we… not only we’ll accelerate the voice technology adoption, we also democratize this kind of technology for every company. This is our vision. This is Atexto. Thank you for hearing me. Thank you.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/accuracy-matters-improving-speech-recognition-through-data-processes-esteban-gorupicz-ceo-atexto-project-voice-x/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
