import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           *//* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "what-is-reinforcement-learning", "text": "What is Reinforcement Learning?" }, { "depth": 2, "slug": "what-is-reinforcement-learning-good-at", "text": "What is Reinforcement Learning good at?" }, { "depth": 2, "slug": "what-is-supervised-learning", "text": "What is supervised learning?" }, { "depth": 2, "slug": "lets-talk-datasets", "text": "Let\u2019s talk datasets" }, { "depth": 2, "slug": "what-is-semi-supervised-learning", "text": "What is semi-supervised learning?" }, { "depth": 2, "slug": "machine-learning-in-business", "text": "Machine learning in business" }, { "depth": 2, "slug": "what-are-the-different-types-of-data-what-do-you-do-with-it", "text": "What are the different types of data? What do you do with it?" }, { "depth": 2, "slug": "dealing-with-data", "text": "Dealing with data" }, { "depth": 2, "slug": "whats-considered-a-large-dataset", "text": "What\u2019s considered a large dataset?" }, { "depth": 2, "slug": "thinking-about-your-task", "text": "Thinking about your task" }, { "depth": 2, "slug": "what-mechanisms-do-humans-have-that-machines-dont", "text": "What mechanisms do humans have that machines don\u2019t?" }, { "depth": 2, "slug": "lets-talk-about-text", "text": "Let\u2019s talk about text" }, { "depth": 2, "slug": "how-do-you-label-data", "text": "How do you label data?" }], "source": `\r
<iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>\r
\r
**Scott**: Welcome to the AI show. Today we're asking a couple big questions. What are those big questions?\r
\r
*   What are the different types of [machine learning](https://en.wikipedia.org/wiki/Machine_learning)?\r
*   What are the different types of data?\r
\r
Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.\r
\r
## What is Reinforcement Learning?\r
\r
**Susan**: [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that's been in the news is [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo). A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.\r
\r
**Scott**: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world's top Go players.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg)](https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html)\r
\r
**Susan**: Another one that's really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you're into this world. If you want to learn more, dig up the [Atari learning environment](http://yavar.naddaf.name/ale/) and start going through a lot of go of code associated with that. It's a phenomenal toolkit for all sorts of stuff, but specifically it's been helping reinforcement learning because these games are a series actions. They lead to reward, a score.\r
\r
**Scott**: So, reinforcement learning is like, "Hey, I'm taking some actions. I can do any number of things, but what I'm trying to do is make some number go up - like my score or my happiness."\r
\r
**Susan**: Exactly. Classically, there isn't just one reward at the end. You can get rewards along the way and the question is, "How do I maximize that in the infinite game? How do I get the biggest payoff throughout time?" It's great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:\r
\r
*   How do I look at the screen?\r
*   What does it mean to do that?\r
*   What parts of that screen are important?\r
*   What do I focus on?\r
\r
There's a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.\r
\r
## What is Reinforcement Learning good at?\r
\r
**Scott**: What kind of problem would you throw at reinforcement learning, say, "Go" and expect it to work?\r
\r
**Susan**: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,\r
\r
*   Trying to find a good path on a map.\r
*   Trying to win one of the thousand Atari games out there.\r
*   Trying to play a game like checkers or chess.\r
\r
You know, the classic, "I take a move, my opponent takes a move, I take a move, my opponent takes a move."\r
\r
**Scott**: So where things are pretty rigid and the actions that you take are known. An act of God isn't going to come in and change something. It's, "Here's your environment, play in it."\r
\r
**Susan**: Basically where there's some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.\r
\r
So, say I have four options in front of me. I choose A and I'm in state _n_ right now. There's some probability based off of the action I choose for what state I'll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what's called the best policy. In other words, given all this information, "What is the best action I should take to get some sort of reward in the end?" But, it sounds dry and academic when you start talking that way. It's a lot better when you say, "Hey, I'm gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?" It's the same thing.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png)](https://en.wikipedia.org/wiki/Pole_Position)\r
\r
**Scott**: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It's getting the input from the screen, it knows what position it's in, and it's trying to make that position number one or make its lap time faster in the game.\r
\r
**Susan**: Exactly, it's great. And going back to the Atari learning environment, when you're trying to frame this as a reinforcement learning problem, you've got to figure out how to identify the state you're in and what actions are available and do those different things.\r
\r
## What is supervised learning?\r
\r
**Susan**: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning), you've got a bunch of labeled, training data. Labeled meaning like "I've got a picture of a cat and I've got right next to it \`cat\`. Every single piece of information I've got has the answer of what it is right next to it.\r
\r
One of the most famous examples that people start off with is the [MNIST](http://yann.lecun.com/exdb/mnist/) handwriting digit recognition.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png)](https://en.wikipedia.org/wiki/MNIST_database)\r
\r
**Scott**: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\. Many different people have written many different digits, but they've all been labeled. So somebody has gone through and said, "A one is a 1 and a five is a 5, and an eight is an 8." It's collections of 28x28 pixels. This was done in the late nineties, but it's a large number, I think sixty thousand images. It's just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, "Yep. That's a two."\r
\r
**Susan**: It's great as an academic set and it was also very useful when it came out for practical things like reading the mail.\r
\r
**Scott**: I think this was actually implemented in the post office in the late nineties.\r
\r
**Susan**: It's awesome because it's small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It's also very easy for you to say, "Oh, that's a one. That's a two." or whatever and kind of see where your model messes up.\r
\r
**Scott**: Yeah you only have to pick from ten. It's not that hard, but there are many different objects in the world for other datasets.\r
\r
## Let's talk datasets\r
\r
**Susan**: [ImageNet](https://en.wikipedia.org/wiki/ImageNet) or [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) is one of my favorites. 10 and 100 there. That one's actually great because you can start off with the simpler world, the 10, and then go to 100.\r
\r
**Scott**: It's a large number of color images. It's the same ones, but they're labeled differently. They're either labeled into ten categories or a hundred categories.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png)](https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855)\r
\r
**Susan**: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.\r
\r
**Scott**: Yeah so you can take the same data and say like, "Okay, I'm going to try for the simple thing: just picking from one of ten, like \`airplane\`, \`car\`, \`animal\`. Things like that." And then maybe the animal would have ten different ones where it's like \`dog\`, \`cat\`,\`lizard\`.\r
\r
**Susan**: That's another great kind of step up because you've got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you've got the answer sitting in front of you. They're not super realistic in the real world. They're well cropped, things are well-sized, everything's exactly the same dimensions. It's great for learning, but the real world has a lot more problems than that.\r
\r
**Scott**: Yeah, not all images are the same size or zoomed in to the same leveling.\r
\r
## What is semi-supervised learning?\r
\r
**Susan**: [Semi-supervised](https://en.wikipedia.org/wiki/Semi-supervised_learning) says, "I have some of the labels and I'm going to use unlabeled data to help me boost my results in some way." Think of audio normalization as an example - I've got a bunch of audio and I'm going to use that to help me normalize background, but I'm really only learning on the subset that I have.\r
\r
**Scott**: You mean like the volume?\r
\r
**Susan**: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.\r
\r
**Scott**: Yeah, to expand on that some more, it's like "Hey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.\r
\r
If you squeeze that down into one number, it can't reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it's been compressed way down so it's not the same size as the original image.\r
\r
This is a traditional [unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning) technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.\r
\r
**Susan**: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.\r
\r
**Scott**: Yeah, so "I see circles here. It's red. I see some texture here." Maybe it's feathers or something. It doesn't even know the idea of feathers, but it knows that it's sort of grouped together. You can use that information later.\r
\r
**Susan**: With every single problem, you're going to find some different way of using unlabeled data to help you out. There isn't some "Oh this is the set way." of doing semi-supervised learning. It's "I found this great semi-supervised technique to help me out in problem _x_." In general, that's the way it goes.\r
\r
"Supervised world, there's a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it's pretty hard to find answers."\r
\r
## Machine learning in business\r
\r
**Scott**: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?\r
\r
You could dream up ways, but is that what people are running right now in order to save money? That's not what they're doing in their business. They're probably using some sort of supervised learning technique.\r
\r
**Susan**: Yeah, the majority of what we're thinking about in the machine learning world is supervised, likely a [deep learning](https://en.wikipedia.org/wiki/Deep_learning) world.\r
\r
**Scott**: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it's almost a hundred percent supervised.\r
\r
**Susan**: Yeah, currently.\r
\r
"As we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that's where most of our data lies."\r
\r
**Scott**: That's how a human learns.\r
\r
**Susan**: Exactly. Humans, we bootstrap.\r
\r
**Scott**: We test the world, we poke.\r
\r
**Susan**: Exactly. Mom and Dad start off by saying, "Apple. Apple. Apple." Later on, _you_ start testing the world by saying, "Apple?"\r
\r
**Scott**: But then you hear somebody with an accent that says "apple" and you can kinda work out from context - _They must mean apple, I'm gonna adjust my [acoustic model](https://en.wikipedia.org/wiki/Acoustic_model)._\r
\r
**Susan**: We start learning more and more and more just by going through the world. That's really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we'll be able to take advantage of huge data sources that are out there.\r
\r
**Scott**: I still think from a pragmatic perspective, if you're a business and you want to tackle some problem using machine learning, you don't start with unsupervised, you don't start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don't even start with deep learning. You start with some tree-based method or something like that.\r
\r
**Susan**: But you definitely have to have data. If you don't understand your problem enough to have a dataset of examples and answers, then you definitely don't understand the problem well enough to train something to figure it out.\r
\r
## What are the different types of data? What do you do with it?\r
\r
**Susan**: Image and audio.\r
\r
**Scott**: Video.\r
\r
**Susan**: Text. Sequences in general.\r
\r
**Scott**: It might be like, "I turned right down this street, I drove this long, I turned left down that street, and Google's trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?" Things like that.\r
\r
**Susan**: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we're definitely blurring what it means to say classes of data anymore. Sure, it's easy to say this is an image, this is video, this is audio, this is whatever.\r
\r
Now we're trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?\r
\r
**Scott**: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you're trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?\r
\r
**Susan**: That's a big challenge on two fronts.\r
\r
First of all, we've got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you're going to probably make your model better.\r
\r
"Focus on useful data that has predictive power. There's this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end."\r
\r
**Scott**: Not necessarily the case. There are other constraints that come into play.\r
\r
## Dealing with data\r
\r
**Susan**: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it's so far that it just never gets there.\r
\r
**Scott**: You're saying don't get data?\r
\r
**Susan**: I'm not saying don't get data. I'm saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.\r
\r
We'll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you're doing to that audio.\r
\r
It's all about getting to a baseline because, in general, a lot of our techniques are really good at saying, "Hey given that something's at this baseline, I can tell you to nudge it up this way or nudge it down that way." But, if the data's coming in down here all the time, it's working really hard just to predict up to the baseline and go above it. It's going to be biased in some way.\r
\r
So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it's a lot easier for your model to nudge it in the right direction and get the right answer.\r
\r
## What's considered a large dataset?\r
\r
**Scott**: MNIST was sixty thousand images. That's not generally considered a large image dataset. It's pretty big. It's good for what it's trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it's nineteen million images labeled into those categories. That's a pretty big dataset, but is it the biggest dataset in the world? No!\r
\r
**Susan**: It's also purely academic right now. When you look at the self-driving car world at the visual information that they're sucking in and the terabytes worth of data that they're processing through their models, that makes nineteen million images seem quaint. They're sucking down large portions of YouTube.\r
\r
**Scott**: They also need data that's segmented. It's not just, "Is there a cat in this image?" It's, "There are three people in this image, I've drawn the outline of the person, I've drawn the shape of the road, I've drawn the traffic light," and things like that. It knows exactly where it is.\r
\r
## Thinking about your task\r
\r
**Scott**: So, you kind have to think about your task, right? If you're choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.\r
\r
If you're choosing from a hundred categories, maybe it's five or ten times that. If you're choosing from a thousand categories, maybe it's another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we're not talking images anymore. We're talking about hours or seconds of labeled audio.\r
\r
**Susan**: That's an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.\r
\r
**Scott**: To get a really good grasp on your one language that you learn from birth it takes probably ten years.\r
\r
**Susan**: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.\r
\r
**Scott**: Maybe tens of thousands of hours of speech that you've heard and in a semi-supervised way.\r
\r
**Susan**: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.\r
\r
**Scott**: You're talking tens to thousands of hours or maybe ten times that. It's all purely supervised as well.\r
\r
So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn't really mastered the language. It's doing pretty well, but it's not mastered. Maybe 10x that, now you're getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.\r
\r
## What mechanisms do humans have that machines don't?\r
\r
**Susan**: What are the mechanisms that allow a human to do that that we you don't have available to us? Is it how we're representing the information? Is it the structure of the model inside? Are we asking the question the right way?\r
\r
This is where speech is such a fun area because there's clearly examples where there are learning algorithms in the world. What's in your head beat the living daylights of what's available on the computer side and that means there's a lot of great, fun play to figure stuff out.\r
\r
**Scott**: Some of it's like tone inflection, things like that, but it's also that you understand the world around you.\r
\r
"I couldn't put the pineapple in the suitcase because it was too small." What does "it" refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.\r
\r
_We_ know, but the machine is kind of like, "Huh?"\r
\r
**Susan**: Yeah, "I saw Grandma." With a handsaw or a power one?\r
\r
**Scott**: Yeah, what was the "saw" here? There's a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.\r
\r
## Let's talk about text\r
\r
**Scott**: Text is huge.\r
\r
**Susan**: It's huge and it's awesome.\r
\r
**Scott**: The web exists. There's tons of textual data all over the place and titles and bodies of blogs are just everywhere.\r
\r
**Susan**: The great thing about text is you can learn so much in so many different fields. It's not just "Oh, we're going to only apply this to translation or only to transcription." You can use text to start learning about some subject matter and help your model in interesting ways with that.\r
\r
Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there's so much and it can be compactly represented comparatively to things.\r
\r
**Scott**: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video's kind of growing, audio's growing, images are going, but text is massive.\r
\r
**Susan**: Yeah you know, "a picture's worth a thousand words." A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There's a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.\r
\r
## How do you label data?\r
\r
**Scott**: Humans do it! You have a bunch of humans that look at images and say, "That is a cat" or they circle the person and say, "That's a person" or they listen to audio and they type out what was said. It's very, very tough work.\r
\r
**Susan**: You know,\r
\r
"There's a lot of people in companies that think, "AI can do that" and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours."\r
\r
**Scott**: Right now there isn't just a, "Here's a ten million dollar check" and get a dataset labeled. It's more like, you're going to be waiting two years or a year or half a year, and you're going to be orchestrating the effort. You have to do it.\r
\r
**Susan**: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you've got, but probably ten, twenty, fifty years from now.\r
`, "html": '<iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" />\n<p><strong>Scott</strong>: Welcome to the AI show. Today we\u2019re asking a couple big questions. What are those big questions?</p>\n<ul>\n<li>What are the different types of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>?</li>\n<li>What are the different types of data?</li>\n</ul>\n<p>Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.</p>\n<h2 id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning</a> is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that\u2019s been in the news is <a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a>. A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.</p>\n<p><strong>Scott</strong>: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world\u2019s top Go players.</p>\n<p><a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg" alt="alt"></a></p>\n<p><strong>Susan</strong>: Another one that\u2019s really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you\u2019re into this world. If you want to learn more, dig up the <a href="http://yavar.naddaf.name/ale/">Atari learning environment</a> and start going through a lot of go of code associated with that. It\u2019s a phenomenal toolkit for all sorts of stuff, but specifically it\u2019s been helping reinforcement learning because these games are a series actions. They lead to reward, a score.</p>\n<p><strong>Scott</strong>: So, reinforcement learning is like, \u201CHey, I\u2019m taking some actions. I can do any number of things, but what I\u2019m trying to do is make some number go up - like my score or my happiness.\u201D</p>\n<p><strong>Susan</strong>: Exactly. Classically, there isn\u2019t just one reward at the end. You can get rewards along the way and the question is, \u201CHow do I maximize that in the infinite game? How do I get the biggest payoff throughout time?\u201D It\u2019s great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:</p>\n<ul>\n<li>How do I look at the screen?</li>\n<li>What does it mean to do that?</li>\n<li>What parts of that screen are important?</li>\n<li>What do I focus on?</li>\n</ul>\n<p>There\u2019s a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.</p>\n<h2 id="what-is-reinforcement-learning-good-at">What is Reinforcement Learning good at?</h2>\n<p><strong>Scott</strong>: What kind of problem would you throw at reinforcement learning, say, \u201CGo\u201D and expect it to work?</p>\n<p><strong>Susan</strong>: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,</p>\n<ul>\n<li>Trying to find a good path on a map.</li>\n<li>Trying to win one of the thousand Atari games out there.</li>\n<li>Trying to play a game like checkers or chess.</li>\n</ul>\n<p>You know, the classic, \u201CI take a move, my opponent takes a move, I take a move, my opponent takes a move.\u201D</p>\n<p><strong>Scott</strong>: So where things are pretty rigid and the actions that you take are known. An act of God isn\u2019t going to come in and change something. It\u2019s, \u201CHere\u2019s your environment, play in it.\u201D</p>\n<p><strong>Susan</strong>: Basically where there\u2019s some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.</p>\n<p>So, say I have four options in front of me. I choose A and I\u2019m in state <em>n</em> right now. There\u2019s some probability based off of the action I choose for what state I\u2019ll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what\u2019s called the best policy. In other words, given all this information, \u201CWhat is the best action I should take to get some sort of reward in the end?\u201D But, it sounds dry and academic when you start talking that way. It\u2019s a lot better when you say, \u201CHey, I\u2019m gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?\u201D It\u2019s the same thing.</p>\n<p><a href="https://en.wikipedia.org/wiki/Pole_Position"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png" alt="alt"></a></p>\n<p><strong>Scott</strong>: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It\u2019s getting the input from the screen, it knows what position it\u2019s in, and it\u2019s trying to make that position number one or make its lap time faster in the game.</p>\n<p><strong>Susan</strong>: Exactly, it\u2019s great. And going back to the Atari learning environment, when you\u2019re trying to frame this as a reinforcement learning problem, you\u2019ve got to figure out how to identify the state you\u2019re in and what actions are available and do those different things.</p>\n<h2 id="what-is-supervised-learning">What is supervised learning?</h2>\n<p><strong>Susan</strong>: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, you\u2019ve got a bunch of labeled, training data. Labeled meaning like \u201CI\u2019ve got a picture of a cat and I\u2019ve got right next to it <code is:raw>cat</code>. Every single piece of information I\u2019ve got has the answer of what it is right next to it.</p>\n<p>One of the most famous examples that people start off with is the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> handwriting digit recognition.</p>\n<p><a href="https://en.wikipedia.org/wiki/MNIST_database"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png" alt="alt"></a></p>\n<p><strong>Scott</strong>: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Many different people have written many different digits, but they\u2019ve all been labeled. So somebody has gone through and said, \u201CA one is a 1 and a five is a 5, and an eight is an 8.\u201D It\u2019s collections of 28x28 pixels. This was done in the late nineties, but it\u2019s a large number, I think sixty thousand images. It\u2019s just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, \u201CYep. That\u2019s a two.\u201D</p>\n<p><strong>Susan</strong>: It\u2019s great as an academic set and it was also very useful when it came out for practical things like reading the mail.</p>\n<p><strong>Scott</strong>: I think this was actually implemented in the post office in the late nineties.</p>\n<p><strong>Susan</strong>: It\u2019s awesome because it\u2019s small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It\u2019s also very easy for you to say, \u201COh, that\u2019s a one. That\u2019s a two.\u201D or whatever and kind of see where your model messes up.</p>\n<p><strong>Scott</strong>: Yeah you only have to pick from ten. It\u2019s not that hard, but there are many different objects in the world for other datasets.</p>\n<h2 id="lets-talk-datasets">Let\u2019s talk datasets</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> or <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a> is one of my favorites. 10 and 100 there. That one\u2019s actually great because you can start off with the simpler world, the 10, and then go to 100.</p>\n<p><strong>Scott</strong>: It\u2019s a large number of color images. It\u2019s the same ones, but they\u2019re labeled differently. They\u2019re either labeled into ten categories or a hundred categories.</p>\n<p><a href="https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png" alt="alt"></a></p>\n<p><strong>Susan</strong>: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.</p>\n<p><strong>Scott</strong>: Yeah so you can take the same data and say like, \u201COkay, I\u2019m going to try for the simple thing: just picking from one of ten, like <code is:raw>airplane</code>, <code is:raw>car</code>, <code is:raw>animal</code>. Things like that.\u201D And then maybe the animal would have ten different ones where it\u2019s like <code is:raw>dog</code>, <code is:raw>cat</code>,<code is:raw>lizard</code>.</p>\n<p><strong>Susan</strong>: That\u2019s another great kind of step up because you\u2019ve got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you\u2019ve got the answer sitting in front of you. They\u2019re not super realistic in the real world. They\u2019re well cropped, things are well-sized, everything\u2019s exactly the same dimensions. It\u2019s great for learning, but the real world has a lot more problems than that.</p>\n<p><strong>Scott</strong>: Yeah, not all images are the same size or zoomed in to the same leveling.</p>\n<h2 id="what-is-semi-supervised-learning">What is semi-supervised learning?</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Semi-supervised</a> says, \u201CI have some of the labels and I\u2019m going to use unlabeled data to help me boost my results in some way.\u201D Think of audio normalization as an example - I\u2019ve got a bunch of audio and I\u2019m going to use that to help me normalize background, but I\u2019m really only learning on the subset that I have.</p>\n<p><strong>Scott</strong>: You mean like the volume?</p>\n<p><strong>Susan</strong>: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.</p>\n<p><strong>Scott</strong>: Yeah, to expand on that some more, it\u2019s like \u201CHey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.</p>\n<p>If you squeeze that down into one number, it can\u2019t reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it\u2019s been compressed way down so it\u2019s not the same size as the original image.</p>\n<p>This is a traditional <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised</a> technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.</p>\n<p><strong>Susan</strong>: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.</p>\n<p><strong>Scott</strong>: Yeah, so \u201CI see circles here. It\u2019s red. I see some texture here.\u201D Maybe it\u2019s feathers or something. It doesn\u2019t even know the idea of feathers, but it knows that it\u2019s sort of grouped together. You can use that information later.</p>\n<p><strong>Susan</strong>: With every single problem, you\u2019re going to find some different way of using unlabeled data to help you out. There isn\u2019t some \u201COh this is the set way.\u201D of doing semi-supervised learning. It\u2019s \u201CI found this great semi-supervised technique to help me out in problem <em>x</em>.\u201D In general, that\u2019s the way it goes.</p>\n<p>\u201CSupervised world, there\u2019s a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it\u2019s pretty hard to find answers.\u201D</p>\n<h2 id="machine-learning-in-business">Machine learning in business</h2>\n<p><strong>Scott</strong>: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?</p>\n<p>You could dream up ways, but is that what people are running right now in order to save money? That\u2019s not what they\u2019re doing in their business. They\u2019re probably using some sort of supervised learning technique.</p>\n<p><strong>Susan</strong>: Yeah, the majority of what we\u2019re thinking about in the machine learning world is supervised, likely a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> world.</p>\n<p><strong>Scott</strong>: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it\u2019s almost a hundred percent supervised.</p>\n<p><strong>Susan</strong>: Yeah, currently.</p>\n<p>\u201CAs we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that\u2019s where most of our data lies.\u201D</p>\n<p><strong>Scott</strong>: That\u2019s how a human learns.</p>\n<p><strong>Susan</strong>: Exactly. Humans, we bootstrap.</p>\n<p><strong>Scott</strong>: We test the world, we poke.</p>\n<p><strong>Susan</strong>: Exactly. Mom and Dad start off by saying, \u201CApple. Apple. Apple.\u201D Later on, <em>you</em> start testing the world by saying, \u201CApple?\u201D</p>\n<p><strong>Scott</strong>: But then you hear somebody with an accent that says \u201Capple\u201D and you can kinda work out from context - <em>They must mean apple, I\u2019m gonna adjust my <a href="https://en.wikipedia.org/wiki/Acoustic_model">acoustic model</a>.</em></p>\n<p><strong>Susan</strong>: We start learning more and more and more just by going through the world. That\u2019s really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we\u2019ll be able to take advantage of huge data sources that are out there.</p>\n<p><strong>Scott</strong>: I still think from a pragmatic perspective, if you\u2019re a business and you want to tackle some problem using machine learning, you don\u2019t start with unsupervised, you don\u2019t start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don\u2019t even start with deep learning. You start with some tree-based method or something like that.</p>\n<p><strong>Susan</strong>: But you definitely have to have data. If you don\u2019t understand your problem enough to have a dataset of examples and answers, then you definitely don\u2019t understand the problem well enough to train something to figure it out.</p>\n<h2 id="what-are-the-different-types-of-data-what-do-you-do-with-it">What are the different types of data? What do you do with it?</h2>\n<p><strong>Susan</strong>: Image and audio.</p>\n<p><strong>Scott</strong>: Video.</p>\n<p><strong>Susan</strong>: Text. Sequences in general.</p>\n<p><strong>Scott</strong>: It might be like, \u201CI turned right down this street, I drove this long, I turned left down that street, and Google\u2019s trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?\u201D Things like that.</p>\n<p><strong>Susan</strong>: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we\u2019re definitely blurring what it means to say classes of data anymore. Sure, it\u2019s easy to say this is an image, this is video, this is audio, this is whatever.</p>\n<p>Now we\u2019re trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?</p>\n<p><strong>Scott</strong>: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you\u2019re trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?</p>\n<p><strong>Susan</strong>: That\u2019s a big challenge on two fronts.</p>\n<p>First of all, we\u2019ve got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you\u2019re going to probably make your model better.</p>\n<p>\u201CFocus on useful data that has predictive power. There\u2019s this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end.\u201D</p>\n<p><strong>Scott</strong>: Not necessarily the case. There are other constraints that come into play.</p>\n<h2 id="dealing-with-data">Dealing with data</h2>\n<p><strong>Susan</strong>: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it\u2019s so far that it just never gets there.</p>\n<p><strong>Scott</strong>: You\u2019re saying don\u2019t get data?</p>\n<p><strong>Susan</strong>: I\u2019m not saying don\u2019t get data. I\u2019m saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.</p>\n<p>We\u2019ll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you\u2019re doing to that audio.</p>\n<p>It\u2019s all about getting to a baseline because, in general, a lot of our techniques are really good at saying, \u201CHey given that something\u2019s at this baseline, I can tell you to nudge it up this way or nudge it down that way.\u201D But, if the data\u2019s coming in down here all the time, it\u2019s working really hard just to predict up to the baseline and go above it. It\u2019s going to be biased in some way.</p>\n<p>So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it\u2019s a lot easier for your model to nudge it in the right direction and get the right answer.</p>\n<h2 id="whats-considered-a-large-dataset">What\u2019s considered a large dataset?</h2>\n<p><strong>Scott</strong>: MNIST was sixty thousand images. That\u2019s not generally considered a large image dataset. It\u2019s pretty big. It\u2019s good for what it\u2019s trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it\u2019s nineteen million images labeled into those categories. That\u2019s a pretty big dataset, but is it the biggest dataset in the world? No!</p>\n<p><strong>Susan</strong>: It\u2019s also purely academic right now. When you look at the self-driving car world at the visual information that they\u2019re sucking in and the terabytes worth of data that they\u2019re processing through their models, that makes nineteen million images seem quaint. They\u2019re sucking down large portions of YouTube.</p>\n<p><strong>Scott</strong>: They also need data that\u2019s segmented. It\u2019s not just, \u201CIs there a cat in this image?\u201D It\u2019s, \u201CThere are three people in this image, I\u2019ve drawn the outline of the person, I\u2019ve drawn the shape of the road, I\u2019ve drawn the traffic light,\u201D and things like that. It knows exactly where it is.</p>\n<h2 id="thinking-about-your-task">Thinking about your task</h2>\n<p><strong>Scott</strong>: So, you kind have to think about your task, right? If you\u2019re choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.</p>\n<p>If you\u2019re choosing from a hundred categories, maybe it\u2019s five or ten times that. If you\u2019re choosing from a thousand categories, maybe it\u2019s another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we\u2019re not talking images anymore. We\u2019re talking about hours or seconds of labeled audio.</p>\n<p><strong>Susan</strong>: That\u2019s an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.</p>\n<p><strong>Scott</strong>: To get a really good grasp on your one language that you learn from birth it takes probably ten years.</p>\n<p><strong>Susan</strong>: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.</p>\n<p><strong>Scott</strong>: Maybe tens of thousands of hours of speech that you\u2019ve heard and in a semi-supervised way.</p>\n<p><strong>Susan</strong>: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.</p>\n<p><strong>Scott</strong>: You\u2019re talking tens to thousands of hours or maybe ten times that. It\u2019s all purely supervised as well.</p>\n<p>So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn\u2019t really mastered the language. It\u2019s doing pretty well, but it\u2019s not mastered. Maybe 10x that, now you\u2019re getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.</p>\n<h2 id="what-mechanisms-do-humans-have-that-machines-dont">What mechanisms do humans have that machines don\u2019t?</h2>\n<p><strong>Susan</strong>: What are the mechanisms that allow a human to do that that we you don\u2019t have available to us? Is it how we\u2019re representing the information? Is it the structure of the model inside? Are we asking the question the right way?</p>\n<p>This is where speech is such a fun area because there\u2019s clearly examples where there are learning algorithms in the world. What\u2019s in your head beat the living daylights of what\u2019s available on the computer side and that means there\u2019s a lot of great, fun play to figure stuff out.</p>\n<p><strong>Scott</strong>: Some of it\u2019s like tone inflection, things like that, but it\u2019s also that you understand the world around you.</p>\n<p>\u201CI couldn\u2019t put the pineapple in the suitcase because it was too small.\u201D What does \u201Cit\u201D refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.</p>\n<p><em>We</em> know, but the machine is kind of like, \u201CHuh?\u201D</p>\n<p><strong>Susan</strong>: Yeah, \u201CI saw Grandma.\u201D With a handsaw or a power one?</p>\n<p><strong>Scott</strong>: Yeah, what was the \u201Csaw\u201D here? There\u2019s a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.</p>\n<h2 id="lets-talk-about-text">Let\u2019s talk about text</h2>\n<p><strong>Scott</strong>: Text is huge.</p>\n<p><strong>Susan</strong>: It\u2019s huge and it\u2019s awesome.</p>\n<p><strong>Scott</strong>: The web exists. There\u2019s tons of textual data all over the place and titles and bodies of blogs are just everywhere.</p>\n<p><strong>Susan</strong>: The great thing about text is you can learn so much in so many different fields. It\u2019s not just \u201COh, we\u2019re going to only apply this to translation or only to transcription.\u201D You can use text to start learning about some subject matter and help your model in interesting ways with that.</p>\n<p>Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there\u2019s so much and it can be compactly represented comparatively to things.</p>\n<p><strong>Scott</strong>: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video\u2019s kind of growing, audio\u2019s growing, images are going, but text is massive.</p>\n<p><strong>Susan</strong>: Yeah you know, \u201Ca picture\u2019s worth a thousand words.\u201D A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There\u2019s a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.</p>\n<h2 id="how-do-you-label-data">How do you label data?</h2>\n<p><strong>Scott</strong>: Humans do it! You have a bunch of humans that look at images and say, \u201CThat is a cat\u201D or they circle the person and say, \u201CThat\u2019s a person\u201D or they listen to audio and they type out what was said. It\u2019s very, very tough work.</p>\n<p><strong>Susan</strong>: You know,</p>\n<p>\u201CThere\u2019s a lot of people in companies that think, \u201CAI can do that\u201D and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours.\u201D</p>\n<p><strong>Scott</strong>: Right now there isn\u2019t just a, \u201CHere\u2019s a ten million dollar check\u201D and get a dataset labeled. It\u2019s more like, you\u2019re going to be waiting two years or a year or half a year, and you\u2019re going to be orchestrating the effort. You have to do it.</p>\n<p><strong>Susan</strong>: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you\u2019ve got, but probably ten, twenty, fifty years from now.</p>' };
const frontmatter = { "title": "What are the different types of machine learning? - AI Show", "description": "Learn about the different kinds of machine learning in this episode of the AI Show.", "date": "2018-09-15T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661981314/blog/ai-show-different-types-of-machine-learning/what-are-the-different-types-of-machine-learning-b.jpg", "authors": ["scott-stephenson"], "category": "ai-and-engineering", "tags": ["deep-learning"], "seo": { "title": "What are the different types of machine learning? - AI Show", "description": "" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661981314/blog/ai-show-different-types-of-machine-learning/what-are-the-different-types-of-machine-learning-b.jpg" }, "shorturls": { "share": "https://dpgr.am/5c9136c", "twitter": "https://dpgr.am/cd3415f", "linkedin": "https://dpgr.am/b61ac44", "reddit": "https://dpgr.am/af0a17a", "facebook": "https://dpgr.am/4bfcd8a" }, "astro": { "headings": [{ "depth": 2, "slug": "what-is-reinforcement-learning", "text": "What is Reinforcement Learning?" }, { "depth": 2, "slug": "what-is-reinforcement-learning-good-at", "text": "What is Reinforcement Learning good at?" }, { "depth": 2, "slug": "what-is-supervised-learning", "text": "What is supervised learning?" }, { "depth": 2, "slug": "lets-talk-datasets", "text": "Let\u2019s talk datasets" }, { "depth": 2, "slug": "what-is-semi-supervised-learning", "text": "What is semi-supervised learning?" }, { "depth": 2, "slug": "machine-learning-in-business", "text": "Machine learning in business" }, { "depth": 2, "slug": "what-are-the-different-types-of-data-what-do-you-do-with-it", "text": "What are the different types of data? What do you do with it?" }, { "depth": 2, "slug": "dealing-with-data", "text": "Dealing with data" }, { "depth": 2, "slug": "whats-considered-a-large-dataset", "text": "What\u2019s considered a large dataset?" }, { "depth": 2, "slug": "thinking-about-your-task", "text": "Thinking about your task" }, { "depth": 2, "slug": "what-mechanisms-do-humans-have-that-machines-dont", "text": "What mechanisms do humans have that machines don\u2019t?" }, { "depth": 2, "slug": "lets-talk-about-text", "text": "Let\u2019s talk about text" }, { "depth": 2, "slug": "how-do-you-label-data", "text": "How do you label data?" }], "source": `\r
<iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>\r
\r
**Scott**: Welcome to the AI show. Today we're asking a couple big questions. What are those big questions?\r
\r
*   What are the different types of [machine learning](https://en.wikipedia.org/wiki/Machine_learning)?\r
*   What are the different types of data?\r
\r
Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.\r
\r
## What is Reinforcement Learning?\r
\r
**Susan**: [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that's been in the news is [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo). A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.\r
\r
**Scott**: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world's top Go players.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg)](https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html)\r
\r
**Susan**: Another one that's really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you're into this world. If you want to learn more, dig up the [Atari learning environment](http://yavar.naddaf.name/ale/) and start going through a lot of go of code associated with that. It's a phenomenal toolkit for all sorts of stuff, but specifically it's been helping reinforcement learning because these games are a series actions. They lead to reward, a score.\r
\r
**Scott**: So, reinforcement learning is like, "Hey, I'm taking some actions. I can do any number of things, but what I'm trying to do is make some number go up - like my score or my happiness."\r
\r
**Susan**: Exactly. Classically, there isn't just one reward at the end. You can get rewards along the way and the question is, "How do I maximize that in the infinite game? How do I get the biggest payoff throughout time?" It's great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:\r
\r
*   How do I look at the screen?\r
*   What does it mean to do that?\r
*   What parts of that screen are important?\r
*   What do I focus on?\r
\r
There's a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.\r
\r
## What is Reinforcement Learning good at?\r
\r
**Scott**: What kind of problem would you throw at reinforcement learning, say, "Go" and expect it to work?\r
\r
**Susan**: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,\r
\r
*   Trying to find a good path on a map.\r
*   Trying to win one of the thousand Atari games out there.\r
*   Trying to play a game like checkers or chess.\r
\r
You know, the classic, "I take a move, my opponent takes a move, I take a move, my opponent takes a move."\r
\r
**Scott**: So where things are pretty rigid and the actions that you take are known. An act of God isn't going to come in and change something. It's, "Here's your environment, play in it."\r
\r
**Susan**: Basically where there's some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.\r
\r
So, say I have four options in front of me. I choose A and I'm in state _n_ right now. There's some probability based off of the action I choose for what state I'll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what's called the best policy. In other words, given all this information, "What is the best action I should take to get some sort of reward in the end?" But, it sounds dry and academic when you start talking that way. It's a lot better when you say, "Hey, I'm gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?" It's the same thing.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png)](https://en.wikipedia.org/wiki/Pole_Position)\r
\r
**Scott**: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It's getting the input from the screen, it knows what position it's in, and it's trying to make that position number one or make its lap time faster in the game.\r
\r
**Susan**: Exactly, it's great. And going back to the Atari learning environment, when you're trying to frame this as a reinforcement learning problem, you've got to figure out how to identify the state you're in and what actions are available and do those different things.\r
\r
## What is supervised learning?\r
\r
**Susan**: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning), you've got a bunch of labeled, training data. Labeled meaning like "I've got a picture of a cat and I've got right next to it \`cat\`. Every single piece of information I've got has the answer of what it is right next to it.\r
\r
One of the most famous examples that people start off with is the [MNIST](http://yann.lecun.com/exdb/mnist/) handwriting digit recognition.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png)](https://en.wikipedia.org/wiki/MNIST_database)\r
\r
**Scott**: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\. Many different people have written many different digits, but they've all been labeled. So somebody has gone through and said, "A one is a 1 and a five is a 5, and an eight is an 8." It's collections of 28x28 pixels. This was done in the late nineties, but it's a large number, I think sixty thousand images. It's just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, "Yep. That's a two."\r
\r
**Susan**: It's great as an academic set and it was also very useful when it came out for practical things like reading the mail.\r
\r
**Scott**: I think this was actually implemented in the post office in the late nineties.\r
\r
**Susan**: It's awesome because it's small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It's also very easy for you to say, "Oh, that's a one. That's a two." or whatever and kind of see where your model messes up.\r
\r
**Scott**: Yeah you only have to pick from ten. It's not that hard, but there are many different objects in the world for other datasets.\r
\r
## Let's talk datasets\r
\r
**Susan**: [ImageNet](https://en.wikipedia.org/wiki/ImageNet) or [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) is one of my favorites. 10 and 100 there. That one's actually great because you can start off with the simpler world, the 10, and then go to 100.\r
\r
**Scott**: It's a large number of color images. It's the same ones, but they're labeled differently. They're either labeled into ten categories or a hundred categories.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png)](https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855)\r
\r
**Susan**: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.\r
\r
**Scott**: Yeah so you can take the same data and say like, "Okay, I'm going to try for the simple thing: just picking from one of ten, like \`airplane\`, \`car\`, \`animal\`. Things like that." And then maybe the animal would have ten different ones where it's like \`dog\`, \`cat\`,\`lizard\`.\r
\r
**Susan**: That's another great kind of step up because you've got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you've got the answer sitting in front of you. They're not super realistic in the real world. They're well cropped, things are well-sized, everything's exactly the same dimensions. It's great for learning, but the real world has a lot more problems than that.\r
\r
**Scott**: Yeah, not all images are the same size or zoomed in to the same leveling.\r
\r
## What is semi-supervised learning?\r
\r
**Susan**: [Semi-supervised](https://en.wikipedia.org/wiki/Semi-supervised_learning) says, "I have some of the labels and I'm going to use unlabeled data to help me boost my results in some way." Think of audio normalization as an example - I've got a bunch of audio and I'm going to use that to help me normalize background, but I'm really only learning on the subset that I have.\r
\r
**Scott**: You mean like the volume?\r
\r
**Susan**: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.\r
\r
**Scott**: Yeah, to expand on that some more, it's like "Hey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.\r
\r
If you squeeze that down into one number, it can't reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it's been compressed way down so it's not the same size as the original image.\r
\r
This is a traditional [unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning) technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.\r
\r
**Susan**: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.\r
\r
**Scott**: Yeah, so "I see circles here. It's red. I see some texture here." Maybe it's feathers or something. It doesn't even know the idea of feathers, but it knows that it's sort of grouped together. You can use that information later.\r
\r
**Susan**: With every single problem, you're going to find some different way of using unlabeled data to help you out. There isn't some "Oh this is the set way." of doing semi-supervised learning. It's "I found this great semi-supervised technique to help me out in problem _x_." In general, that's the way it goes.\r
\r
"Supervised world, there's a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it's pretty hard to find answers."\r
\r
## Machine learning in business\r
\r
**Scott**: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?\r
\r
You could dream up ways, but is that what people are running right now in order to save money? That's not what they're doing in their business. They're probably using some sort of supervised learning technique.\r
\r
**Susan**: Yeah, the majority of what we're thinking about in the machine learning world is supervised, likely a [deep learning](https://en.wikipedia.org/wiki/Deep_learning) world.\r
\r
**Scott**: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it's almost a hundred percent supervised.\r
\r
**Susan**: Yeah, currently.\r
\r
"As we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that's where most of our data lies."\r
\r
**Scott**: That's how a human learns.\r
\r
**Susan**: Exactly. Humans, we bootstrap.\r
\r
**Scott**: We test the world, we poke.\r
\r
**Susan**: Exactly. Mom and Dad start off by saying, "Apple. Apple. Apple." Later on, _you_ start testing the world by saying, "Apple?"\r
\r
**Scott**: But then you hear somebody with an accent that says "apple" and you can kinda work out from context - _They must mean apple, I'm gonna adjust my [acoustic model](https://en.wikipedia.org/wiki/Acoustic_model)._\r
\r
**Susan**: We start learning more and more and more just by going through the world. That's really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we'll be able to take advantage of huge data sources that are out there.\r
\r
**Scott**: I still think from a pragmatic perspective, if you're a business and you want to tackle some problem using machine learning, you don't start with unsupervised, you don't start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don't even start with deep learning. You start with some tree-based method or something like that.\r
\r
**Susan**: But you definitely have to have data. If you don't understand your problem enough to have a dataset of examples and answers, then you definitely don't understand the problem well enough to train something to figure it out.\r
\r
## What are the different types of data? What do you do with it?\r
\r
**Susan**: Image and audio.\r
\r
**Scott**: Video.\r
\r
**Susan**: Text. Sequences in general.\r
\r
**Scott**: It might be like, "I turned right down this street, I drove this long, I turned left down that street, and Google's trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?" Things like that.\r
\r
**Susan**: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we're definitely blurring what it means to say classes of data anymore. Sure, it's easy to say this is an image, this is video, this is audio, this is whatever.\r
\r
Now we're trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?\r
\r
**Scott**: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you're trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?\r
\r
**Susan**: That's a big challenge on two fronts.\r
\r
First of all, we've got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you're going to probably make your model better.\r
\r
"Focus on useful data that has predictive power. There's this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end."\r
\r
**Scott**: Not necessarily the case. There are other constraints that come into play.\r
\r
## Dealing with data\r
\r
**Susan**: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it's so far that it just never gets there.\r
\r
**Scott**: You're saying don't get data?\r
\r
**Susan**: I'm not saying don't get data. I'm saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.\r
\r
We'll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you're doing to that audio.\r
\r
It's all about getting to a baseline because, in general, a lot of our techniques are really good at saying, "Hey given that something's at this baseline, I can tell you to nudge it up this way or nudge it down that way." But, if the data's coming in down here all the time, it's working really hard just to predict up to the baseline and go above it. It's going to be biased in some way.\r
\r
So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it's a lot easier for your model to nudge it in the right direction and get the right answer.\r
\r
## What's considered a large dataset?\r
\r
**Scott**: MNIST was sixty thousand images. That's not generally considered a large image dataset. It's pretty big. It's good for what it's trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it's nineteen million images labeled into those categories. That's a pretty big dataset, but is it the biggest dataset in the world? No!\r
\r
**Susan**: It's also purely academic right now. When you look at the self-driving car world at the visual information that they're sucking in and the terabytes worth of data that they're processing through their models, that makes nineteen million images seem quaint. They're sucking down large portions of YouTube.\r
\r
**Scott**: They also need data that's segmented. It's not just, "Is there a cat in this image?" It's, "There are three people in this image, I've drawn the outline of the person, I've drawn the shape of the road, I've drawn the traffic light," and things like that. It knows exactly where it is.\r
\r
## Thinking about your task\r
\r
**Scott**: So, you kind have to think about your task, right? If you're choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.\r
\r
If you're choosing from a hundred categories, maybe it's five or ten times that. If you're choosing from a thousand categories, maybe it's another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we're not talking images anymore. We're talking about hours or seconds of labeled audio.\r
\r
**Susan**: That's an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.\r
\r
**Scott**: To get a really good grasp on your one language that you learn from birth it takes probably ten years.\r
\r
**Susan**: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.\r
\r
**Scott**: Maybe tens of thousands of hours of speech that you've heard and in a semi-supervised way.\r
\r
**Susan**: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.\r
\r
**Scott**: You're talking tens to thousands of hours or maybe ten times that. It's all purely supervised as well.\r
\r
So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn't really mastered the language. It's doing pretty well, but it's not mastered. Maybe 10x that, now you're getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.\r
\r
## What mechanisms do humans have that machines don't?\r
\r
**Susan**: What are the mechanisms that allow a human to do that that we you don't have available to us? Is it how we're representing the information? Is it the structure of the model inside? Are we asking the question the right way?\r
\r
This is where speech is such a fun area because there's clearly examples where there are learning algorithms in the world. What's in your head beat the living daylights of what's available on the computer side and that means there's a lot of great, fun play to figure stuff out.\r
\r
**Scott**: Some of it's like tone inflection, things like that, but it's also that you understand the world around you.\r
\r
"I couldn't put the pineapple in the suitcase because it was too small." What does "it" refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.\r
\r
_We_ know, but the machine is kind of like, "Huh?"\r
\r
**Susan**: Yeah, "I saw Grandma." With a handsaw or a power one?\r
\r
**Scott**: Yeah, what was the "saw" here? There's a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.\r
\r
## Let's talk about text\r
\r
**Scott**: Text is huge.\r
\r
**Susan**: It's huge and it's awesome.\r
\r
**Scott**: The web exists. There's tons of textual data all over the place and titles and bodies of blogs are just everywhere.\r
\r
**Susan**: The great thing about text is you can learn so much in so many different fields. It's not just "Oh, we're going to only apply this to translation or only to transcription." You can use text to start learning about some subject matter and help your model in interesting ways with that.\r
\r
Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there's so much and it can be compactly represented comparatively to things.\r
\r
**Scott**: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video's kind of growing, audio's growing, images are going, but text is massive.\r
\r
**Susan**: Yeah you know, "a picture's worth a thousand words." A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There's a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.\r
\r
## How do you label data?\r
\r
**Scott**: Humans do it! You have a bunch of humans that look at images and say, "That is a cat" or they circle the person and say, "That's a person" or they listen to audio and they type out what was said. It's very, very tough work.\r
\r
**Susan**: You know,\r
\r
"There's a lot of people in companies that think, "AI can do that" and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours."\r
\r
**Scott**: Right now there isn't just a, "Here's a ten million dollar check" and get a dataset labeled. It's more like, you're going to be waiting two years or a year or half a year, and you're going to be orchestrating the effort. You have to do it.\r
\r
**Susan**: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you've got, but probably ten, twenty, fifty years from now.\r
`, "html": '<iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" />\n<p><strong>Scott</strong>: Welcome to the AI show. Today we\u2019re asking a couple big questions. What are those big questions?</p>\n<ul>\n<li>What are the different types of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>?</li>\n<li>What are the different types of data?</li>\n</ul>\n<p>Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.</p>\n<h2 id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning</a> is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that\u2019s been in the news is <a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a>. A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.</p>\n<p><strong>Scott</strong>: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world\u2019s top Go players.</p>\n<p><a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg" alt="alt"></a></p>\n<p><strong>Susan</strong>: Another one that\u2019s really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you\u2019re into this world. If you want to learn more, dig up the <a href="http://yavar.naddaf.name/ale/">Atari learning environment</a> and start going through a lot of go of code associated with that. It\u2019s a phenomenal toolkit for all sorts of stuff, but specifically it\u2019s been helping reinforcement learning because these games are a series actions. They lead to reward, a score.</p>\n<p><strong>Scott</strong>: So, reinforcement learning is like, \u201CHey, I\u2019m taking some actions. I can do any number of things, but what I\u2019m trying to do is make some number go up - like my score or my happiness.\u201D</p>\n<p><strong>Susan</strong>: Exactly. Classically, there isn\u2019t just one reward at the end. You can get rewards along the way and the question is, \u201CHow do I maximize that in the infinite game? How do I get the biggest payoff throughout time?\u201D It\u2019s great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:</p>\n<ul>\n<li>How do I look at the screen?</li>\n<li>What does it mean to do that?</li>\n<li>What parts of that screen are important?</li>\n<li>What do I focus on?</li>\n</ul>\n<p>There\u2019s a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.</p>\n<h2 id="what-is-reinforcement-learning-good-at">What is Reinforcement Learning good at?</h2>\n<p><strong>Scott</strong>: What kind of problem would you throw at reinforcement learning, say, \u201CGo\u201D and expect it to work?</p>\n<p><strong>Susan</strong>: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,</p>\n<ul>\n<li>Trying to find a good path on a map.</li>\n<li>Trying to win one of the thousand Atari games out there.</li>\n<li>Trying to play a game like checkers or chess.</li>\n</ul>\n<p>You know, the classic, \u201CI take a move, my opponent takes a move, I take a move, my opponent takes a move.\u201D</p>\n<p><strong>Scott</strong>: So where things are pretty rigid and the actions that you take are known. An act of God isn\u2019t going to come in and change something. It\u2019s, \u201CHere\u2019s your environment, play in it.\u201D</p>\n<p><strong>Susan</strong>: Basically where there\u2019s some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.</p>\n<p>So, say I have four options in front of me. I choose A and I\u2019m in state <em>n</em> right now. There\u2019s some probability based off of the action I choose for what state I\u2019ll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what\u2019s called the best policy. In other words, given all this information, \u201CWhat is the best action I should take to get some sort of reward in the end?\u201D But, it sounds dry and academic when you start talking that way. It\u2019s a lot better when you say, \u201CHey, I\u2019m gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?\u201D It\u2019s the same thing.</p>\n<p><a href="https://en.wikipedia.org/wiki/Pole_Position"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png" alt="alt"></a></p>\n<p><strong>Scott</strong>: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It\u2019s getting the input from the screen, it knows what position it\u2019s in, and it\u2019s trying to make that position number one or make its lap time faster in the game.</p>\n<p><strong>Susan</strong>: Exactly, it\u2019s great. And going back to the Atari learning environment, when you\u2019re trying to frame this as a reinforcement learning problem, you\u2019ve got to figure out how to identify the state you\u2019re in and what actions are available and do those different things.</p>\n<h2 id="what-is-supervised-learning">What is supervised learning?</h2>\n<p><strong>Susan</strong>: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, you\u2019ve got a bunch of labeled, training data. Labeled meaning like \u201CI\u2019ve got a picture of a cat and I\u2019ve got right next to it <code is:raw>cat</code>. Every single piece of information I\u2019ve got has the answer of what it is right next to it.</p>\n<p>One of the most famous examples that people start off with is the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> handwriting digit recognition.</p>\n<p><a href="https://en.wikipedia.org/wiki/MNIST_database"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png" alt="alt"></a></p>\n<p><strong>Scott</strong>: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Many different people have written many different digits, but they\u2019ve all been labeled. So somebody has gone through and said, \u201CA one is a 1 and a five is a 5, and an eight is an 8.\u201D It\u2019s collections of 28x28 pixels. This was done in the late nineties, but it\u2019s a large number, I think sixty thousand images. It\u2019s just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, \u201CYep. That\u2019s a two.\u201D</p>\n<p><strong>Susan</strong>: It\u2019s great as an academic set and it was also very useful when it came out for practical things like reading the mail.</p>\n<p><strong>Scott</strong>: I think this was actually implemented in the post office in the late nineties.</p>\n<p><strong>Susan</strong>: It\u2019s awesome because it\u2019s small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It\u2019s also very easy for you to say, \u201COh, that\u2019s a one. That\u2019s a two.\u201D or whatever and kind of see where your model messes up.</p>\n<p><strong>Scott</strong>: Yeah you only have to pick from ten. It\u2019s not that hard, but there are many different objects in the world for other datasets.</p>\n<h2 id="lets-talk-datasets">Let\u2019s talk datasets</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> or <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a> is one of my favorites. 10 and 100 there. That one\u2019s actually great because you can start off with the simpler world, the 10, and then go to 100.</p>\n<p><strong>Scott</strong>: It\u2019s a large number of color images. It\u2019s the same ones, but they\u2019re labeled differently. They\u2019re either labeled into ten categories or a hundred categories.</p>\n<p><a href="https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png" alt="alt"></a></p>\n<p><strong>Susan</strong>: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.</p>\n<p><strong>Scott</strong>: Yeah so you can take the same data and say like, \u201COkay, I\u2019m going to try for the simple thing: just picking from one of ten, like <code is:raw>airplane</code>, <code is:raw>car</code>, <code is:raw>animal</code>. Things like that.\u201D And then maybe the animal would have ten different ones where it\u2019s like <code is:raw>dog</code>, <code is:raw>cat</code>,<code is:raw>lizard</code>.</p>\n<p><strong>Susan</strong>: That\u2019s another great kind of step up because you\u2019ve got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you\u2019ve got the answer sitting in front of you. They\u2019re not super realistic in the real world. They\u2019re well cropped, things are well-sized, everything\u2019s exactly the same dimensions. It\u2019s great for learning, but the real world has a lot more problems than that.</p>\n<p><strong>Scott</strong>: Yeah, not all images are the same size or zoomed in to the same leveling.</p>\n<h2 id="what-is-semi-supervised-learning">What is semi-supervised learning?</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Semi-supervised</a> says, \u201CI have some of the labels and I\u2019m going to use unlabeled data to help me boost my results in some way.\u201D Think of audio normalization as an example - I\u2019ve got a bunch of audio and I\u2019m going to use that to help me normalize background, but I\u2019m really only learning on the subset that I have.</p>\n<p><strong>Scott</strong>: You mean like the volume?</p>\n<p><strong>Susan</strong>: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.</p>\n<p><strong>Scott</strong>: Yeah, to expand on that some more, it\u2019s like \u201CHey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.</p>\n<p>If you squeeze that down into one number, it can\u2019t reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it\u2019s been compressed way down so it\u2019s not the same size as the original image.</p>\n<p>This is a traditional <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised</a> technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.</p>\n<p><strong>Susan</strong>: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.</p>\n<p><strong>Scott</strong>: Yeah, so \u201CI see circles here. It\u2019s red. I see some texture here.\u201D Maybe it\u2019s feathers or something. It doesn\u2019t even know the idea of feathers, but it knows that it\u2019s sort of grouped together. You can use that information later.</p>\n<p><strong>Susan</strong>: With every single problem, you\u2019re going to find some different way of using unlabeled data to help you out. There isn\u2019t some \u201COh this is the set way.\u201D of doing semi-supervised learning. It\u2019s \u201CI found this great semi-supervised technique to help me out in problem <em>x</em>.\u201D In general, that\u2019s the way it goes.</p>\n<p>\u201CSupervised world, there\u2019s a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it\u2019s pretty hard to find answers.\u201D</p>\n<h2 id="machine-learning-in-business">Machine learning in business</h2>\n<p><strong>Scott</strong>: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?</p>\n<p>You could dream up ways, but is that what people are running right now in order to save money? That\u2019s not what they\u2019re doing in their business. They\u2019re probably using some sort of supervised learning technique.</p>\n<p><strong>Susan</strong>: Yeah, the majority of what we\u2019re thinking about in the machine learning world is supervised, likely a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> world.</p>\n<p><strong>Scott</strong>: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it\u2019s almost a hundred percent supervised.</p>\n<p><strong>Susan</strong>: Yeah, currently.</p>\n<p>\u201CAs we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that\u2019s where most of our data lies.\u201D</p>\n<p><strong>Scott</strong>: That\u2019s how a human learns.</p>\n<p><strong>Susan</strong>: Exactly. Humans, we bootstrap.</p>\n<p><strong>Scott</strong>: We test the world, we poke.</p>\n<p><strong>Susan</strong>: Exactly. Mom and Dad start off by saying, \u201CApple. Apple. Apple.\u201D Later on, <em>you</em> start testing the world by saying, \u201CApple?\u201D</p>\n<p><strong>Scott</strong>: But then you hear somebody with an accent that says \u201Capple\u201D and you can kinda work out from context - <em>They must mean apple, I\u2019m gonna adjust my <a href="https://en.wikipedia.org/wiki/Acoustic_model">acoustic model</a>.</em></p>\n<p><strong>Susan</strong>: We start learning more and more and more just by going through the world. That\u2019s really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we\u2019ll be able to take advantage of huge data sources that are out there.</p>\n<p><strong>Scott</strong>: I still think from a pragmatic perspective, if you\u2019re a business and you want to tackle some problem using machine learning, you don\u2019t start with unsupervised, you don\u2019t start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don\u2019t even start with deep learning. You start with some tree-based method or something like that.</p>\n<p><strong>Susan</strong>: But you definitely have to have data. If you don\u2019t understand your problem enough to have a dataset of examples and answers, then you definitely don\u2019t understand the problem well enough to train something to figure it out.</p>\n<h2 id="what-are-the-different-types-of-data-what-do-you-do-with-it">What are the different types of data? What do you do with it?</h2>\n<p><strong>Susan</strong>: Image and audio.</p>\n<p><strong>Scott</strong>: Video.</p>\n<p><strong>Susan</strong>: Text. Sequences in general.</p>\n<p><strong>Scott</strong>: It might be like, \u201CI turned right down this street, I drove this long, I turned left down that street, and Google\u2019s trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?\u201D Things like that.</p>\n<p><strong>Susan</strong>: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we\u2019re definitely blurring what it means to say classes of data anymore. Sure, it\u2019s easy to say this is an image, this is video, this is audio, this is whatever.</p>\n<p>Now we\u2019re trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?</p>\n<p><strong>Scott</strong>: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you\u2019re trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?</p>\n<p><strong>Susan</strong>: That\u2019s a big challenge on two fronts.</p>\n<p>First of all, we\u2019ve got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you\u2019re going to probably make your model better.</p>\n<p>\u201CFocus on useful data that has predictive power. There\u2019s this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end.\u201D</p>\n<p><strong>Scott</strong>: Not necessarily the case. There are other constraints that come into play.</p>\n<h2 id="dealing-with-data">Dealing with data</h2>\n<p><strong>Susan</strong>: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it\u2019s so far that it just never gets there.</p>\n<p><strong>Scott</strong>: You\u2019re saying don\u2019t get data?</p>\n<p><strong>Susan</strong>: I\u2019m not saying don\u2019t get data. I\u2019m saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.</p>\n<p>We\u2019ll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you\u2019re doing to that audio.</p>\n<p>It\u2019s all about getting to a baseline because, in general, a lot of our techniques are really good at saying, \u201CHey given that something\u2019s at this baseline, I can tell you to nudge it up this way or nudge it down that way.\u201D But, if the data\u2019s coming in down here all the time, it\u2019s working really hard just to predict up to the baseline and go above it. It\u2019s going to be biased in some way.</p>\n<p>So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it\u2019s a lot easier for your model to nudge it in the right direction and get the right answer.</p>\n<h2 id="whats-considered-a-large-dataset">What\u2019s considered a large dataset?</h2>\n<p><strong>Scott</strong>: MNIST was sixty thousand images. That\u2019s not generally considered a large image dataset. It\u2019s pretty big. It\u2019s good for what it\u2019s trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it\u2019s nineteen million images labeled into those categories. That\u2019s a pretty big dataset, but is it the biggest dataset in the world? No!</p>\n<p><strong>Susan</strong>: It\u2019s also purely academic right now. When you look at the self-driving car world at the visual information that they\u2019re sucking in and the terabytes worth of data that they\u2019re processing through their models, that makes nineteen million images seem quaint. They\u2019re sucking down large portions of YouTube.</p>\n<p><strong>Scott</strong>: They also need data that\u2019s segmented. It\u2019s not just, \u201CIs there a cat in this image?\u201D It\u2019s, \u201CThere are three people in this image, I\u2019ve drawn the outline of the person, I\u2019ve drawn the shape of the road, I\u2019ve drawn the traffic light,\u201D and things like that. It knows exactly where it is.</p>\n<h2 id="thinking-about-your-task">Thinking about your task</h2>\n<p><strong>Scott</strong>: So, you kind have to think about your task, right? If you\u2019re choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.</p>\n<p>If you\u2019re choosing from a hundred categories, maybe it\u2019s five or ten times that. If you\u2019re choosing from a thousand categories, maybe it\u2019s another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we\u2019re not talking images anymore. We\u2019re talking about hours or seconds of labeled audio.</p>\n<p><strong>Susan</strong>: That\u2019s an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.</p>\n<p><strong>Scott</strong>: To get a really good grasp on your one language that you learn from birth it takes probably ten years.</p>\n<p><strong>Susan</strong>: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.</p>\n<p><strong>Scott</strong>: Maybe tens of thousands of hours of speech that you\u2019ve heard and in a semi-supervised way.</p>\n<p><strong>Susan</strong>: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.</p>\n<p><strong>Scott</strong>: You\u2019re talking tens to thousands of hours or maybe ten times that. It\u2019s all purely supervised as well.</p>\n<p>So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn\u2019t really mastered the language. It\u2019s doing pretty well, but it\u2019s not mastered. Maybe 10x that, now you\u2019re getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.</p>\n<h2 id="what-mechanisms-do-humans-have-that-machines-dont">What mechanisms do humans have that machines don\u2019t?</h2>\n<p><strong>Susan</strong>: What are the mechanisms that allow a human to do that that we you don\u2019t have available to us? Is it how we\u2019re representing the information? Is it the structure of the model inside? Are we asking the question the right way?</p>\n<p>This is where speech is such a fun area because there\u2019s clearly examples where there are learning algorithms in the world. What\u2019s in your head beat the living daylights of what\u2019s available on the computer side and that means there\u2019s a lot of great, fun play to figure stuff out.</p>\n<p><strong>Scott</strong>: Some of it\u2019s like tone inflection, things like that, but it\u2019s also that you understand the world around you.</p>\n<p>\u201CI couldn\u2019t put the pineapple in the suitcase because it was too small.\u201D What does \u201Cit\u201D refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.</p>\n<p><em>We</em> know, but the machine is kind of like, \u201CHuh?\u201D</p>\n<p><strong>Susan</strong>: Yeah, \u201CI saw Grandma.\u201D With a handsaw or a power one?</p>\n<p><strong>Scott</strong>: Yeah, what was the \u201Csaw\u201D here? There\u2019s a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.</p>\n<h2 id="lets-talk-about-text">Let\u2019s talk about text</h2>\n<p><strong>Scott</strong>: Text is huge.</p>\n<p><strong>Susan</strong>: It\u2019s huge and it\u2019s awesome.</p>\n<p><strong>Scott</strong>: The web exists. There\u2019s tons of textual data all over the place and titles and bodies of blogs are just everywhere.</p>\n<p><strong>Susan</strong>: The great thing about text is you can learn so much in so many different fields. It\u2019s not just \u201COh, we\u2019re going to only apply this to translation or only to transcription.\u201D You can use text to start learning about some subject matter and help your model in interesting ways with that.</p>\n<p>Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there\u2019s so much and it can be compactly represented comparatively to things.</p>\n<p><strong>Scott</strong>: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video\u2019s kind of growing, audio\u2019s growing, images are going, but text is massive.</p>\n<p><strong>Susan</strong>: Yeah you know, \u201Ca picture\u2019s worth a thousand words.\u201D A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There\u2019s a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.</p>\n<h2 id="how-do-you-label-data">How do you label data?</h2>\n<p><strong>Scott</strong>: Humans do it! You have a bunch of humans that look at images and say, \u201CThat is a cat\u201D or they circle the person and say, \u201CThat\u2019s a person\u201D or they listen to audio and they type out what was said. It\u2019s very, very tough work.</p>\n<p><strong>Susan</strong>: You know,</p>\n<p>\u201CThere\u2019s a lot of people in companies that think, \u201CAI can do that\u201D and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours.\u201D</p>\n<p><strong>Scott</strong>: Right now there isn\u2019t just a, \u201CHere\u2019s a ten million dollar check\u201D and get a dataset labeled. It\u2019s more like, you\u2019re going to be waiting two years or a year or half a year, and you\u2019re going to be orchestrating the effort. You have to do it.</p>\n<p><strong>Susan</strong>: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you\u2019ve got, but probably ten, twenty, fifty years from now.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/ai-show-different-types-of-machine-learning/index.md" };
function rawContent() {
  return `\r
<iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>\r
\r
**Scott**: Welcome to the AI show. Today we're asking a couple big questions. What are those big questions?\r
\r
*   What are the different types of [machine learning](https://en.wikipedia.org/wiki/Machine_learning)?\r
*   What are the different types of data?\r
\r
Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.\r
\r
## What is Reinforcement Learning?\r
\r
**Susan**: [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that's been in the news is [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo). A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.\r
\r
**Scott**: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world's top Go players.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg)](https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html)\r
\r
**Susan**: Another one that's really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you're into this world. If you want to learn more, dig up the [Atari learning environment](http://yavar.naddaf.name/ale/) and start going through a lot of go of code associated with that. It's a phenomenal toolkit for all sorts of stuff, but specifically it's been helping reinforcement learning because these games are a series actions. They lead to reward, a score.\r
\r
**Scott**: So, reinforcement learning is like, "Hey, I'm taking some actions. I can do any number of things, but what I'm trying to do is make some number go up - like my score or my happiness."\r
\r
**Susan**: Exactly. Classically, there isn't just one reward at the end. You can get rewards along the way and the question is, "How do I maximize that in the infinite game? How do I get the biggest payoff throughout time?" It's great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:\r
\r
*   How do I look at the screen?\r
*   What does it mean to do that?\r
*   What parts of that screen are important?\r
*   What do I focus on?\r
\r
There's a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.\r
\r
## What is Reinforcement Learning good at?\r
\r
**Scott**: What kind of problem would you throw at reinforcement learning, say, "Go" and expect it to work?\r
\r
**Susan**: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,\r
\r
*   Trying to find a good path on a map.\r
*   Trying to win one of the thousand Atari games out there.\r
*   Trying to play a game like checkers or chess.\r
\r
You know, the classic, "I take a move, my opponent takes a move, I take a move, my opponent takes a move."\r
\r
**Scott**: So where things are pretty rigid and the actions that you take are known. An act of God isn't going to come in and change something. It's, "Here's your environment, play in it."\r
\r
**Susan**: Basically where there's some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.\r
\r
So, say I have four options in front of me. I choose A and I'm in state _n_ right now. There's some probability based off of the action I choose for what state I'll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what's called the best policy. In other words, given all this information, "What is the best action I should take to get some sort of reward in the end?" But, it sounds dry and academic when you start talking that way. It's a lot better when you say, "Hey, I'm gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?" It's the same thing.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png)](https://en.wikipedia.org/wiki/Pole_Position)\r
\r
**Scott**: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It's getting the input from the screen, it knows what position it's in, and it's trying to make that position number one or make its lap time faster in the game.\r
\r
**Susan**: Exactly, it's great. And going back to the Atari learning environment, when you're trying to frame this as a reinforcement learning problem, you've got to figure out how to identify the state you're in and what actions are available and do those different things.\r
\r
## What is supervised learning?\r
\r
**Susan**: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning), you've got a bunch of labeled, training data. Labeled meaning like "I've got a picture of a cat and I've got right next to it \`cat\`. Every single piece of information I've got has the answer of what it is right next to it.\r
\r
One of the most famous examples that people start off with is the [MNIST](http://yann.lecun.com/exdb/mnist/) handwriting digit recognition.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png)](https://en.wikipedia.org/wiki/MNIST_database)\r
\r
**Scott**: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\. Many different people have written many different digits, but they've all been labeled. So somebody has gone through and said, "A one is a 1 and a five is a 5, and an eight is an 8." It's collections of 28x28 pixels. This was done in the late nineties, but it's a large number, I think sixty thousand images. It's just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, "Yep. That's a two."\r
\r
**Susan**: It's great as an academic set and it was also very useful when it came out for practical things like reading the mail.\r
\r
**Scott**: I think this was actually implemented in the post office in the late nineties.\r
\r
**Susan**: It's awesome because it's small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It's also very easy for you to say, "Oh, that's a one. That's a two." or whatever and kind of see where your model messes up.\r
\r
**Scott**: Yeah you only have to pick from ten. It's not that hard, but there are many different objects in the world for other datasets.\r
\r
## Let's talk datasets\r
\r
**Susan**: [ImageNet](https://en.wikipedia.org/wiki/ImageNet) or [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) is one of my favorites. 10 and 100 there. That one's actually great because you can start off with the simpler world, the 10, and then go to 100.\r
\r
**Scott**: It's a large number of color images. It's the same ones, but they're labeled differently. They're either labeled into ten categories or a hundred categories.\r
\r
 [![alt](https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png)](https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855)\r
\r
**Susan**: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.\r
\r
**Scott**: Yeah so you can take the same data and say like, "Okay, I'm going to try for the simple thing: just picking from one of ten, like \`airplane\`, \`car\`, \`animal\`. Things like that." And then maybe the animal would have ten different ones where it's like \`dog\`, \`cat\`,\`lizard\`.\r
\r
**Susan**: That's another great kind of step up because you've got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you've got the answer sitting in front of you. They're not super realistic in the real world. They're well cropped, things are well-sized, everything's exactly the same dimensions. It's great for learning, but the real world has a lot more problems than that.\r
\r
**Scott**: Yeah, not all images are the same size or zoomed in to the same leveling.\r
\r
## What is semi-supervised learning?\r
\r
**Susan**: [Semi-supervised](https://en.wikipedia.org/wiki/Semi-supervised_learning) says, "I have some of the labels and I'm going to use unlabeled data to help me boost my results in some way." Think of audio normalization as an example - I've got a bunch of audio and I'm going to use that to help me normalize background, but I'm really only learning on the subset that I have.\r
\r
**Scott**: You mean like the volume?\r
\r
**Susan**: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.\r
\r
**Scott**: Yeah, to expand on that some more, it's like "Hey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.\r
\r
If you squeeze that down into one number, it can't reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it's been compressed way down so it's not the same size as the original image.\r
\r
This is a traditional [unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning) technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.\r
\r
**Susan**: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.\r
\r
**Scott**: Yeah, so "I see circles here. It's red. I see some texture here." Maybe it's feathers or something. It doesn't even know the idea of feathers, but it knows that it's sort of grouped together. You can use that information later.\r
\r
**Susan**: With every single problem, you're going to find some different way of using unlabeled data to help you out. There isn't some "Oh this is the set way." of doing semi-supervised learning. It's "I found this great semi-supervised technique to help me out in problem _x_." In general, that's the way it goes.\r
\r
"Supervised world, there's a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it's pretty hard to find answers."\r
\r
## Machine learning in business\r
\r
**Scott**: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?\r
\r
You could dream up ways, but is that what people are running right now in order to save money? That's not what they're doing in their business. They're probably using some sort of supervised learning technique.\r
\r
**Susan**: Yeah, the majority of what we're thinking about in the machine learning world is supervised, likely a [deep learning](https://en.wikipedia.org/wiki/Deep_learning) world.\r
\r
**Scott**: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it's almost a hundred percent supervised.\r
\r
**Susan**: Yeah, currently.\r
\r
"As we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that's where most of our data lies."\r
\r
**Scott**: That's how a human learns.\r
\r
**Susan**: Exactly. Humans, we bootstrap.\r
\r
**Scott**: We test the world, we poke.\r
\r
**Susan**: Exactly. Mom and Dad start off by saying, "Apple. Apple. Apple." Later on, _you_ start testing the world by saying, "Apple?"\r
\r
**Scott**: But then you hear somebody with an accent that says "apple" and you can kinda work out from context - _They must mean apple, I'm gonna adjust my [acoustic model](https://en.wikipedia.org/wiki/Acoustic_model)._\r
\r
**Susan**: We start learning more and more and more just by going through the world. That's really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we'll be able to take advantage of huge data sources that are out there.\r
\r
**Scott**: I still think from a pragmatic perspective, if you're a business and you want to tackle some problem using machine learning, you don't start with unsupervised, you don't start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don't even start with deep learning. You start with some tree-based method or something like that.\r
\r
**Susan**: But you definitely have to have data. If you don't understand your problem enough to have a dataset of examples and answers, then you definitely don't understand the problem well enough to train something to figure it out.\r
\r
## What are the different types of data? What do you do with it?\r
\r
**Susan**: Image and audio.\r
\r
**Scott**: Video.\r
\r
**Susan**: Text. Sequences in general.\r
\r
**Scott**: It might be like, "I turned right down this street, I drove this long, I turned left down that street, and Google's trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?" Things like that.\r
\r
**Susan**: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we're definitely blurring what it means to say classes of data anymore. Sure, it's easy to say this is an image, this is video, this is audio, this is whatever.\r
\r
Now we're trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?\r
\r
**Scott**: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you're trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?\r
\r
**Susan**: That's a big challenge on two fronts.\r
\r
First of all, we've got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you're going to probably make your model better.\r
\r
"Focus on useful data that has predictive power. There's this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end."\r
\r
**Scott**: Not necessarily the case. There are other constraints that come into play.\r
\r
## Dealing with data\r
\r
**Susan**: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it's so far that it just never gets there.\r
\r
**Scott**: You're saying don't get data?\r
\r
**Susan**: I'm not saying don't get data. I'm saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.\r
\r
We'll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you're doing to that audio.\r
\r
It's all about getting to a baseline because, in general, a lot of our techniques are really good at saying, "Hey given that something's at this baseline, I can tell you to nudge it up this way or nudge it down that way." But, if the data's coming in down here all the time, it's working really hard just to predict up to the baseline and go above it. It's going to be biased in some way.\r
\r
So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it's a lot easier for your model to nudge it in the right direction and get the right answer.\r
\r
## What's considered a large dataset?\r
\r
**Scott**: MNIST was sixty thousand images. That's not generally considered a large image dataset. It's pretty big. It's good for what it's trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it's nineteen million images labeled into those categories. That's a pretty big dataset, but is it the biggest dataset in the world? No!\r
\r
**Susan**: It's also purely academic right now. When you look at the self-driving car world at the visual information that they're sucking in and the terabytes worth of data that they're processing through their models, that makes nineteen million images seem quaint. They're sucking down large portions of YouTube.\r
\r
**Scott**: They also need data that's segmented. It's not just, "Is there a cat in this image?" It's, "There are three people in this image, I've drawn the outline of the person, I've drawn the shape of the road, I've drawn the traffic light," and things like that. It knows exactly where it is.\r
\r
## Thinking about your task\r
\r
**Scott**: So, you kind have to think about your task, right? If you're choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.\r
\r
If you're choosing from a hundred categories, maybe it's five or ten times that. If you're choosing from a thousand categories, maybe it's another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we're not talking images anymore. We're talking about hours or seconds of labeled audio.\r
\r
**Susan**: That's an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.\r
\r
**Scott**: To get a really good grasp on your one language that you learn from birth it takes probably ten years.\r
\r
**Susan**: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.\r
\r
**Scott**: Maybe tens of thousands of hours of speech that you've heard and in a semi-supervised way.\r
\r
**Susan**: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.\r
\r
**Scott**: You're talking tens to thousands of hours or maybe ten times that. It's all purely supervised as well.\r
\r
So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn't really mastered the language. It's doing pretty well, but it's not mastered. Maybe 10x that, now you're getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.\r
\r
## What mechanisms do humans have that machines don't?\r
\r
**Susan**: What are the mechanisms that allow a human to do that that we you don't have available to us? Is it how we're representing the information? Is it the structure of the model inside? Are we asking the question the right way?\r
\r
This is where speech is such a fun area because there's clearly examples where there are learning algorithms in the world. What's in your head beat the living daylights of what's available on the computer side and that means there's a lot of great, fun play to figure stuff out.\r
\r
**Scott**: Some of it's like tone inflection, things like that, but it's also that you understand the world around you.\r
\r
"I couldn't put the pineapple in the suitcase because it was too small." What does "it" refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.\r
\r
_We_ know, but the machine is kind of like, "Huh?"\r
\r
**Susan**: Yeah, "I saw Grandma." With a handsaw or a power one?\r
\r
**Scott**: Yeah, what was the "saw" here? There's a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.\r
\r
## Let's talk about text\r
\r
**Scott**: Text is huge.\r
\r
**Susan**: It's huge and it's awesome.\r
\r
**Scott**: The web exists. There's tons of textual data all over the place and titles and bodies of blogs are just everywhere.\r
\r
**Susan**: The great thing about text is you can learn so much in so many different fields. It's not just "Oh, we're going to only apply this to translation or only to transcription." You can use text to start learning about some subject matter and help your model in interesting ways with that.\r
\r
Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there's so much and it can be compactly represented comparatively to things.\r
\r
**Scott**: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video's kind of growing, audio's growing, images are going, but text is massive.\r
\r
**Susan**: Yeah you know, "a picture's worth a thousand words." A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There's a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.\r
\r
## How do you label data?\r
\r
**Scott**: Humans do it! You have a bunch of humans that look at images and say, "That is a cat" or they circle the person and say, "That's a person" or they listen to audio and they type out what was said. It's very, very tough work.\r
\r
**Susan**: You know,\r
\r
"There's a lot of people in companies that think, "AI can do that" and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours."\r
\r
**Scott**: Right now there isn't just a, "Here's a ten million dollar check" and get a dataset labeled. It's more like, you're going to be waiting two years or a year or half a year, and you're going to be orchestrating the effort. You have to do it.\r
\r
**Susan**: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you've got, but probably ten, twenty, fifty years from now.\r
`;
}
function compiledContent() {
  return '<iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" />\n<p><strong>Scott</strong>: Welcome to the AI show. Today we\u2019re asking a couple big questions. What are those big questions?</p>\n<ul>\n<li>What are the different types of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>?</li>\n<li>What are the different types of data?</li>\n</ul>\n<p>Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.</p>\n<h2 id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning</a> is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that\u2019s been in the news is <a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a>. A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.</p>\n<p><strong>Scott</strong>: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world\u2019s top Go players.</p>\n<p><a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg" alt="alt"></a></p>\n<p><strong>Susan</strong>: Another one that\u2019s really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you\u2019re into this world. If you want to learn more, dig up the <a href="http://yavar.naddaf.name/ale/">Atari learning environment</a> and start going through a lot of go of code associated with that. It\u2019s a phenomenal toolkit for all sorts of stuff, but specifically it\u2019s been helping reinforcement learning because these games are a series actions. They lead to reward, a score.</p>\n<p><strong>Scott</strong>: So, reinforcement learning is like, \u201CHey, I\u2019m taking some actions. I can do any number of things, but what I\u2019m trying to do is make some number go up - like my score or my happiness.\u201D</p>\n<p><strong>Susan</strong>: Exactly. Classically, there isn\u2019t just one reward at the end. You can get rewards along the way and the question is, \u201CHow do I maximize that in the infinite game? How do I get the biggest payoff throughout time?\u201D It\u2019s great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:</p>\n<ul>\n<li>How do I look at the screen?</li>\n<li>What does it mean to do that?</li>\n<li>What parts of that screen are important?</li>\n<li>What do I focus on?</li>\n</ul>\n<p>There\u2019s a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.</p>\n<h2 id="what-is-reinforcement-learning-good-at">What is Reinforcement Learning good at?</h2>\n<p><strong>Scott</strong>: What kind of problem would you throw at reinforcement learning, say, \u201CGo\u201D and expect it to work?</p>\n<p><strong>Susan</strong>: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,</p>\n<ul>\n<li>Trying to find a good path on a map.</li>\n<li>Trying to win one of the thousand Atari games out there.</li>\n<li>Trying to play a game like checkers or chess.</li>\n</ul>\n<p>You know, the classic, \u201CI take a move, my opponent takes a move, I take a move, my opponent takes a move.\u201D</p>\n<p><strong>Scott</strong>: So where things are pretty rigid and the actions that you take are known. An act of God isn\u2019t going to come in and change something. It\u2019s, \u201CHere\u2019s your environment, play in it.\u201D</p>\n<p><strong>Susan</strong>: Basically where there\u2019s some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.</p>\n<p>So, say I have four options in front of me. I choose A and I\u2019m in state <em>n</em> right now. There\u2019s some probability based off of the action I choose for what state I\u2019ll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what\u2019s called the best policy. In other words, given all this information, \u201CWhat is the best action I should take to get some sort of reward in the end?\u201D But, it sounds dry and academic when you start talking that way. It\u2019s a lot better when you say, \u201CHey, I\u2019m gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?\u201D It\u2019s the same thing.</p>\n<p><a href="https://en.wikipedia.org/wiki/Pole_Position"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png" alt="alt"></a></p>\n<p><strong>Scott</strong>: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It\u2019s getting the input from the screen, it knows what position it\u2019s in, and it\u2019s trying to make that position number one or make its lap time faster in the game.</p>\n<p><strong>Susan</strong>: Exactly, it\u2019s great. And going back to the Atari learning environment, when you\u2019re trying to frame this as a reinforcement learning problem, you\u2019ve got to figure out how to identify the state you\u2019re in and what actions are available and do those different things.</p>\n<h2 id="what-is-supervised-learning">What is supervised learning?</h2>\n<p><strong>Susan</strong>: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, you\u2019ve got a bunch of labeled, training data. Labeled meaning like \u201CI\u2019ve got a picture of a cat and I\u2019ve got right next to it <code is:raw>cat</code>. Every single piece of information I\u2019ve got has the answer of what it is right next to it.</p>\n<p>One of the most famous examples that people start off with is the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> handwriting digit recognition.</p>\n<p><a href="https://en.wikipedia.org/wiki/MNIST_database"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png" alt="alt"></a></p>\n<p><strong>Scott</strong>: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Many different people have written many different digits, but they\u2019ve all been labeled. So somebody has gone through and said, \u201CA one is a 1 and a five is a 5, and an eight is an 8.\u201D It\u2019s collections of 28x28 pixels. This was done in the late nineties, but it\u2019s a large number, I think sixty thousand images. It\u2019s just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, \u201CYep. That\u2019s a two.\u201D</p>\n<p><strong>Susan</strong>: It\u2019s great as an academic set and it was also very useful when it came out for practical things like reading the mail.</p>\n<p><strong>Scott</strong>: I think this was actually implemented in the post office in the late nineties.</p>\n<p><strong>Susan</strong>: It\u2019s awesome because it\u2019s small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It\u2019s also very easy for you to say, \u201COh, that\u2019s a one. That\u2019s a two.\u201D or whatever and kind of see where your model messes up.</p>\n<p><strong>Scott</strong>: Yeah you only have to pick from ten. It\u2019s not that hard, but there are many different objects in the world for other datasets.</p>\n<h2 id="lets-talk-datasets">Let\u2019s talk datasets</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> or <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a> is one of my favorites. 10 and 100 there. That one\u2019s actually great because you can start off with the simpler world, the 10, and then go to 100.</p>\n<p><strong>Scott</strong>: It\u2019s a large number of color images. It\u2019s the same ones, but they\u2019re labeled differently. They\u2019re either labeled into ten categories or a hundred categories.</p>\n<p><a href="https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png" alt="alt"></a></p>\n<p><strong>Susan</strong>: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.</p>\n<p><strong>Scott</strong>: Yeah so you can take the same data and say like, \u201COkay, I\u2019m going to try for the simple thing: just picking from one of ten, like <code is:raw>airplane</code>, <code is:raw>car</code>, <code is:raw>animal</code>. Things like that.\u201D And then maybe the animal would have ten different ones where it\u2019s like <code is:raw>dog</code>, <code is:raw>cat</code>,<code is:raw>lizard</code>.</p>\n<p><strong>Susan</strong>: That\u2019s another great kind of step up because you\u2019ve got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you\u2019ve got the answer sitting in front of you. They\u2019re not super realistic in the real world. They\u2019re well cropped, things are well-sized, everything\u2019s exactly the same dimensions. It\u2019s great for learning, but the real world has a lot more problems than that.</p>\n<p><strong>Scott</strong>: Yeah, not all images are the same size or zoomed in to the same leveling.</p>\n<h2 id="what-is-semi-supervised-learning">What is semi-supervised learning?</h2>\n<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Semi-supervised</a> says, \u201CI have some of the labels and I\u2019m going to use unlabeled data to help me boost my results in some way.\u201D Think of audio normalization as an example - I\u2019ve got a bunch of audio and I\u2019m going to use that to help me normalize background, but I\u2019m really only learning on the subset that I have.</p>\n<p><strong>Scott</strong>: You mean like the volume?</p>\n<p><strong>Susan</strong>: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.</p>\n<p><strong>Scott</strong>: Yeah, to expand on that some more, it\u2019s like \u201CHey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.</p>\n<p>If you squeeze that down into one number, it can\u2019t reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it\u2019s been compressed way down so it\u2019s not the same size as the original image.</p>\n<p>This is a traditional <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised</a> technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.</p>\n<p><strong>Susan</strong>: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.</p>\n<p><strong>Scott</strong>: Yeah, so \u201CI see circles here. It\u2019s red. I see some texture here.\u201D Maybe it\u2019s feathers or something. It doesn\u2019t even know the idea of feathers, but it knows that it\u2019s sort of grouped together. You can use that information later.</p>\n<p><strong>Susan</strong>: With every single problem, you\u2019re going to find some different way of using unlabeled data to help you out. There isn\u2019t some \u201COh this is the set way.\u201D of doing semi-supervised learning. It\u2019s \u201CI found this great semi-supervised technique to help me out in problem <em>x</em>.\u201D In general, that\u2019s the way it goes.</p>\n<p>\u201CSupervised world, there\u2019s a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it\u2019s pretty hard to find answers.\u201D</p>\n<h2 id="machine-learning-in-business">Machine learning in business</h2>\n<p><strong>Scott</strong>: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?</p>\n<p>You could dream up ways, but is that what people are running right now in order to save money? That\u2019s not what they\u2019re doing in their business. They\u2019re probably using some sort of supervised learning technique.</p>\n<p><strong>Susan</strong>: Yeah, the majority of what we\u2019re thinking about in the machine learning world is supervised, likely a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> world.</p>\n<p><strong>Scott</strong>: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it\u2019s almost a hundred percent supervised.</p>\n<p><strong>Susan</strong>: Yeah, currently.</p>\n<p>\u201CAs we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that\u2019s where most of our data lies.\u201D</p>\n<p><strong>Scott</strong>: That\u2019s how a human learns.</p>\n<p><strong>Susan</strong>: Exactly. Humans, we bootstrap.</p>\n<p><strong>Scott</strong>: We test the world, we poke.</p>\n<p><strong>Susan</strong>: Exactly. Mom and Dad start off by saying, \u201CApple. Apple. Apple.\u201D Later on, <em>you</em> start testing the world by saying, \u201CApple?\u201D</p>\n<p><strong>Scott</strong>: But then you hear somebody with an accent that says \u201Capple\u201D and you can kinda work out from context - <em>They must mean apple, I\u2019m gonna adjust my <a href="https://en.wikipedia.org/wiki/Acoustic_model">acoustic model</a>.</em></p>\n<p><strong>Susan</strong>: We start learning more and more and more just by going through the world. That\u2019s really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we\u2019ll be able to take advantage of huge data sources that are out there.</p>\n<p><strong>Scott</strong>: I still think from a pragmatic perspective, if you\u2019re a business and you want to tackle some problem using machine learning, you don\u2019t start with unsupervised, you don\u2019t start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don\u2019t even start with deep learning. You start with some tree-based method or something like that.</p>\n<p><strong>Susan</strong>: But you definitely have to have data. If you don\u2019t understand your problem enough to have a dataset of examples and answers, then you definitely don\u2019t understand the problem well enough to train something to figure it out.</p>\n<h2 id="what-are-the-different-types-of-data-what-do-you-do-with-it">What are the different types of data? What do you do with it?</h2>\n<p><strong>Susan</strong>: Image and audio.</p>\n<p><strong>Scott</strong>: Video.</p>\n<p><strong>Susan</strong>: Text. Sequences in general.</p>\n<p><strong>Scott</strong>: It might be like, \u201CI turned right down this street, I drove this long, I turned left down that street, and Google\u2019s trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?\u201D Things like that.</p>\n<p><strong>Susan</strong>: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we\u2019re definitely blurring what it means to say classes of data anymore. Sure, it\u2019s easy to say this is an image, this is video, this is audio, this is whatever.</p>\n<p>Now we\u2019re trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?</p>\n<p><strong>Scott</strong>: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you\u2019re trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?</p>\n<p><strong>Susan</strong>: That\u2019s a big challenge on two fronts.</p>\n<p>First of all, we\u2019ve got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you\u2019re going to probably make your model better.</p>\n<p>\u201CFocus on useful data that has predictive power. There\u2019s this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end.\u201D</p>\n<p><strong>Scott</strong>: Not necessarily the case. There are other constraints that come into play.</p>\n<h2 id="dealing-with-data">Dealing with data</h2>\n<p><strong>Susan</strong>: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it\u2019s so far that it just never gets there.</p>\n<p><strong>Scott</strong>: You\u2019re saying don\u2019t get data?</p>\n<p><strong>Susan</strong>: I\u2019m not saying don\u2019t get data. I\u2019m saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.</p>\n<p>We\u2019ll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you\u2019re doing to that audio.</p>\n<p>It\u2019s all about getting to a baseline because, in general, a lot of our techniques are really good at saying, \u201CHey given that something\u2019s at this baseline, I can tell you to nudge it up this way or nudge it down that way.\u201D But, if the data\u2019s coming in down here all the time, it\u2019s working really hard just to predict up to the baseline and go above it. It\u2019s going to be biased in some way.</p>\n<p>So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it\u2019s a lot easier for your model to nudge it in the right direction and get the right answer.</p>\n<h2 id="whats-considered-a-large-dataset">What\u2019s considered a large dataset?</h2>\n<p><strong>Scott</strong>: MNIST was sixty thousand images. That\u2019s not generally considered a large image dataset. It\u2019s pretty big. It\u2019s good for what it\u2019s trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it\u2019s nineteen million images labeled into those categories. That\u2019s a pretty big dataset, but is it the biggest dataset in the world? No!</p>\n<p><strong>Susan</strong>: It\u2019s also purely academic right now. When you look at the self-driving car world at the visual information that they\u2019re sucking in and the terabytes worth of data that they\u2019re processing through their models, that makes nineteen million images seem quaint. They\u2019re sucking down large portions of YouTube.</p>\n<p><strong>Scott</strong>: They also need data that\u2019s segmented. It\u2019s not just, \u201CIs there a cat in this image?\u201D It\u2019s, \u201CThere are three people in this image, I\u2019ve drawn the outline of the person, I\u2019ve drawn the shape of the road, I\u2019ve drawn the traffic light,\u201D and things like that. It knows exactly where it is.</p>\n<h2 id="thinking-about-your-task">Thinking about your task</h2>\n<p><strong>Scott</strong>: So, you kind have to think about your task, right? If you\u2019re choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.</p>\n<p>If you\u2019re choosing from a hundred categories, maybe it\u2019s five or ten times that. If you\u2019re choosing from a thousand categories, maybe it\u2019s another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we\u2019re not talking images anymore. We\u2019re talking about hours or seconds of labeled audio.</p>\n<p><strong>Susan</strong>: That\u2019s an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.</p>\n<p><strong>Scott</strong>: To get a really good grasp on your one language that you learn from birth it takes probably ten years.</p>\n<p><strong>Susan</strong>: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.</p>\n<p><strong>Scott</strong>: Maybe tens of thousands of hours of speech that you\u2019ve heard and in a semi-supervised way.</p>\n<p><strong>Susan</strong>: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.</p>\n<p><strong>Scott</strong>: You\u2019re talking tens to thousands of hours or maybe ten times that. It\u2019s all purely supervised as well.</p>\n<p>So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn\u2019t really mastered the language. It\u2019s doing pretty well, but it\u2019s not mastered. Maybe 10x that, now you\u2019re getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.</p>\n<h2 id="what-mechanisms-do-humans-have-that-machines-dont">What mechanisms do humans have that machines don\u2019t?</h2>\n<p><strong>Susan</strong>: What are the mechanisms that allow a human to do that that we you don\u2019t have available to us? Is it how we\u2019re representing the information? Is it the structure of the model inside? Are we asking the question the right way?</p>\n<p>This is where speech is such a fun area because there\u2019s clearly examples where there are learning algorithms in the world. What\u2019s in your head beat the living daylights of what\u2019s available on the computer side and that means there\u2019s a lot of great, fun play to figure stuff out.</p>\n<p><strong>Scott</strong>: Some of it\u2019s like tone inflection, things like that, but it\u2019s also that you understand the world around you.</p>\n<p>\u201CI couldn\u2019t put the pineapple in the suitcase because it was too small.\u201D What does \u201Cit\u201D refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.</p>\n<p><em>We</em> know, but the machine is kind of like, \u201CHuh?\u201D</p>\n<p><strong>Susan</strong>: Yeah, \u201CI saw Grandma.\u201D With a handsaw or a power one?</p>\n<p><strong>Scott</strong>: Yeah, what was the \u201Csaw\u201D here? There\u2019s a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.</p>\n<h2 id="lets-talk-about-text">Let\u2019s talk about text</h2>\n<p><strong>Scott</strong>: Text is huge.</p>\n<p><strong>Susan</strong>: It\u2019s huge and it\u2019s awesome.</p>\n<p><strong>Scott</strong>: The web exists. There\u2019s tons of textual data all over the place and titles and bodies of blogs are just everywhere.</p>\n<p><strong>Susan</strong>: The great thing about text is you can learn so much in so many different fields. It\u2019s not just \u201COh, we\u2019re going to only apply this to translation or only to transcription.\u201D You can use text to start learning about some subject matter and help your model in interesting ways with that.</p>\n<p>Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there\u2019s so much and it can be compactly represented comparatively to things.</p>\n<p><strong>Scott</strong>: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video\u2019s kind of growing, audio\u2019s growing, images are going, but text is massive.</p>\n<p><strong>Susan</strong>: Yeah you know, \u201Ca picture\u2019s worth a thousand words.\u201D A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There\u2019s a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.</p>\n<h2 id="how-do-you-label-data">How do you label data?</h2>\n<p><strong>Scott</strong>: Humans do it! You have a bunch of humans that look at images and say, \u201CThat is a cat\u201D or they circle the person and say, \u201CThat\u2019s a person\u201D or they listen to audio and they type out what was said. It\u2019s very, very tough work.</p>\n<p><strong>Susan</strong>: You know,</p>\n<p>\u201CThere\u2019s a lot of people in companies that think, \u201CAI can do that\u201D and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours.\u201D</p>\n<p><strong>Scott</strong>: Right now there isn\u2019t just a, \u201CHere\u2019s a ten million dollar check\u201D and get a dataset labeled. It\u2019s more like, you\u2019re going to be waiting two years or a year or half a year, and you\u2019re going to be orchestrating the effort. You have to do it.</p>\n<p><strong>Susan</strong>: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you\u2019ve got, but probably ten, twenty, fifty years from now.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/ai-show-different-types-of-machine-learning/index.md", "https://blog.deepgram.com/", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><iframe width="600" height="315" src="https://www.youtube.com/embed/7VMio8Tk2so" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
<p><strong>Scott</strong>: Welcome to the AI show. Today we’re asking a couple big questions. What are those big questions?</p>
<ul>
<li>What are the different types of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>?</li>
<li>What are the different types of data?</li>
</ul>
<p>Usually people think about three different types, like reinforcement learning, unsupervised, or supervised.</p>
<h2 id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>
<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning</a> is learning from a series of actions where you get a series of choices and rewards along away. So, a classic one that’s been in the news is <a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a>. A large chunk of reinforcement learning techniques are used in there, specifically Monte Carlo tree research techniques.</p>
<p><strong>Scott</strong>: So, people play the game Go. AlphaGo is a machine playing Go, being very good at it, and beating the world’s top Go players.</p>
<p><a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/google-alphago-computer-beats-professional-at-worlds-most-complex-board-game-go-a6837506.html"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/alphago.jpg" alt="alt"></a></p>
<p><strong>Susan</strong>: Another one that’s really fun and has popped up the last couple of years is based off of Atari games. Atari specifically has a great tool kit if you’re into this world. If you want to learn more, dig up the <a href="http://yavar.naddaf.name/ale/">Atari learning environment</a> and start going through a lot of go of code associated with that. It’s a phenomenal toolkit for all sorts of stuff, but specifically it’s been helping reinforcement learning because these games are a series actions. They lead to reward, a score.</p>
<p><strong>Scott</strong>: So, reinforcement learning is like, “Hey, I’m taking some actions. I can do any number of things, but what I’m trying to do is make some number go up - like my score or my happiness.”</p>
<p><strong>Susan</strong>: Exactly. Classically, there isn’t just one reward at the end. You can get rewards along the way and the question is, “How do I maximize that in the infinite game? How do I get the biggest payoff throughout time?” It’s great because it allows you not only to explore classic reinforcement learning, but also get into things like image recognition:</p>
<ul>
<li>How do I look at the screen?</li>
<li>What does it mean to do that?</li>
<li>What parts of that screen are important?</li>
<li>What do I focus on?</li>
</ul>
<p>There’s a lot of great techniques that can draw you in there. You can do simple stuff or really complex stuff. It is just a fun, awesome environment to explore nothing but a bunch of great technologies.</p>
<h2 id="what-is-reinforcement-learning-good-at">What is Reinforcement Learning good at?</h2>
<p><strong>Scott</strong>: What kind of problem would you throw at reinforcement learning, say, “Go” and expect it to work?</p>
<p><strong>Susan</strong>: So reinforcement learning has a lot of problems that fit into graphs. So a series actions that lead to other choices, actions that lead to other choices, actions lead to other choices. So,</p>
<ul>
<li>Trying to find a good path on a map.</li>
<li>Trying to win one of the thousand Atari games out there.</li>
<li>Trying to play a game like checkers or chess.</li>
</ul>
<p>You know, the classic, “I take a move, my opponent takes a move, I take a move, my opponent takes a move.”</p>
<p><strong>Scott</strong>: So where things are pretty rigid and the actions that you take are known. An act of God isn’t going to come in and change something. It’s, “Here’s your environment, play in it.”</p>
<p><strong>Susan</strong>: Basically where there’s some finite set states, they transition in some way that we can model, and they have actions that affect those transitions.</p>
<p>So, say I have four options in front of me. I choose A and I’m in state <em>n</em> right now. There’s some probability based off of the action I choose for what state I’ll end up in after that. Reinforcement learning allows me to understand those probabilities, these transitions, and also what’s called the best policy. In other words, given all this information, “What is the best action I should take to get some sort of reward in the end?” But, it sounds dry and academic when you start talking that way. It’s a lot better when you say, “Hey, I’m gonna play Pole Position. Do I move the car left? Do I move it right? Do I tell it to speed up? Do I tell it to slow down?” It’s the same thing.</p>
<p><a href="https://en.wikipedia.org/wiki/Pole_Position"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976374/blog/ai-show-different-types-of-machine-learning/poleposition.png" alt="alt"></a></p>
<p><strong>Scott</strong>: Yeah, it might have access to the image - it can look around, it could look on the screen, it can see if a car has passed it or not - but it has to figure all those things out on its own. It’s getting the input from the screen, it knows what position it’s in, and it’s trying to make that position number one or make its lap time faster in the game.</p>
<p><strong>Susan</strong>: Exactly, it’s great. And going back to the Atari learning environment, when you’re trying to frame this as a reinforcement learning problem, you’ve got to figure out how to identify the state you’re in and what actions are available and do those different things.</p>
<h2 id="what-is-supervised-learning">What is supervised learning?</h2>
<p><strong>Susan</strong>: So, when we talk about unsupervised, supervised, semi-supervised the classic definitions are all around data. So <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, you’ve got a bunch of labeled, training data. Labeled meaning like “I’ve got a picture of a cat and I’ve got right next to it <code>cat</code>. Every single piece of information I’ve got has the answer of what it is right next to it.</p>
<p>One of the most famous examples that people start off with is the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> handwriting digit recognition.</p>
<p><a href="https://en.wikipedia.org/wiki/MNIST_database"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976375/blog/ai-show-different-types-of-machine-learning/mnist.png" alt="alt"></a></p>
<p><strong>Scott</strong>: These are images where people have handwritten numbers on a piece of paper. That means 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Many different people have written many different digits, but they’ve all been labeled. So somebody has gone through and said, “A one is a 1 and a five is a 5, and an eight is an 8.” It’s collections of 28x28 pixels. This was done in the late nineties, but it’s a large number, I think sixty thousand images. It’s just black and white images of 28x28 pixels, but you can read it. You can look at it as a human and be like, “Yep. That’s a two.”</p>
<p><strong>Susan</strong>: It’s great as an academic set and it was also very useful when it came out for practical things like reading the mail.</p>
<p><strong>Scott</strong>: I think this was actually implemented in the post office in the late nineties.</p>
<p><strong>Susan</strong>: It’s awesome because it’s small off enough from a data perspective that pretty much anybody with a home computer can do real networks against it, you can see real results, apply some basic stuff, and have a good time learning a lot of stuff about it. It’s also very easy for you to say, “Oh, that’s a one. That’s a two.” or whatever and kind of see where your model messes up.</p>
<p><strong>Scott</strong>: Yeah you only have to pick from ten. It’s not that hard, but there are many different objects in the world for other datasets.</p>
<h2 id="lets-talk-datasets">Let’s talk datasets</h2>
<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet</a> or <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a> is one of my favorites. 10 and 100 there. That one’s actually great because you can start off with the simpler world, the 10, and then go to 100.</p>
<p><strong>Scott</strong>: It’s a large number of color images. It’s the same ones, but they’re labeled differently. They’re either labeled into ten categories or a hundred categories.</p>
<p><a href="https://www.researchgate.net/figure/Heterogeneousness-and-diversity-of-the-CIFAR-10-entries-in-their-10-image-categories-The_fig1_322148855"><img src="https://res.cloudinary.com/deepgram/image/upload/v1661976376/blog/ai-show-different-types-of-machine-learning/cifar.png" alt="alt"></a></p>
<p><strong>Susan</strong>: Yeah, same number of pixels and colors and all that stuff so you can use basically the same model.</p>
<p><strong>Scott</strong>: Yeah so you can take the same data and say like, “Okay, I’m going to try for the simple thing: just picking from one of ten, like <code>airplane</code>, <code>car</code>, <code>animal</code>. Things like that.” And then maybe the animal would have ten different ones where it’s like <code>dog</code>, <code>cat</code>,<code>lizard</code>.</p>
<p><strong>Susan</strong>: That’s another great kind of step up because you’ve got more data to play with, harder classification task to deal. The simple model, the simple two layer feed forward network that would have worked on MNIST will not do nearly as well on CIFAR. So it allows you to step up your game that bit. But, both of these sets which are fully supervised, you’ve got the answer sitting in front of you. They’re not super realistic in the real world. They’re well cropped, things are well-sized, everything’s exactly the same dimensions. It’s great for learning, but the real world has a lot more problems than that.</p>
<p><strong>Scott</strong>: Yeah, not all images are the same size or zoomed in to the same leveling.</p>
<h2 id="what-is-semi-supervised-learning">What is semi-supervised learning?</h2>
<p><strong>Susan</strong>: <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Semi-supervised</a> says, “I have some of the labels and I’m going to use unlabeled data to help me boost my results in some way.” Think of audio normalization as an example - I’ve got a bunch of audio and I’m going to use that to help me normalize background, but I’m really only learning on the subset that I have.</p>
<p><strong>Scott</strong>: You mean like the volume?</p>
<p><strong>Susan</strong>: Yeah, like the volume or some simple stuff like that. Or, I could use it in more complex ways like using it to compress down to try to rebuild the exact same audio stream.</p>
<p><strong>Scott</strong>: Yeah, to expand on that some more, it’s like “Hey, if I gave a network or some machine learning algorithm the original image and then I forced that network to squish down into a really small space, meaning it can only hang on to a few numbers, it then has to rebuild that and try to come up with the original image.</p>
<p>If you squeeze that down into one number, it can’t reconstruct any image. It could probably do like how bright or dark it was, but you expand that out to a few numbers, at least now it can start to construct what color the image was, maybe some shapes in it, and expanded it a little further. Now it kind of looks like the original image, but it’s been compressed way down so it’s not the same size as the original image.</p>
<p>This is a traditional <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised</a> technique. Then, what you do is you take that model that tried to squish it down and you use that later in a supervised way.</p>
<p><strong>Susan</strong>: Basically, what that last little bit is, that little squished down version, is the essential information behind that image.</p>
<p><strong>Scott</strong>: Yeah, so “I see circles here. It’s red. I see some texture here.” Maybe it’s feathers or something. It doesn’t even know the idea of feathers, but it knows that it’s sort of grouped together. You can use that information later.</p>
<p><strong>Susan</strong>: With every single problem, you’re going to find some different way of using unlabeled data to help you out. There isn’t some “Oh this is the set way.” of doing semi-supervised learning. It’s “I found this great semi-supervised technique to help me out in problem <em>x</em>.” In general, that’s the way it goes.</p>
<p>“Supervised world, there’s a lot more canned answers. Semi-supervised, a lot less canned answers. Unsupervised, it’s pretty hard to find answers.”</p>
<h2 id="machine-learning-in-business">Machine learning in business</h2>
<p><strong>Scott</strong>: We started out with the more academic side - reinforcement learning. Is that super useful in real world business? Not so much, right?</p>
<p>You could dream up ways, but is that what people are running right now in order to save money? That’s not what they’re doing in their business. They’re probably using some sort of supervised learning technique.</p>
<p><strong>Susan</strong>: Yeah, the majority of what we’re thinking about in the machine learning world is supervised, likely a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> world.</p>
<p><strong>Scott</strong>: Like translation. You know, going from English to French or doing speech recognition, going from an audio recording to text that was spoken. Those are all trained. They might be augmented a little bit with some unsupervised technique, but it’s almost a hundred percent supervised.</p>
<p><strong>Susan</strong>: Yeah, currently.</p>
<p>“As we move forward in this world, the real future is semi-supervised, unsupervised as much as possible because that’s where most of our data lies.”</p>
<p><strong>Scott</strong>: That’s how a human learns.</p>
<p><strong>Susan</strong>: Exactly. Humans, we bootstrap.</p>
<p><strong>Scott</strong>: We test the world, we poke.</p>
<p><strong>Susan</strong>: Exactly. Mom and Dad start off by saying, “Apple. Apple. Apple.” Later on, <em>you</em> start testing the world by saying, “Apple?”</p>
<p><strong>Scott</strong>: But then you hear somebody with an accent that says “apple” and you can kinda work out from context - <em>They must mean apple, I’m gonna adjust my <a href="https://en.wikipedia.org/wiki/Acoustic_model">acoustic model</a>.</em></p>
<p><strong>Susan</strong>: We start learning more and more and more just by going through the world. That’s really an amazing thing that we need to learn a lot more in the machine learning world. The more we can get those techniques and rip them out of our own head, the more we’ll be able to take advantage of huge data sources that are out there.</p>
<p><strong>Scott</strong>: I still think from a pragmatic perspective, if you’re a business and you want to tackle some problem using machine learning, you don’t start with unsupervised, you don’t start with reinforcement learning, you start with supervised learning. You go and label some data, you go gather data, then you label some of it, and then you train a model and you see how well it works. You probably don’t even start with deep learning. You start with some tree-based method or something like that.</p>
<p><strong>Susan</strong>: But you definitely have to have data. If you don’t understand your problem enough to have a dataset of examples and answers, then you definitely don’t understand the problem well enough to train something to figure it out.</p>
<h2 id="what-are-the-different-types-of-data-what-do-you-do-with-it">What are the different types of data? What do you do with it?</h2>
<p><strong>Susan</strong>: Image and audio.</p>
<p><strong>Scott</strong>: Video.</p>
<p><strong>Susan</strong>: Text. Sequences in general.</p>
<p><strong>Scott</strong>: It might be like, “I turned right down this street, I drove this long, I turned left down that street, and Google’s trying to figure out what your intentions are. Are you going to a restaurant? Should I pop up a gas station?” Things like that.</p>
<p><strong>Susan</strong>: Which, by the way, are great examples of where reinforcement learning is winning big. But, again, on the big classes data we’re definitely blurring what it means to say classes of data anymore. Sure, it’s easy to say this is an image, this is video, this is audio, this is whatever.</p>
<p>Now we’re trying to fuse together different sources of data to help us answer the question at hand: Make the money. What information sources do you need? Is it clicks? Is it pictures? Is it audio? Is it text? Is it bank accounts? Is it all these different sources of information?</p>
<p><strong>Scott</strong>: Usually called multi-channel in a business setting. Somebody emails you, they send you some chats, they also call you on the phone and you’re trying to fuse all that information together, build a model, and predict something about them: Are they pissed off? Are they happy?</p>
<p><strong>Susan</strong>: That’s a big challenge on two fronts.</p>
<p>First of all, we’ve got a lot of great techniques that are sifting signal from noise, but the more noise you give it the harder it is to work and sometimes adding more data actually hurts you. So, if you can filter out a lot of bad sources, you’re going to probably make your model better.</p>
<p>“Focus on useful data that has predictive power. There’s this common misconception: If I just put enough layers, enough neurons together and enough data sources and then run it for a long enough time on a big GPU, magic and the right answer happens on the other end.”</p>
<p><strong>Scott</strong>: Not necessarily the case. There are other constraints that come into play.</p>
<h2 id="dealing-with-data">Dealing with data</h2>
<p><strong>Susan</strong>: Just purely dealing with that data becomes a problem. More data means a longer time before your model converges, before it starts being able to get predictive power. Sometimes it’s so far that it just never gets there.</p>
<p><strong>Scott</strong>: You’re saying don’t get data?</p>
<p><strong>Susan</strong>: I’m not saying don’t get data. I’m saying, try to figure out how useful your data is. If you can pre-process it, you might make a huge difference on your model in some way.</p>
<p>We’ll talk audio for a second. If you do absolutely nothing to your audio and send it to a model, you probably will get better results for whatever you’re doing to that audio.</p>
<p>It’s all about getting to a baseline because, in general, a lot of our techniques are really good at saying, “Hey given that something’s at this baseline, I can tell you to nudge it up this way or nudge it down that way.” But, if the data’s coming in down here all the time, it’s working really hard just to predict up to the baseline and go above it. It’s going to be biased in some way.</p>
<p>So, if you can get it through some simple statistical technique or whatever to a reasonable baseline, it’s a lot easier for your model to nudge it in the right direction and get the right answer.</p>
<h2 id="whats-considered-a-large-dataset">What’s considered a large dataset?</h2>
<p><strong>Scott</strong>: MNIST was sixty thousand images. That’s not generally considered a large image dataset. It’s pretty big. It’s good for what it’s trying to do. It can tell handwritten digits pretty well, but the large datasets in the world like ImageNet, which is actually not ten or a hundred like CIFAR, but a thousand categories. I think it’s nineteen million images labeled into those categories. That’s a pretty big dataset, but is it the biggest dataset in the world? No!</p>
<p><strong>Susan</strong>: It’s also purely academic right now. When you look at the self-driving car world at the visual information that they’re sucking in and the terabytes worth of data that they’re processing through their models, that makes nineteen million images seem quaint. They’re sucking down large portions of YouTube.</p>
<p><strong>Scott</strong>: They also need data that’s segmented. It’s not just, “Is there a cat in this image?” It’s, “There are three people in this image, I’ve drawn the outline of the person, I’ve drawn the shape of the road, I’ve drawn the traffic light,” and things like that. It knows exactly where it is.</p>
<h2 id="thinking-about-your-task">Thinking about your task</h2>
<p><strong>Scott</strong>: So, you kind have to think about your task, right? If you’re choosing from one of ten categories, then maybe like sixty thousand or ten thousand or a hundred thousand. Somewhere in that range is the number of labeled pieces of data that you would need.</p>
<p>If you’re choosing from a hundred categories, maybe it’s five or ten times that. If you’re choosing from a thousand categories, maybe it’s another five or ten times that in order to get up to the amount of data that you need to tell the differentiation between them. But in the speech world, we’re not talking images anymore. We’re talking about hours or seconds of labeled audio.</p>
<p><strong>Susan</strong>: That’s an interesting one. We were talking about this earlier: How long does it take a human to learn? How many hours of audio does it take for a human to learn a language? Even from infancy.</p>
<p><strong>Scott</strong>: To get a really good grasp on your one language that you learn from birth it takes probably ten years.</p>
<p><strong>Susan</strong>: Yeah, when you think about the amount of audio that was heard in that, it was really not a tremendous amount.</p>
<p><strong>Scott</strong>: Maybe tens of thousands of hours of speech that you’ve heard and in a semi-supervised way.</p>
<p><strong>Susan</strong>: Exactly, a very semi-supervised way. And the crazy thing is, training a world class speech model generally takes a lot more than that.</p>
<p><strong>Scott</strong>: You’re talking tens to thousands of hours or maybe ten times that. It’s all purely supervised as well.</p>
<p>So a human is semi-supervised - at about ten thousand hours it can master language. But, a machine at ten thousand hours, even supervised, hasn’t really mastered the language. It’s doing pretty well, but it’s not mastered. Maybe 10x that, now you’re getting to the territory where it feels like it mastered the language. Still, it was a supervised way, not a semi-supervised way.</p>
<h2 id="what-mechanisms-do-humans-have-that-machines-dont">What mechanisms do humans have that machines don’t?</h2>
<p><strong>Susan</strong>: What are the mechanisms that allow a human to do that that we you don’t have available to us? Is it how we’re representing the information? Is it the structure of the model inside? Are we asking the question the right way?</p>
<p>This is where speech is such a fun area because there’s clearly examples where there are learning algorithms in the world. What’s in your head beat the living daylights of what’s available on the computer side and that means there’s a lot of great, fun play to figure stuff out.</p>
<p><strong>Scott</strong>: Some of it’s like tone inflection, things like that, but it’s also that you understand the world around you.</p>
<p>“I couldn’t put the pineapple in the suitcase because it was too small.” What does “it” refer to? Is it that the pineapple was too small or that the suitcase was too small? We can figure that out really quickly.</p>
<p><em>We</em> know, but the machine is kind of like, “Huh?”</p>
<p><strong>Susan</strong>: Yeah, “I saw Grandma.” With a handsaw or a power one?</p>
<p><strong>Scott</strong>: Yeah, what was the “saw” here? There’s a lot of common sense here that humans are able to apply really easily. Another really large dataset is text though.</p>
<h2 id="lets-talk-about-text">Let’s talk about text</h2>
<p><strong>Scott</strong>: Text is huge.</p>
<p><strong>Susan</strong>: It’s huge and it’s awesome.</p>
<p><strong>Scott</strong>: The web exists. There’s tons of textual data all over the place and titles and bodies of blogs are just everywhere.</p>
<p><strong>Susan</strong>: The great thing about text is you can learn so much in so many different fields. It’s not just “Oh, we’re going to only apply this to translation or only to transcription.” You can use text to start learning about some subject matter and help your model in interesting ways with that.</p>
<p>Text is a great secondary source to so many problems out there if you can figure out how to work it in just because there’s so much and it can be compactly represented comparatively to things.</p>
<p><strong>Scott</strong>: Text is the biggest, richest data source that people have right now just because the internet exists and everything is kind of in text. Video’s kind of growing, audio’s growing, images are going, but text is massive.</p>
<p><strong>Susan</strong>: Yeah you know, “a picture’s worth a thousand words.” A thousand words may be worth more than single picture in all honesty in how much meaning it conveys. There’s a lot of great stuff in text, huge things. The synthetic world, just as a big, broad category, synthetic versus truly labeled, supervised data versus unsupervised.</p>
<h2 id="how-do-you-label-data">How do you label data?</h2>
<p><strong>Scott</strong>: Humans do it! You have a bunch of humans that look at images and say, “That is a cat” or they circle the person and say, “That’s a person” or they listen to audio and they type out what was said. It’s very, very tough work.</p>
<p><strong>Susan</strong>: You know,</p>
<p>“There’s a lot of people in companies that think, “AI can do that” and maybe you can build the model, maybe you can buy the GPUs, maybe you can set up the servers, maybe you can dedicate some people, but just go out and find the data and either pay the millions of dollars to get it or spend the tens of thousands of man hours.”</p>
<p><strong>Scott</strong>: Right now there isn’t just a, “Here’s a ten million dollar check” and get a dataset labeled. It’s more like, you’re going to be waiting two years or a year or half a year, and you’re going to be orchestrating the effort. You have to do it.</p>
<p><strong>Susan</strong>: Just think about the data it takes to go out and build a map in the world, physically getting people out there. That data will be useful not only today and for the problem you’ve got, but probably ten, twenty, fifty years from now.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/ai-show-different-types-of-machine-learning/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
