import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
/* empty css                           */import 'axios';
/* empty css                          *//* empty css                           *//* empty css                          *//* empty css                              *//* empty css                              */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           *//* empty css                              */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "method-1-monitor-media-mentions-in-podcasts-using-diarization-with-ai-speech-recognition", "text": "Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition" }, { "depth": 2, "slug": "method-2-monitor-media-mentions-in-podcasts-using-search-and-entity-detection", "text": "Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection" }, { "depth": 3, "slug": "python-code-breakdown-with-ai-deepgram-speech-to-text-and-spacy", "text": "Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy" }, { "depth": 2, "slug": "conclusion", "text": "Conclusion" }], "source": "\nOver the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.\n\nFor example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you\u2019re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.\n\nThere are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let\u2019s look at a method using diarization (FYI, there is a better way further down in this post).\n\n## Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition\n\nThis method is interesting but not as effective as I\u2019ll show later in this post. As a quick review, [Deepgram\u2019s diarization feature](https://developers.deepgram.com/documentation/features/diarize/) recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to `True`, a word will be assigned to each speaker in the transcript.\n\nA readable formatted transcript with the speech-to-text diarize feature may look something like this:\n\n```\n[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.\n\n[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. \n\n[Speaker:1] The faster website loads, the better off you are.\n\n[Speaker:1] With Google's core vital update that makes it super important to optimize your site or load time.\n\n[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.\n```\n\nIn a podcast, there\u2019s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you\u2019ll notice that Speaker 1 talks the longest during that segment. This *could* indicate that\u2019s where the ad is read on behalf of the sponsor.\n\nI promised you a better way to monitor mentions in a podcast. Let\u2019s look at how that would work with Python, Deepgram\u2019s AI speech-to-text [Search feature](https://developers.deepgram.com/documentation/features/search/), and entity detection with SpaCy.\n\n## Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection\n\nI was curious how to come up with a way to monitor media mentions in podcasts that would do the following:\n\nSearch for terms in the podcast transcript like \u201Csponsor\u201D or \u201Cpaid\u201D that indicate an ad segment\nIdentify the organizations that are talked about in the ad to determine the company sponsoring that segment\nAnd overall, not cause a bigger headache for me\n\nI needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the [Deepgram Python SDK](https://github.com/deepgram/python-sdk). I used the prerecorded option in this scenario to transcribe the already recorded audio. I also [grabbed a Deepgram API key ](https://console.deepgram.com/signup?jump=keys) from our console, which has gamified missions you can try to get up to speed quicker.\n\nDeepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I\u2019ll show you in the code), and speed is an advantage, so I didn\u2019t have to wait long for the transcribed audio.\n\nThe Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.\n\nI added the Search feature as a parameter in the Python code like this:\n\n```python\n'search': 'sponsor'\n```\n\nSince I wanted to find where the podcast hosts mentioned sponsorships, searching for the world `sponsor` made sense. Imagine them saying something like, \u201CNow a word from our sponsor\u201D.\n\nAfter printing the results, I received a response similar to this:\n```bash\n[{'confidence': 1.0, 'end': 23.57, 'snippet': 'our sponsor', 'start': 23.09},\n    {'confidence': 0.7023809, 'end': 79.82909, 'snippet': 'spotify', 'start': 79.38954},\n    {'confidence': 0.6279762, 'end': 120.18001, 'snippet': 'stocks','start': 119.740005},\n    {'confidence': 0.5535714, 'end': 241.19926,'snippet': 'focus on','start': 240.92029}]\n```\nThe response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.\n\nNext, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.\n\nSpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You\u2019ll see how that works in the next section when I break down the code.\n\n### Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy\n\nThe first thing I did was pip install the following Python libraries:\n\n    pip install deepgram-sdk\n    pip install python-dotenv\n    pip install -U pip setuptools wheel\n    pip install spacy\n    python3 -m spacy download en_core_web_md\n\nIf you want to see the Python code that I wrote for this podcast media mentions project, please look below:\n\n```python\nfrom multiprocessing.context import set_spawning_popen\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom spacy.pipeline import EntityRuler\nimport spacy\nimport asyncio\nimport json\nimport os\n\nload_dotenv()\n\nPATH_TO_FILE = 'podcast-audio-file.mp3'\n\nasync def transcribe_with_deepgram():\n   # Initializes the Deepgram SDK\n   deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n\n   options = {\n       'punctuate': True,\n       'search': 'sponsor'\n   }   \n\n   get_start_time = 0.0\n\n\n   # Open the audio file\n   with open(PATH_TO_FILE, 'rb') as audio:\n       # ...or replace mimetype as appropriate\n       source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n       response = await deepgram.transcription.prerecorded(source, options)\n\n       if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n           # search for query word in transcript\n           search_term = response['results']['channels'][0]['search'][0]['hits']\n\n           # get search_term with confidence of 1.0\n           if search_term[0]['confidence'] == 1.0:\n               get_start_time = search_term[0]['start']\n                  \n           transcript = response['results']['channels'][0]['alternatives'][0]['words']\n\n    get_end_start_time = get_start_time + 30\n\n   start_list = []\n\n   for word in transcript:\n       if word['start'] >= get_start_time and word['start'] < get_end_start_time:\n           start_list.append(word['punctuated_word'])\n\n   new_transcript = \" \".join(start_list)\n\n   return new_transcript\n\n\nasync def get_media_mentions():\n\n   media_transcript = await transcribe_with_deepgram()\n\n   # Build upon the spaCy Medium Model\n   nlp = spacy.load(\"en_core_web_md\")\n\n   # Create the EntityRuler (your competition or whichever ORG)\n   ruler = nlp.add_pipe(\"entity_ruler\")\n\n   # List of Entities and Patterns\n   patterns = [\n                   {\"label\": \"ORG\", \"pattern\": \"Dream Host\"}\n              ]\n\n   ruler.add_patterns(patterns)\n\n\n   doc = nlp(media_transcript)\n\n   #extract entities\n   for ent in doc.ents:\n       if ent.label_ == \"ORG\":\n           print(ent.text, ent.label_)\n\n      \n\nasyncio.run(get_media_mentions())\n```\n\nIn the `transcribe_ with_deepgram` method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the **prerecorded** transcription option to transcribe a recorded file to text.\n\nIn the `get_media_mentions` method, I\u2019m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern `Dream Host` with a corresponding label `ORG`. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.\n\nFinally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.\n\nHere\u2019s what it looked like in my terminal:\n\n```\nGoogle ORG\nGoogle ORG\nDream Host ORG\n```\nAs you can see, the podcast hosts mentioned the companies Google and Dream Host.\n\n## Conclusion\n\nThat wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at [@DeepgramAI](https://twitter.com/DeepgramAI).\n\n", "html": '<p>Over the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.</p>\n<p>For example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you\u2019re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.</p>\n<p>There are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let\u2019s look at a method using diarization (FYI, there is a better way further down in this post).</p>\n<h2 id="method-1-monitor-media-mentions-in-podcasts-using-diarization-with-ai-speech-recognition">Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition</h2>\n<p>This method is interesting but not as effective as I\u2019ll show later in this post. As a quick review, <a href="https://developers.deepgram.com/documentation/features/diarize/">Deepgram\u2019s diarization feature</a> recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to <code is:raw>True</code>, a word will be assigned to each speaker in the transcript.</p>\n<p>A readable formatted transcript with the speech-to-text diarize feature may look something like this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. </span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] The faster website loads, the better off you are.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] With Google&#39;s core vital update that makes it super important to optimize your site or load time.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.</span></span></code></pre>\n<p>In a podcast, there\u2019s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you\u2019ll notice that Speaker 1 talks the longest during that segment. This <em>could</em> indicate that\u2019s where the ad is read on behalf of the sponsor.</p>\n<p>I promised you a better way to monitor mentions in a podcast. Let\u2019s look at how that would work with Python, Deepgram\u2019s AI speech-to-text <a href="https://developers.deepgram.com/documentation/features/search/">Search feature</a>, and entity detection with SpaCy.</p>\n<h2 id="method-2-monitor-media-mentions-in-podcasts-using-search-and-entity-detection">Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection</h2>\n<p>I was curious how to come up with a way to monitor media mentions in podcasts that would do the following:</p>\n<p>Search for terms in the podcast transcript like \u201Csponsor\u201D or \u201Cpaid\u201D that indicate an ad segment\nIdentify the organizations that are talked about in the ad to determine the company sponsoring that segment\nAnd overall, not cause a bigger headache for me</p>\n<p>I needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the <a href="https://github.com/deepgram/python-sdk">Deepgram Python SDK</a>. I used the prerecorded option in this scenario to transcribe the already recorded audio. I also <a href="https://console.deepgram.com/signup?jump=keys">grabbed a Deepgram API key </a> from our console, which has gamified missions you can try to get up to speed quicker.</p>\n<p>Deepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I\u2019ll show you in the code), and speed is an advantage, so I didn\u2019t have to wait long for the transcribed audio.</p>\n<p>The Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.</p>\n<p>I added the Search feature as a parameter in the Python code like this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span></code></pre>\n<p>Since I wanted to find where the podcast hosts mentioned sponsorships, searching for the world <code is:raw>sponsor</code> made sense. Imagine them saying something like, \u201CNow a word from our sponsor\u201D.</p>\n<p>After printing the results, I received a response similar to this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">[{</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 1.0, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 23.57, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;our sponsor&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 23.09},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.7023809, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 79.82909, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;spotify&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 79.38954},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.6279762, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 120.18001, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;stocks&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 119.740005},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.5535714, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 241.19926,</span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;focus on&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 240.92029}]</span></span></code></pre>\n<p>The response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.</p>\n<p>Next, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.</p>\n<p>SpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You\u2019ll see how that works in the next section when I break down the code.</p>\n<h3 id="python-code-breakdown-with-ai-deepgram-speech-to-text-and-spacy">Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy</h3>\n<p>The first thing I did was pip install the following Python libraries:</p>\n<p>pip install deepgram-sdk\npip install python-dotenv\npip install -U pip setuptools wheel\npip install spacy\npython3 -m spacy download en_core_web_md</p>\n<p>If you want to see the Python code that I wrote for this podcast media mentions project, please look below:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> multiprocessing.context </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> set_spawning_popen</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> spacy.pipeline </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> EntityRuler</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> spacy</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;podcast-audio-file.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">   deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   options </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span>\n<span class="line"><span style="color: #C9D1D9">   }   </span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.0</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">       source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">       response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, options)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># search for query word in transcript</span></span>\n<span class="line"><span style="color: #C9D1D9">           search_term </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;hits&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># get search_term with confidence of 1.0</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">               get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">                  </span></span>\n<span class="line"><span style="color: #C9D1D9">           transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">    get_end_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">30</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   start_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> transcript:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> get_end_start_time:</span></span>\n<span class="line"><span style="color: #C9D1D9">           start_list.append(word[</span><span style="color: #A5D6FF">&#39;punctuated_word&#39;</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   new_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(start_list)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> new_transcript</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_media_mentions</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   media_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Build upon the spaCy Medium Model</span></span>\n<span class="line"><span style="color: #C9D1D9">   nlp </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> spacy.load(</span><span style="color: #A5D6FF">&quot;en_core_web_md&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Create the EntityRuler (your competition or whichever ORG)</span></span>\n<span class="line"><span style="color: #C9D1D9">   ruler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp.add_pipe(</span><span style="color: #A5D6FF">&quot;entity_ruler&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># List of Entities and Patterns</span></span>\n<span class="line"><span style="color: #C9D1D9">   patterns </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">                   {</span><span style="color: #A5D6FF">&quot;label&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;pattern&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;Dream Host&quot;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">              ]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   ruler.add_patterns(patterns)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   doc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp(media_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E">#extract entities</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ent </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> doc.ents:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ent.label_ </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(ent.text, ent.label_)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(get_media_mentions())</span></span></code></pre>\n<p>In the <code is:raw>transcribe_ with_deepgram</code> method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <strong>prerecorded</strong> transcription option to transcribe a recorded file to text.</p>\n<p>In the <code is:raw>get_media_mentions</code> method, I\u2019m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern <code is:raw>Dream Host</code> with a corresponding label <code is:raw>ORG</code>. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.</p>\n<p>Finally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.</p>\n<p>Here\u2019s what it looked like in my terminal:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Google ORG</span></span>\n<span class="line"><span style="color: #c9d1d9">Google ORG</span></span>\n<span class="line"><span style="color: #c9d1d9">Dream Host ORG</span></span></code></pre>\n<p>As you can see, the podcast hosts mentioned the companies Google and Dream Host.</p>\n<h2 id="conclusion">Conclusion</h2>\n<p>That wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a>.</p>' };
const frontmatter = { "title": "How To Monitor Media Mentions in Podcasts with Python", "description": "This tutorial will use Python, SpaCy and the Deepgram API speech-to-text to monitor media mentions in a podcast and label meaningful text using entity detection. ", "date": "2022-08-31T18:47:17.677Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661868639/blog/2022/08/monitor-media-mentions/2208-Monitor-Media-Mentions-in-Podcasts-with-Python-blog%402x.jpg", "authors": ["tonya-sims"], "category": "tutorial", "tags": ["python"], "shorturls": { "share": "https://dpgr.am/e6fd847", "twitter": "https://dpgr.am/236c343", "linkedin": "https://dpgr.am/0e4df59", "reddit": "https://dpgr.am/9cc67d6", "facebook": "https://dpgr.am/fe5c66d" }, "astro": { "headings": [{ "depth": 2, "slug": "method-1-monitor-media-mentions-in-podcasts-using-diarization-with-ai-speech-recognition", "text": "Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition" }, { "depth": 2, "slug": "method-2-monitor-media-mentions-in-podcasts-using-search-and-entity-detection", "text": "Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection" }, { "depth": 3, "slug": "python-code-breakdown-with-ai-deepgram-speech-to-text-and-spacy", "text": "Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy" }, { "depth": 2, "slug": "conclusion", "text": "Conclusion" }], "source": "\nOver the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.\n\nFor example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you\u2019re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.\n\nThere are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let\u2019s look at a method using diarization (FYI, there is a better way further down in this post).\n\n## Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition\n\nThis method is interesting but not as effective as I\u2019ll show later in this post. As a quick review, [Deepgram\u2019s diarization feature](https://developers.deepgram.com/documentation/features/diarize/) recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to `True`, a word will be assigned to each speaker in the transcript.\n\nA readable formatted transcript with the speech-to-text diarize feature may look something like this:\n\n```\n[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.\n\n[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. \n\n[Speaker:1] The faster website loads, the better off you are.\n\n[Speaker:1] With Google's core vital update that makes it super important to optimize your site or load time.\n\n[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.\n```\n\nIn a podcast, there\u2019s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you\u2019ll notice that Speaker 1 talks the longest during that segment. This *could* indicate that\u2019s where the ad is read on behalf of the sponsor.\n\nI promised you a better way to monitor mentions in a podcast. Let\u2019s look at how that would work with Python, Deepgram\u2019s AI speech-to-text [Search feature](https://developers.deepgram.com/documentation/features/search/), and entity detection with SpaCy.\n\n## Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection\n\nI was curious how to come up with a way to monitor media mentions in podcasts that would do the following:\n\nSearch for terms in the podcast transcript like \u201Csponsor\u201D or \u201Cpaid\u201D that indicate an ad segment\nIdentify the organizations that are talked about in the ad to determine the company sponsoring that segment\nAnd overall, not cause a bigger headache for me\n\nI needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the [Deepgram Python SDK](https://github.com/deepgram/python-sdk). I used the prerecorded option in this scenario to transcribe the already recorded audio. I also [grabbed a Deepgram API key ](https://console.deepgram.com/signup?jump=keys) from our console, which has gamified missions you can try to get up to speed quicker.\n\nDeepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I\u2019ll show you in the code), and speed is an advantage, so I didn\u2019t have to wait long for the transcribed audio.\n\nThe Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.\n\nI added the Search feature as a parameter in the Python code like this:\n\n```python\n'search': 'sponsor'\n```\n\nSince I wanted to find where the podcast hosts mentioned sponsorships, searching for the world `sponsor` made sense. Imagine them saying something like, \u201CNow a word from our sponsor\u201D.\n\nAfter printing the results, I received a response similar to this:\n```bash\n[{'confidence': 1.0, 'end': 23.57, 'snippet': 'our sponsor', 'start': 23.09},\n    {'confidence': 0.7023809, 'end': 79.82909, 'snippet': 'spotify', 'start': 79.38954},\n    {'confidence': 0.6279762, 'end': 120.18001, 'snippet': 'stocks','start': 119.740005},\n    {'confidence': 0.5535714, 'end': 241.19926,'snippet': 'focus on','start': 240.92029}]\n```\nThe response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.\n\nNext, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.\n\nSpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You\u2019ll see how that works in the next section when I break down the code.\n\n### Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy\n\nThe first thing I did was pip install the following Python libraries:\n\n    pip install deepgram-sdk\n    pip install python-dotenv\n    pip install -U pip setuptools wheel\n    pip install spacy\n    python3 -m spacy download en_core_web_md\n\nIf you want to see the Python code that I wrote for this podcast media mentions project, please look below:\n\n```python\nfrom multiprocessing.context import set_spawning_popen\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom spacy.pipeline import EntityRuler\nimport spacy\nimport asyncio\nimport json\nimport os\n\nload_dotenv()\n\nPATH_TO_FILE = 'podcast-audio-file.mp3'\n\nasync def transcribe_with_deepgram():\n   # Initializes the Deepgram SDK\n   deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n\n   options = {\n       'punctuate': True,\n       'search': 'sponsor'\n   }   \n\n   get_start_time = 0.0\n\n\n   # Open the audio file\n   with open(PATH_TO_FILE, 'rb') as audio:\n       # ...or replace mimetype as appropriate\n       source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n       response = await deepgram.transcription.prerecorded(source, options)\n\n       if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n           # search for query word in transcript\n           search_term = response['results']['channels'][0]['search'][0]['hits']\n\n           # get search_term with confidence of 1.0\n           if search_term[0]['confidence'] == 1.0:\n               get_start_time = search_term[0]['start']\n                  \n           transcript = response['results']['channels'][0]['alternatives'][0]['words']\n\n    get_end_start_time = get_start_time + 30\n\n   start_list = []\n\n   for word in transcript:\n       if word['start'] >= get_start_time and word['start'] < get_end_start_time:\n           start_list.append(word['punctuated_word'])\n\n   new_transcript = \" \".join(start_list)\n\n   return new_transcript\n\n\nasync def get_media_mentions():\n\n   media_transcript = await transcribe_with_deepgram()\n\n   # Build upon the spaCy Medium Model\n   nlp = spacy.load(\"en_core_web_md\")\n\n   # Create the EntityRuler (your competition or whichever ORG)\n   ruler = nlp.add_pipe(\"entity_ruler\")\n\n   # List of Entities and Patterns\n   patterns = [\n                   {\"label\": \"ORG\", \"pattern\": \"Dream Host\"}\n              ]\n\n   ruler.add_patterns(patterns)\n\n\n   doc = nlp(media_transcript)\n\n   #extract entities\n   for ent in doc.ents:\n       if ent.label_ == \"ORG\":\n           print(ent.text, ent.label_)\n\n      \n\nasyncio.run(get_media_mentions())\n```\n\nIn the `transcribe_ with_deepgram` method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the **prerecorded** transcription option to transcribe a recorded file to text.\n\nIn the `get_media_mentions` method, I\u2019m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern `Dream Host` with a corresponding label `ORG`. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.\n\nFinally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.\n\nHere\u2019s what it looked like in my terminal:\n\n```\nGoogle ORG\nGoogle ORG\nDream Host ORG\n```\nAs you can see, the podcast hosts mentioned the companies Google and Dream Host.\n\n## Conclusion\n\nThat wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at [@DeepgramAI](https://twitter.com/DeepgramAI).\n\n", "html": '<p>Over the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.</p>\n<p>For example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you\u2019re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.</p>\n<p>There are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let\u2019s look at a method using diarization (FYI, there is a better way further down in this post).</p>\n<h2 id="method-1-monitor-media-mentions-in-podcasts-using-diarization-with-ai-speech-recognition">Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition</h2>\n<p>This method is interesting but not as effective as I\u2019ll show later in this post. As a quick review, <a href="https://developers.deepgram.com/documentation/features/diarize/">Deepgram\u2019s diarization feature</a> recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to <code is:raw>True</code>, a word will be assigned to each speaker in the transcript.</p>\n<p>A readable formatted transcript with the speech-to-text diarize feature may look something like this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. </span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] The faster website loads, the better off you are.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] With Google&#39;s core vital update that makes it super important to optimize your site or load time.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.</span></span></code></pre>\n<p>In a podcast, there\u2019s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you\u2019ll notice that Speaker 1 talks the longest during that segment. This <em>could</em> indicate that\u2019s where the ad is read on behalf of the sponsor.</p>\n<p>I promised you a better way to monitor mentions in a podcast. Let\u2019s look at how that would work with Python, Deepgram\u2019s AI speech-to-text <a href="https://developers.deepgram.com/documentation/features/search/">Search feature</a>, and entity detection with SpaCy.</p>\n<h2 id="method-2-monitor-media-mentions-in-podcasts-using-search-and-entity-detection">Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection</h2>\n<p>I was curious how to come up with a way to monitor media mentions in podcasts that would do the following:</p>\n<p>Search for terms in the podcast transcript like \u201Csponsor\u201D or \u201Cpaid\u201D that indicate an ad segment\nIdentify the organizations that are talked about in the ad to determine the company sponsoring that segment\nAnd overall, not cause a bigger headache for me</p>\n<p>I needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the <a href="https://github.com/deepgram/python-sdk">Deepgram Python SDK</a>. I used the prerecorded option in this scenario to transcribe the already recorded audio. I also <a href="https://console.deepgram.com/signup?jump=keys">grabbed a Deepgram API key </a> from our console, which has gamified missions you can try to get up to speed quicker.</p>\n<p>Deepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I\u2019ll show you in the code), and speed is an advantage, so I didn\u2019t have to wait long for the transcribed audio.</p>\n<p>The Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.</p>\n<p>I added the Search feature as a parameter in the Python code like this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span></code></pre>\n<p>Since I wanted to find where the podcast hosts mentioned sponsorships, searching for the world <code is:raw>sponsor</code> made sense. Imagine them saying something like, \u201CNow a word from our sponsor\u201D.</p>\n<p>After printing the results, I received a response similar to this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">[{</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 1.0, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 23.57, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;our sponsor&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 23.09},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.7023809, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 79.82909, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;spotify&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 79.38954},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.6279762, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 120.18001, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;stocks&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 119.740005},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.5535714, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 241.19926,</span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;focus on&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 240.92029}]</span></span></code></pre>\n<p>The response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.</p>\n<p>Next, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.</p>\n<p>SpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You\u2019ll see how that works in the next section when I break down the code.</p>\n<h3 id="python-code-breakdown-with-ai-deepgram-speech-to-text-and-spacy">Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy</h3>\n<p>The first thing I did was pip install the following Python libraries:</p>\n<p>pip install deepgram-sdk\npip install python-dotenv\npip install -U pip setuptools wheel\npip install spacy\npython3 -m spacy download en_core_web_md</p>\n<p>If you want to see the Python code that I wrote for this podcast media mentions project, please look below:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> multiprocessing.context </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> set_spawning_popen</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> spacy.pipeline </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> EntityRuler</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> spacy</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;podcast-audio-file.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">   deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   options </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span>\n<span class="line"><span style="color: #C9D1D9">   }   </span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.0</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">       source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">       response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, options)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># search for query word in transcript</span></span>\n<span class="line"><span style="color: #C9D1D9">           search_term </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;hits&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># get search_term with confidence of 1.0</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">               get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">                  </span></span>\n<span class="line"><span style="color: #C9D1D9">           transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">    get_end_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">30</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   start_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> transcript:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> get_end_start_time:</span></span>\n<span class="line"><span style="color: #C9D1D9">           start_list.append(word[</span><span style="color: #A5D6FF">&#39;punctuated_word&#39;</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   new_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(start_list)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> new_transcript</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_media_mentions</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   media_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Build upon the spaCy Medium Model</span></span>\n<span class="line"><span style="color: #C9D1D9">   nlp </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> spacy.load(</span><span style="color: #A5D6FF">&quot;en_core_web_md&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Create the EntityRuler (your competition or whichever ORG)</span></span>\n<span class="line"><span style="color: #C9D1D9">   ruler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp.add_pipe(</span><span style="color: #A5D6FF">&quot;entity_ruler&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># List of Entities and Patterns</span></span>\n<span class="line"><span style="color: #C9D1D9">   patterns </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">                   {</span><span style="color: #A5D6FF">&quot;label&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;pattern&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;Dream Host&quot;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">              ]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   ruler.add_patterns(patterns)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   doc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp(media_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E">#extract entities</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ent </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> doc.ents:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ent.label_ </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(ent.text, ent.label_)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(get_media_mentions())</span></span></code></pre>\n<p>In the <code is:raw>transcribe_ with_deepgram</code> method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <strong>prerecorded</strong> transcription option to transcribe a recorded file to text.</p>\n<p>In the <code is:raw>get_media_mentions</code> method, I\u2019m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern <code is:raw>Dream Host</code> with a corresponding label <code is:raw>ORG</code>. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.</p>\n<p>Finally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.</p>\n<p>Here\u2019s what it looked like in my terminal:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Google ORG</span></span>\n<span class="line"><span style="color: #c9d1d9">Google ORG</span></span>\n<span class="line"><span style="color: #c9d1d9">Dream Host ORG</span></span></code></pre>\n<p>As you can see, the podcast hosts mentioned the companies Google and Dream Host.</p>\n<h2 id="conclusion">Conclusion</h2>\n<p>That wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a>.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/how-to-monitor-media-mentions-in-podcasts-with-python/index.md" };
function rawContent() {
  return "\nOver the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.\n\nFor example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you\u2019re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.\n\nThere are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let\u2019s look at a method using diarization (FYI, there is a better way further down in this post).\n\n## Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition\n\nThis method is interesting but not as effective as I\u2019ll show later in this post. As a quick review, [Deepgram\u2019s diarization feature](https://developers.deepgram.com/documentation/features/diarize/) recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to `True`, a word will be assigned to each speaker in the transcript.\n\nA readable formatted transcript with the speech-to-text diarize feature may look something like this:\n\n```\n[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.\n\n[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. \n\n[Speaker:1] The faster website loads, the better off you are.\n\n[Speaker:1] With Google's core vital update that makes it super important to optimize your site or load time.\n\n[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.\n```\n\nIn a podcast, there\u2019s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you\u2019ll notice that Speaker 1 talks the longest during that segment. This *could* indicate that\u2019s where the ad is read on behalf of the sponsor.\n\nI promised you a better way to monitor mentions in a podcast. Let\u2019s look at how that would work with Python, Deepgram\u2019s AI speech-to-text [Search feature](https://developers.deepgram.com/documentation/features/search/), and entity detection with SpaCy.\n\n## Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection\n\nI was curious how to come up with a way to monitor media mentions in podcasts that would do the following:\n\nSearch for terms in the podcast transcript like \u201Csponsor\u201D or \u201Cpaid\u201D that indicate an ad segment\nIdentify the organizations that are talked about in the ad to determine the company sponsoring that segment\nAnd overall, not cause a bigger headache for me\n\nI needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the [Deepgram Python SDK](https://github.com/deepgram/python-sdk). I used the prerecorded option in this scenario to transcribe the already recorded audio. I also [grabbed a Deepgram API key ](https://console.deepgram.com/signup?jump=keys) from our console, which has gamified missions you can try to get up to speed quicker.\n\nDeepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I\u2019ll show you in the code), and speed is an advantage, so I didn\u2019t have to wait long for the transcribed audio.\n\nThe Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.\n\nI added the Search feature as a parameter in the Python code like this:\n\n```python\n'search': 'sponsor'\n```\n\nSince I wanted to find where the podcast hosts mentioned sponsorships, searching for the world `sponsor` made sense. Imagine them saying something like, \u201CNow a word from our sponsor\u201D.\n\nAfter printing the results, I received a response similar to this:\n```bash\n[{'confidence': 1.0, 'end': 23.57, 'snippet': 'our sponsor', 'start': 23.09},\n    {'confidence': 0.7023809, 'end': 79.82909, 'snippet': 'spotify', 'start': 79.38954},\n    {'confidence': 0.6279762, 'end': 120.18001, 'snippet': 'stocks','start': 119.740005},\n    {'confidence': 0.5535714, 'end': 241.19926,'snippet': 'focus on','start': 240.92029}]\n```\nThe response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.\n\nNext, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.\n\nSpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You\u2019ll see how that works in the next section when I break down the code.\n\n### Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy\n\nThe first thing I did was pip install the following Python libraries:\n\n    pip install deepgram-sdk\n    pip install python-dotenv\n    pip install -U pip setuptools wheel\n    pip install spacy\n    python3 -m spacy download en_core_web_md\n\nIf you want to see the Python code that I wrote for this podcast media mentions project, please look below:\n\n```python\nfrom multiprocessing.context import set_spawning_popen\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom spacy.pipeline import EntityRuler\nimport spacy\nimport asyncio\nimport json\nimport os\n\nload_dotenv()\n\nPATH_TO_FILE = 'podcast-audio-file.mp3'\n\nasync def transcribe_with_deepgram():\n   # Initializes the Deepgram SDK\n   deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n\n   options = {\n       'punctuate': True,\n       'search': 'sponsor'\n   }   \n\n   get_start_time = 0.0\n\n\n   # Open the audio file\n   with open(PATH_TO_FILE, 'rb') as audio:\n       # ...or replace mimetype as appropriate\n       source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n       response = await deepgram.transcription.prerecorded(source, options)\n\n       if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n           # search for query word in transcript\n           search_term = response['results']['channels'][0]['search'][0]['hits']\n\n           # get search_term with confidence of 1.0\n           if search_term[0]['confidence'] == 1.0:\n               get_start_time = search_term[0]['start']\n                  \n           transcript = response['results']['channels'][0]['alternatives'][0]['words']\n\n    get_end_start_time = get_start_time + 30\n\n   start_list = []\n\n   for word in transcript:\n       if word['start'] >= get_start_time and word['start'] < get_end_start_time:\n           start_list.append(word['punctuated_word'])\n\n   new_transcript = \" \".join(start_list)\n\n   return new_transcript\n\n\nasync def get_media_mentions():\n\n   media_transcript = await transcribe_with_deepgram()\n\n   # Build upon the spaCy Medium Model\n   nlp = spacy.load(\"en_core_web_md\")\n\n   # Create the EntityRuler (your competition or whichever ORG)\n   ruler = nlp.add_pipe(\"entity_ruler\")\n\n   # List of Entities and Patterns\n   patterns = [\n                   {\"label\": \"ORG\", \"pattern\": \"Dream Host\"}\n              ]\n\n   ruler.add_patterns(patterns)\n\n\n   doc = nlp(media_transcript)\n\n   #extract entities\n   for ent in doc.ents:\n       if ent.label_ == \"ORG\":\n           print(ent.text, ent.label_)\n\n      \n\nasyncio.run(get_media_mentions())\n```\n\nIn the `transcribe_ with_deepgram` method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the **prerecorded** transcription option to transcribe a recorded file to text.\n\nIn the `get_media_mentions` method, I\u2019m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern `Dream Host` with a corresponding label `ORG`. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.\n\nFinally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.\n\nHere\u2019s what it looked like in my terminal:\n\n```\nGoogle ORG\nGoogle ORG\nDream Host ORG\n```\nAs you can see, the podcast hosts mentioned the companies Google and Dream Host.\n\n## Conclusion\n\nThat wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at [@DeepgramAI](https://twitter.com/DeepgramAI).\n\n";
}
function compiledContent() {
  return '<p>Over the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.</p>\n<p>For example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you\u2019re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.</p>\n<p>There are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let\u2019s look at a method using diarization (FYI, there is a better way further down in this post).</p>\n<h2 id="method-1-monitor-media-mentions-in-podcasts-using-diarization-with-ai-speech-recognition">Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition</h2>\n<p>This method is interesting but not as effective as I\u2019ll show later in this post. As a quick review, <a href="https://developers.deepgram.com/documentation/features/diarize/">Deepgram\u2019s diarization feature</a> recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to <code is:raw>True</code>, a word will be assigned to each speaker in the transcript.</p>\n<p>A readable formatted transcript with the speech-to-text diarize feature may look something like this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. </span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] The faster website loads, the better off you are.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] With Google&#39;s core vital update that makes it super important to optimize your site or load time.</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.</span></span></code></pre>\n<p>In a podcast, there\u2019s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you\u2019ll notice that Speaker 1 talks the longest during that segment. This <em>could</em> indicate that\u2019s where the ad is read on behalf of the sponsor.</p>\n<p>I promised you a better way to monitor mentions in a podcast. Let\u2019s look at how that would work with Python, Deepgram\u2019s AI speech-to-text <a href="https://developers.deepgram.com/documentation/features/search/">Search feature</a>, and entity detection with SpaCy.</p>\n<h2 id="method-2-monitor-media-mentions-in-podcasts-using-search-and-entity-detection">Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection</h2>\n<p>I was curious how to come up with a way to monitor media mentions in podcasts that would do the following:</p>\n<p>Search for terms in the podcast transcript like \u201Csponsor\u201D or \u201Cpaid\u201D that indicate an ad segment\nIdentify the organizations that are talked about in the ad to determine the company sponsoring that segment\nAnd overall, not cause a bigger headache for me</p>\n<p>I needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the <a href="https://github.com/deepgram/python-sdk">Deepgram Python SDK</a>. I used the prerecorded option in this scenario to transcribe the already recorded audio. I also <a href="https://console.deepgram.com/signup?jump=keys">grabbed a Deepgram API key </a> from our console, which has gamified missions you can try to get up to speed quicker.</p>\n<p>Deepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I\u2019ll show you in the code), and speed is an advantage, so I didn\u2019t have to wait long for the transcribed audio.</p>\n<p>The Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.</p>\n<p>I added the Search feature as a parameter in the Python code like this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span></code></pre>\n<p>Since I wanted to find where the podcast hosts mentioned sponsorships, searching for the world <code is:raw>sponsor</code> made sense. Imagine them saying something like, \u201CNow a word from our sponsor\u201D.</p>\n<p>After printing the results, I received a response similar to this:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">[{</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 1.0, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 23.57, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;our sponsor&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 23.09},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.7023809, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 79.82909, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;spotify&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 79.38954},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.6279762, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 120.18001, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;stocks&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 119.740005},</span></span>\n<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.5535714, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 241.19926,</span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;focus on&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 240.92029}]</span></span></code></pre>\n<p>The response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.</p>\n<p>Next, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.</p>\n<p>SpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You\u2019ll see how that works in the next section when I break down the code.</p>\n<h3 id="python-code-breakdown-with-ai-deepgram-speech-to-text-and-spacy">Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy</h3>\n<p>The first thing I did was pip install the following Python libraries:</p>\n<p>pip install deepgram-sdk\npip install python-dotenv\npip install -U pip setuptools wheel\npip install spacy\npython3 -m spacy download en_core_web_md</p>\n<p>If you want to see the Python code that I wrote for this podcast media mentions project, please look below:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> multiprocessing.context </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> set_spawning_popen</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> spacy.pipeline </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> EntityRuler</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> spacy</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;podcast-audio-file.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">   deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   options </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span>\n<span class="line"><span style="color: #C9D1D9">   }   </span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.0</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">       source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">       response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, options)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># search for query word in transcript</span></span>\n<span class="line"><span style="color: #C9D1D9">           search_term </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;hits&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># get search_term with confidence of 1.0</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">               get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">                  </span></span>\n<span class="line"><span style="color: #C9D1D9">           transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">    get_end_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">30</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   start_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> transcript:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> get_end_start_time:</span></span>\n<span class="line"><span style="color: #C9D1D9">           start_list.append(word[</span><span style="color: #A5D6FF">&#39;punctuated_word&#39;</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   new_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(start_list)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> new_transcript</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_media_mentions</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   media_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Build upon the spaCy Medium Model</span></span>\n<span class="line"><span style="color: #C9D1D9">   nlp </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> spacy.load(</span><span style="color: #A5D6FF">&quot;en_core_web_md&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Create the EntityRuler (your competition or whichever ORG)</span></span>\n<span class="line"><span style="color: #C9D1D9">   ruler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp.add_pipe(</span><span style="color: #A5D6FF">&quot;entity_ruler&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># List of Entities and Patterns</span></span>\n<span class="line"><span style="color: #C9D1D9">   patterns </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">                   {</span><span style="color: #A5D6FF">&quot;label&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;pattern&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;Dream Host&quot;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">              ]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   ruler.add_patterns(patterns)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   doc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp(media_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E">#extract entities</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ent </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> doc.ents:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ent.label_ </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(ent.text, ent.label_)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(get_media_mentions())</span></span></code></pre>\n<p>In the <code is:raw>transcribe_ with_deepgram</code> method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <strong>prerecorded</strong> transcription option to transcribe a recorded file to text.</p>\n<p>In the <code is:raw>get_media_mentions</code> method, I\u2019m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern <code is:raw>Dream Host</code> with a corresponding label <code is:raw>ORG</code>. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.</p>\n<p>Finally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.</p>\n<p>Here\u2019s what it looked like in my terminal:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Google ORG</span></span>\n<span class="line"><span style="color: #c9d1d9">Google ORG</span></span>\n<span class="line"><span style="color: #c9d1d9">Dream Host ORG</span></span></code></pre>\n<p>As you can see, the podcast hosts mentioned the companies Google and Dream Host.</p>\n<h2 id="conclusion">Conclusion</h2>\n<p>That wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a>.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/how-to-monitor-media-mentions-in-podcasts-with-python/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>Over the last ten years, the number of people who listen to podcasts has doubled. With this increase comes more ad spending. Companies must monitor media mentions from podcast ads using AI and Python more than ever to identify which companies are mentioned, either theirs or a competitor.</p>
<p>For example, the podcasts I listen to occasionally include ads from multiple sponsors. What if you’re a company that needs to monitor media mentions in podcasts for your competitors? You need to identify what was said about these companies versus what was paid to be said. This differentiation is an important distinction.</p>
<p>There are a few ways to monitor media mentions in podcasts using AI speech-to-text and Python. Let’s look at a method using diarization (FYI, there is a better way further down in this post).</p>
<h2 id="method-1-monitor-media-mentions-in-podcasts-using-diarization-with-ai-speech-recognition">Method 1: Monitor Media Mentions in Podcasts Using Diarization with AI Speech Recognition</h2>
<p>This method is interesting but not as effective as I’ll show later in this post. As a quick review, <a href="https://developers.deepgram.com/documentation/features/diarize/">Deepgram’s diarization feature</a> recognizes speaker changes in a transcript. For example, if there are multiple speakers and diarization is set to <code>True</code>, a word will be assigned to each speaker in the transcript.</p>
<p>A readable formatted transcript with the speech-to-text diarize feature may look something like this:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">[Speaker:0] All alright, guys, before we start, we got a special message from our sponsor.</span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">[Speaker:1] If you wanna rank higher on Google, you gotta look at your page speed time. </span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">[Speaker:1] The faster website loads, the better off you are.</span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">[Speaker:1] With Google&#39;s core vital update that makes it super important to optimize your site or load time.</span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">[Speaker:1] And one easy way to do it is use the host that Eric and I use, Dream Host.</span></span></code></pre>
<p>In a podcast, there’s usually an even split time between the speakers or the hosts. The way diarization is used to monitor media mentions in podcasts is to determine if one person is a speaker for a more extended time than the other. In our above transcript example, you’ll notice that Speaker 1 talks the longest during that segment. This <em>could</em> indicate that’s where the ad is read on behalf of the sponsor.</p>
<p>I promised you a better way to monitor mentions in a podcast. Let’s look at how that would work with Python, Deepgram’s AI speech-to-text <a href="https://developers.deepgram.com/documentation/features/search/">Search feature</a>, and entity detection with SpaCy.</p>
<h2 id="method-2-monitor-media-mentions-in-podcasts-using-search-and-entity-detection">Method 2: Monitor Media Mentions in Podcasts Using Search and Entity Detection</h2>
<p>I was curious how to come up with a way to monitor media mentions in podcasts that would do the following:</p>
<p>Search for terms in the podcast transcript like “sponsor” or “paid” that indicate an ad segment
Identify the organizations that are talked about in the ad to determine the company sponsoring that segment
And overall, not cause a bigger headache for me</p>
<p>I needed to use an AI voice recognition API that would transcribe the podcast audio. That part was easy to figure out. Use the <a href="https://github.com/deepgram/python-sdk">Deepgram Python SDK</a>. I used the prerecorded option in this scenario to transcribe the already recorded audio. I also <a href="https://console.deepgram.com/signup?jump=keys">grabbed a Deepgram API key </a> from our console, which has gamified missions you can try to get up to speed quicker.</p>
<p>Deepgram is nice because it has high accuracy, and the transcript gets returned quickly. Both are important in this case. I needed accuracy to correctly flag the organizations (I’ll show you in the code), and speed is an advantage, so I didn’t have to wait long for the transcribed audio.</p>
<p>The Search feature from Deepgram was a lifesaver when working on this project. It searches for terms or phrases by matching acoustic patterns in audio, then returns the result as a JSON object.</p>
<p>I added the Search feature as a parameter in the Python code like this:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span></code></pre>
<p>Since I wanted to find where the podcast hosts mentioned sponsorships, searching for the world <code>sponsor</code> made sense. Imagine them saying something like, “Now a word from our sponsor”.</p>
<p>After printing the results, I received a response similar to this:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">[{</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 1.0, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 23.57, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;our sponsor&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 23.09},</span></span>
<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.7023809, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 79.82909, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;spotify&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 79.38954},</span></span>
<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.6279762, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 120.18001, </span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;stocks&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 119.740005},</span></span>
<span class="line"><span style="color: #C9D1D9">    {</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">: 0.5535714, </span><span style="color: #A5D6FF">&#39;end&#39;</span><span style="color: #C9D1D9">: 241.19926,</span><span style="color: #A5D6FF">&#39;snippet&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;focus on&#39;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">: 240.92029}]</span></span></code></pre>
<p>The response is a list of dictionaries with the closest match for my search term indicated by the confidence. The higher the confidence, the more likely it matches the search. This feature helped tremendously since all I had to do was pass in a word to search for in the transcript to the speech-to-text Python SDK and spit out a result.</p>
<p>Next, I used SpaCy to handle the entity detection. SpaCy is a Python library used for Machine Learning and Natural Language Processing. I was looking for a way to tag the entities in the transcribed audio as an organization.</p>
<p>SpaCy labels the recognized company entities as ORG, but I also used EntityRuler to identify lesser-known organizations. You’ll see how that works in the next section when I break down the code.</p>
<h3 id="python-code-breakdown-with-ai-deepgram-speech-to-text-and-spacy">Python Code Breakdown With AI Deepgram Speech-to-Text and SpaCy</h3>
<p>The first thing I did was pip install the following Python libraries:</p>
<p>pip install deepgram-sdk
pip install python-dotenv
pip install -U pip setuptools wheel
pip install spacy
python3 -m spacy download en_core_web_md</p>
<p>If you want to see the Python code that I wrote for this podcast media mentions project, please look below:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> multiprocessing.context </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> set_spawning_popen</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> spacy.pipeline </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> EntityRuler</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> spacy</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;podcast-audio-file.mp3&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>
<span class="line"><span style="color: #C9D1D9">   deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   options </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;sponsor&#39;</span></span>
<span class="line"><span style="color: #C9D1D9">   }   </span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.0</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Open the audio file</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>
<span class="line"><span style="color: #C9D1D9">       source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">       response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, options)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>
<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># search for query word in transcript</span></span>
<span class="line"><span style="color: #C9D1D9">           search_term </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;search&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;hits&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #8B949E"># get search_term with confidence of 1.0</span></span>
<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;confidence&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.0</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">               get_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> search_term[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">                  </span></span>
<span class="line"><span style="color: #C9D1D9">           transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;words&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">    get_end_start_time </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">30</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   start_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> transcript:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> get_start_time </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> word[</span><span style="color: #A5D6FF">&#39;start&#39;</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> get_end_start_time:</span></span>
<span class="line"><span style="color: #C9D1D9">           start_list.append(word[</span><span style="color: #A5D6FF">&#39;punctuated_word&#39;</span><span style="color: #C9D1D9">])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   new_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(start_list)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> new_transcript</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_media_mentions</span><span style="color: #C9D1D9">():</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   media_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Build upon the spaCy Medium Model</span></span>
<span class="line"><span style="color: #C9D1D9">   nlp </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> spacy.load(</span><span style="color: #A5D6FF">&quot;en_core_web_md&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Create the EntityRuler (your competition or whichever ORG)</span></span>
<span class="line"><span style="color: #C9D1D9">   ruler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp.add_pipe(</span><span style="color: #A5D6FF">&quot;entity_ruler&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># List of Entities and Patterns</span></span>
<span class="line"><span style="color: #C9D1D9">   patterns </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>
<span class="line"><span style="color: #C9D1D9">                   {</span><span style="color: #A5D6FF">&quot;label&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;pattern&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;Dream Host&quot;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">              ]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   ruler.add_patterns(patterns)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   doc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> nlp(media_transcript)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E">#extract entities</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ent </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> doc.ents:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ent.label_ </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;ORG&quot;</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(ent.text, ent.label_)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">      </span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">asyncio.run(get_media_mentions())</span></span></code></pre>
<p>In the <code>transcribe_ with_deepgram</code> method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <strong>prerecorded</strong> transcription option to transcribe a recorded file to text.</p>
<p>In the <code>get_media_mentions</code> method, I’m loading up the SpaCY medium model and creating an EntityRuler. This EntityRuler allowed me to create a pattern <code>Dream Host</code> with a corresponding label <code>ORG</code>. In this example, Dream Host is not a recognized company. Still, it is mentioned in the transcript, so I wanted to ensure the code picked it up as I monitored the media mentions in the podcast.</p>
<p>Finally, I extracted the entities and printed out the text or name of the company mentioned in the sponsored segment of the podcast and all the labels with ORG, identifying it as an organization.</p>
<p>Here’s what it looked like in my terminal:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Google ORG</span></span>
<span class="line"><span style="color: #c9d1d9">Google ORG</span></span>
<span class="line"><span style="color: #c9d1d9">Dream Host ORG</span></span></code></pre>
<p>As you can see, the podcast hosts mentioned the companies Google and Dream Host.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That wraps up this blog post on how to monitor media mentions in podcasts with Python. I hope you found this tutorial helpful. If you did or have any questions, please feel to tweet me at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a>.</p>`;
});

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
