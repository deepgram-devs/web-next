import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           */import '@storyblok/js';
/* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import 'camelcase';
import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "how-will-data-influence-the-future-of-machine-learning", "text": "How will data influence the future of machine learning?" }, { "depth": 2, "slug": "how-do-normal-machine-learning-problems-go", "text": "How do normal machine learning problems go?" }, { "depth": 3, "slug": "how-datasets-come-to-be", "text": "How datasets come to be" }, { "depth": 3, "slug": "the-challenging-link-between-data-and-privacy", "text": "The challenging link between data and privacy" }, { "depth": 3, "slug": "what-data-policies-do-we-need-what-exists", "text": "What data policies do we need? What exists?" }, { "depth": 3, "slug": "whats-the-future-going-to-hold", "text": "What\u2019s the future going to hold?" }, { "depth": 3, "slug": "what-are-the-future-datasets-going-to-be", "text": "What are the future datasets going to be?" }], "source": `<iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

**Scott:** Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:

## How will data influence the future of machine learning?

**Susan:** You know, it's a pretty key thing, as we've discussed many times before.

**Scott:** Well, you have to have the trifecta, right?

* You've got to have computing power,
* You've got to have data,
* You've got to have good models.

**Susan:** You know, I think we're starting to see some trends here.

## How do normal machine learning problems go?

**Scott:** Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That's usually how that goes. But, it isn't necessarily that the bigger the data, the better your model is going to be, right?

**Susan:** No, definitely not. Data plays a key role, and the size of data definitely helps if you've got more, but there's a lot more that goes into it. But, we're starting to see a lot of these problems evolve along a standard path. We've seen this a couple times now.

**Scott:** How do they evolve?

**Susan:** It seems like there's a couple key points in the life of a machine-learning problem. At least, I've noticed this. Have you noticed this?

**Scott:** I, probably. I don't know. I'm not sure what you're thinking.

**Susan:** Well, here's what I'm thinking, I'll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I've noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There's a lot of classic datasets that, once those were published, people could try different algorithms and compare them.

**Scott:** Yep. So if you're drawing "0, 1, 2, 3, 4, 5, 6, 7, 8, 9," just writing it. "Hey, can you recognize those?" That type of dataset. Maybe another simple one like, "What category does this fall into? Is it a human? Is it an airplane? Is it a cat?"

![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)

*[The MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database)*

**Susan:** Yeah, we've talked about [CIFAR dataset](https://en.wikipedia.org/wiki/CIFAR-10) and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We're seeing [Tensorflow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), all these standardized tools kind of follow along. But, people start standardizing: [ImageNet](http://www.image-net.org/) and stuff like that. Like, "Hey, here's eight ways to attack this problem."

> "We see the evolution of this problem go from understanding there's a problem, a classic dataset's released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time."

**Scott:** And the progress is rapid. You can look back and be like, "Wow, how did so much get accomplished?" But, it also still takes place over the span of decades. Like, [MNIST](https://en.wikipedia.org/wiki/MNIST_database), the hand written digits, was 20 years ago.

**Susan:** Maybe more.

**Scott:** Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.

**Susan:** It's pretty cool to see that we've had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they're at. It's like charting a star: "This is how old it is based on how it looks."

**Scott:** That's a good point. That's sort of based on

* How hard is the problem?
* How easy is it to get the data?
* How scintillating is the data?
* Is it something that you can find for free easily on the Internet, nicely labeled?

Images are like that a lot. It's easy to find a lot of images that are labeled. Not super easy, but you can search for a "tool" and you'll find tons of pictures of tools. Okay, that's pretty easy. But, there isn't an easy way for speech recognition to say the word, "tool." "Give me all the examples of everybody saying that word." That's a harder problem.

![Alt](https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg)

**Susan:** Well, by the time that becomes easy it probably means that the problem has been

**Scott:** Problem has been solved!

**Susan:** Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they're still kind of following that arc.

**Scott:** Well, it's not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.

**Susan:** Yes.

**Scott:** Here's the caption: "A picture of a tool."

"Oh, okay. So that probably means that's what the image is." But, that's not how it goes in audio. If you just recorded your meetings, you're not going to sit down and label all the moments.

**Susan:** No.

**Scott:** Not generally. Usually not.

**Susan:** There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.

To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.

**Scott:** Sit down, try to get it exactly. You already know what you're talking about. You already know all the vocabulary words.

**Susan:** You're the one who said it!

**Scott:** Yeah! You know your voice, right? And then you're like, "Wow, this takes a lot longer than I would expect."

### How datasets come to be

**Scott:**

* Is the data fairly easy to get?
* Is it pretty freely available?
* Is it all that hard to label?
* Is it a problem that's worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.

**Susan:** There's one more angle here that's been popping up more and more lately. That, in the early datasets, we really just didn't concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we're putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.

You thought you were anonymizing your history here, and suddenly now everybody knows what movies you've been watching. Remember [the Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)?

**Scott:** Yeah, maybe eight years ago now? It was a machine-learning prize. It was, "Get a million dollars if you're able to make a recommendation that's better than 90% accurate," or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that's how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.

![Alt](https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg) *Winners of the Netflix prize; photo: dannypeled.com*

**Susan:** It kind of did follow the same curve we were talking about earlier:

1. A big dataset was put out there
2. A bunch of different people, academics, started throwing a lot of different answers to it,
3. They finally got to an acceptable solution.

Now, from what I understand, the solution that won wasn't what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.

**Scott:** It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.

### The challenging link between data and privacy

**Susan:** This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you're getting challenges publishing it because you've got privacy concerns, that could put the brakes on a lot of problems that might be solved. There's tradeoffs here. I'm not advocating throwing out privacy, let me be very clear about this.

**Scott:** In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it's been fairly free up until recent times. [GDPR](https://eugdpr.org/) happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.

People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it'll probably work is that if you say, "No," then you probably are giving up some functionality there, because now it can't learn from you.

**Susan:** So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.

This is what you see everywhere and honestly, we're kind of at the beginning of this. We're starting to really see big legal entities come in and move and start doing this, and they think they've got enough information to start building laws and stuff like that. This is the beginning of a process that's going to take decades to shake out. So it's a huge, huge, huge thing that you have to pay attention to when dealing with this.

**Scott:** This has been in the [news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference](https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/) giving a keynote there and sort of lampooning a lot of the other tech companies, saying, "Hey, you're stepping on people's data rights."

> We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:
>
> * Tim Cook (@tim_cook) [October 24, 2018](https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw)

**Susan:** Yeah, it's interesting to see a very large company, especially one with access to so much personal data.

**Scott:** With tons of data. With machine learning groups.

**Susan:** And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.

<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

**Scott:** They've always planted a flag in the ground and said, "We are security conscious. We are data privacy conscious, et cetera," Apple has been.

Famously saying, "Hey, we're not going to give you the keys to unlock somebody who's been arrested's iPhone." Things like that.

**Susan:** I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they've been doing this but (this is the jaded side of me) I'm going to have to ...

**Scott:** You don't really believe it?

**Susan:** Well, I mean, it's kind of hard to see big companies saying that they're altruistic. I'm not saying Apple's evil or anything like that. I'm just saying you always have to take a grain of salt with a big company movement. That's a well thought out movement and they have, I'm sure, some under the hood ideas that they're not telling everybody.

**Scott:** And there's a competitive landscape that you're in as well. Hey, you're a company, other people are getting data, and maybe you are taking a stance so that you don't. Okay, now you have a competitive disadvantage.

Maybe this is why he's saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.

**Susan:** Also, [if you come out early as an advocate, knowing that it's going to go down the route of tighter and stricter laws, maybe you have more influence](https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/). Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, "Hey, make it work for me, as best as I can." So you come out waving the flag of privacy first, and you get a bit more of a voice and that's inevitable.

**Scott:** Sure.
 You want to build a company, or you want to build products, that people aren't going to hate, they're going to like, they're going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.

**Susan:** It's true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.

**Scott:** Understandably.

**Susan:** Understandably. And the complexity is growing with the complexity of the problems we're tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it's like, "Yeah, of course that's easy." We're tackling really deep, hard problems now.

Another [great dataset that just came out, Twitter](https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html).

**Scott:** Text datasets, Twitter.

**Susan:** That's a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We'll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?

Maybe we have a first dataset on there. But there's a lot of concerns with that.

### What data policies do we need? What exists?

**Scott:** So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?

**Susan:** What's the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.

**Scott:** It's like 1900 trying to talk about electricity.

**Susan:** Exactly. I mean, I think first of all, without talking about restricting what is and isn't there. Susan's personal take is, openness is the number one thing.
 Being open about what data's being collected and what it's being used for. I'm not saying restrictions anything like that, but that will help. That'll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That's the nature of the digital age. If you're more open right about now, it'll go a lot easier when the harder privacy laws inevitably start hitting.

**Scott:** If you're asking me to make a prediction, "Hey, how are people going to feel about this in the future or what's going to happen?" I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody's afraid of it. They're like, "I don't know if I'm going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I'm not going to trust anything. How could I get anything through the mail, through eBay and trust that?"

There's a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.

**Susan:**
 Fear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there's only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.

**Scott:** In the back and watch what happens.

But to answer our big question, how is data going to influence the future of machine learning? Okay, so we've got to worry about privacy, you've got the different types of machine learning. We talked a bit about text, audio, images, other stuff.

### What's the future going to hold?

**Susan:** I think that we're going to see more and more of these big data dumps trying be the cornerstone of solving a problem.

**Scott:** Like a jumping off point?

**Susan:** Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I'm already calling it The Twitter Dataset! Their name is out there and they're looking like they're doing something about this problem. So it's good PR, although it's really challenging and it can be a disaster if you do it wrong. But, we're going to see more of those cornerstone datasets come out there, help define these problems with data.

Data defining the problems. That's a big piece of what's going to shape what the machine learning world looks like five, ten years down the road.

**Scott:**
 This is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That's not really going to end because that's where all the data is. The big companies have the big data and in order to do AI well, you need big data.

**Susan:** And, people that want to solve problems want to solve problems where the problems are interesting. Early on it's interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.

**Scott:** Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it'll be very common place: "Yeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we're collecting what we're doing, and doing all the things." But, what's the new good stuff, general AI, or whatever, where's that going to be seeded? It may be in the companies, but probably more like there'll be some kind of data partnership with academic institutions or something like that.

**Susan:** You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you're going to release something.

**Scott:** Oh, yeah, like it has to fit these rules.

**Susan:** Yeah. Or, "You must have learned from this dataset, and we're going to test you against your ability to deal with these datasets."

**Scott:** Kind of an adversarial, like "If you can't deal with this, then you're not a good enough model?"

**Susan:** Well, think about judging. We'll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.

**Scott:** Answer yes or no.

**Susan:** Yeah, this becomes how to board-certify an algorithm.

**Scott:** A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There's a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it's not trade secrets or something like that, but sort of underlying ways that humans work. It's what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.

**Susan:** Yeah, it's a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.

### What are the future datasets going to be?

**Scott:** I think it's going to be interesting. I think we are just in the very beginning stages. It's like the first railroad was built across the US or something, now there's going to be 3,000 railroads. It's a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It's going to work it's way into every part of life and, at least from my perspective, people shouldn't be too afraid of it because it's going to make your life so much easier.

So as long as the path is taken in a way that isn't crazy, which, companies are pretty non-crazy now. They don't want to scare you off from being a customer. Then it's like, "Hey, this is going to evolve. It's going to make your life way easier. Things are going to be more efficient. Then, you'll just be very glad."

Similarly to text messaging or Facebook or something like that. Hey, you're giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?

**Susan:** Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they're going to drop off social media, they're going to drop off and you never hear from them again.

**Scott:** But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?

I think data obviously plays a big part now, but it's going to play a very big part in the future. You'll get your baselines set over the next few years, but then there'll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. "Hey, here's some data. Hey, we labeled it. Hey we trained a model and then it did this task."Then people will become used to it and they go, "Well, this is awesome. I don't have to do all these menial tasks anymore."

**Susan:** It gives you that bootstrap. So one more final interesting aspect of all this is people don't realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn't as targeted as you'd like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.

**Scott:** It's something to build off of. If you just have an example, you have a template, and it's like, "Okay, maybe I'll add one hour from my time to make that." Now it's a two hour dataset, and then it starts to build a community around it.

**Susan:** Yeah, these things are like little seeds. These little datasets are just seeds.

**Scott:** You've got to form it in the right way and then it grows.`, "html": '<iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" />\n<p><strong>Scott:</strong> Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:</p>\n<h2 id="how-will-data-influence-the-future-of-machine-learning">How will data influence the future of machine learning?</h2>\n<p><strong>Susan:</strong> You know, it\u2019s a pretty key thing, as we\u2019ve discussed many times before.</p>\n<p><strong>Scott:</strong> Well, you have to have the trifecta, right?</p>\n<ul>\n<li>You\u2019ve got to have computing power,</li>\n<li>You\u2019ve got to have data,</li>\n<li>You\u2019ve got to have good models.</li>\n</ul>\n<p><strong>Susan:</strong> You know, I think we\u2019re starting to see some trends here.</p>\n<h2 id="how-do-normal-machine-learning-problems-go">How do normal machine learning problems go?</h2>\n<p><strong>Scott:</strong> Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That\u2019s usually how that goes. But, it isn\u2019t necessarily that the bigger the data, the better your model is going to be, right?</p>\n<p><strong>Susan:</strong> No, definitely not. Data plays a key role, and the size of data definitely helps if you\u2019ve got more, but there\u2019s a lot more that goes into it. But, we\u2019re starting to see a lot of these problems evolve along a standard path. We\u2019ve seen this a couple times now.</p>\n<p><strong>Scott:</strong> How do they evolve?</p>\n<p><strong>Susan:</strong> It seems like there\u2019s a couple key points in the life of a machine-learning problem. At least, I\u2019ve noticed this. Have you noticed this?</p>\n<p><strong>Scott:</strong> I, probably. I don\u2019t know. I\u2019m not sure what you\u2019re thinking.</p>\n<p><strong>Susan:</strong> Well, here\u2019s what I\u2019m thinking, I\u2019ll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I\u2019ve noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There\u2019s a lot of classic datasets that, once those were published, people could try different algorithms and compare them.</p>\n<p><strong>Scott:</strong> Yep. So if you\u2019re drawing \u201C0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\u201D just writing it. \u201CHey, can you recognize those?\u201D That type of dataset. Maybe another simple one like, \u201CWhat category does this fall into? Is it a human? Is it an airplane? Is it a cat?\u201D</p>\n<p><img src="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png" alt=""></p>\n<p><em><a href="https://en.wikipedia.org/wiki/MNIST_database">The MNIST dataset</a></em></p>\n<p><strong>Susan:</strong> Yeah, we\u2019ve talked about <a href="https://en.wikipedia.org/wiki/CIFAR-10">CIFAR dataset</a> and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We\u2019re seeing <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://pytorch.org/">PyTorch</a>, all these standardized tools kind of follow along. But, people start standardizing: <a href="http://www.image-net.org/">ImageNet</a> and stuff like that. Like, \u201CHey, here\u2019s eight ways to attack this problem.\u201D</p>\n<blockquote>\n<p>\u201CWe see the evolution of this problem go from understanding there\u2019s a problem, a classic dataset\u2019s released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time.\u201D</p>\n</blockquote>\n<p><strong>Scott:</strong> And the progress is rapid. You can look back and be like, \u201CWow, how did so much get accomplished?\u201D But, it also still takes place over the span of decades. Like, <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>, the hand written digits, was 20 years ago.</p>\n<p><strong>Susan:</strong> Maybe more.</p>\n<p><strong>Scott:</strong> Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.</p>\n<p><strong>Susan:</strong> It\u2019s pretty cool to see that we\u2019ve had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they\u2019re at. It\u2019s like charting a star: \u201CThis is how old it is based on how it looks.\u201D</p>\n<p><strong>Scott:</strong> That\u2019s a good point. That\u2019s sort of based on</p>\n<ul>\n<li>How hard is the problem?</li>\n<li>How easy is it to get the data?</li>\n<li>How scintillating is the data?</li>\n<li>Is it something that you can find for free easily on the Internet, nicely labeled?</li>\n</ul>\n<p>Images are like that a lot. It\u2019s easy to find a lot of images that are labeled. Not super easy, but you can search for a \u201Ctool\u201D and you\u2019ll find tons of pictures of tools. Okay, that\u2019s pretty easy. But, there isn\u2019t an easy way for speech recognition to say the word, \u201Ctool.\u201D \u201CGive me all the examples of everybody saying that word.\u201D That\u2019s a harder problem.</p>\n<p><img src="https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg" alt="Alt"></p>\n<p><strong>Susan:</strong> Well, by the time that becomes easy it probably means that the problem has been</p>\n<p><strong>Scott:</strong> Problem has been solved!</p>\n<p><strong>Susan:</strong> Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they\u2019re still kind of following that arc.</p>\n<p><strong>Scott:</strong> Well, it\u2019s not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.</p>\n<p><strong>Susan:</strong> Yes.</p>\n<p><strong>Scott:</strong> Here\u2019s the caption: \u201CA picture of a tool.\u201D</p>\n<p>\u201COh, okay. So that probably means that\u2019s what the image is.\u201D But, that\u2019s not how it goes in audio. If you just recorded your meetings, you\u2019re not going to sit down and label all the moments.</p>\n<p><strong>Susan:</strong> No.</p>\n<p><strong>Scott:</strong> Not generally. Usually not.</p>\n<p><strong>Susan:</strong> There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.</p>\n<p>To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.</p>\n<p><strong>Scott:</strong> Sit down, try to get it exactly. You already know what you\u2019re talking about. You already know all the vocabulary words.</p>\n<p><strong>Susan:</strong> You\u2019re the one who said it!</p>\n<p><strong>Scott:</strong> Yeah! You know your voice, right? And then you\u2019re like, \u201CWow, this takes a lot longer than I would expect.\u201D</p>\n<h3 id="how-datasets-come-to-be">How datasets come to be</h3>\n<p><strong>Scott:</strong></p>\n<ul>\n<li>Is the data fairly easy to get?</li>\n<li>Is it pretty freely available?</li>\n<li>Is it all that hard to label?</li>\n<li>Is it a problem that\u2019s worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.</li>\n</ul>\n<p><strong>Susan:</strong> There\u2019s one more angle here that\u2019s been popping up more and more lately. That, in the early datasets, we really just didn\u2019t concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we\u2019re putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.</p>\n<p>You thought you were anonymizing your history here, and suddenly now everybody knows what movies you\u2019ve been watching. Remember <a href="https://en.wikipedia.org/wiki/Netflix_Prize">the Netflix prize</a>?</p>\n<p><strong>Scott:</strong> Yeah, maybe eight years ago now? It was a machine-learning prize. It was, \u201CGet a million dollars if you\u2019re able to make a recommendation that\u2019s better than 90% accurate,\u201D or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that\u2019s how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.</p>\n<p><img src="https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg" alt="Alt"> <em>Winners of the Netflix prize; photo: dannypeled.com</em></p>\n<p><strong>Susan:</strong> It kind of did follow the same curve we were talking about earlier:</p>\n<ol>\n<li>A big dataset was put out there</li>\n<li>A bunch of different people, academics, started throwing a lot of different answers to it,</li>\n<li>They finally got to an acceptable solution.</li>\n</ol>\n<p>Now, from what I understand, the solution that won wasn\u2019t what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.</p>\n<p><strong>Scott:</strong> It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.</p>\n<h3 id="the-challenging-link-between-data-and-privacy">The challenging link between data and privacy</h3>\n<p><strong>Susan:</strong> This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you\u2019re getting challenges publishing it because you\u2019ve got privacy concerns, that could put the brakes on a lot of problems that might be solved. There\u2019s tradeoffs here. I\u2019m not advocating throwing out privacy, let me be very clear about this.</p>\n<p><strong>Scott:</strong> In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it\u2019s been fairly free up until recent times. <a href="https://eugdpr.org/">GDPR</a> happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.</p>\n<p>People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it\u2019ll probably work is that if you say, \u201CNo,\u201D then you probably are giving up some functionality there, because now it can\u2019t learn from you.</p>\n<p><strong>Susan:</strong> So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.</p>\n<p>This is what you see everywhere and honestly, we\u2019re kind of at the beginning of this. We\u2019re starting to really see big legal entities come in and move and start doing this, and they think they\u2019ve got enough information to start building laws and stuff like that. This is the beginning of a process that\u2019s going to take decades to shake out. So it\u2019s a huge, huge, huge thing that you have to pay attention to when dealing with this.</p>\n<p><strong>Scott:</strong> This has been in the <a href="https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/">news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference</a> giving a keynote there and sort of lampooning a lot of the other tech companies, saying, \u201CHey, you\u2019re stepping on people\u2019s data rights.\u201D</p>\n<blockquote>\n<p>We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:</p>\n<ul>\n<li>Tim Cook (@tim_cook) <a href="https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw">October 24, 2018</a></li>\n</ul>\n</blockquote>\n<p><strong>Susan:</strong> Yeah, it\u2019s interesting to see a very large company, especially one with access to so much personal data.</p>\n<p><strong>Scott:</strong> With tons of data. With machine learning groups.</p>\n<p><strong>Susan:</strong> And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.</p>\n<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" />\n<p><strong>Scott:</strong> They\u2019ve always planted a flag in the ground and said, \u201CWe are security conscious. We are data privacy conscious, et cetera,\u201D Apple has been.</p>\n<p>Famously saying, \u201CHey, we\u2019re not going to give you the keys to unlock somebody who\u2019s been arrested\u2019s iPhone.\u201D Things like that.</p>\n<p><strong>Susan:</strong> I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they\u2019ve been doing this but (this is the jaded side of me) I\u2019m going to have to \u2026</p>\n<p><strong>Scott:</strong> You don\u2019t really believe it?</p>\n<p><strong>Susan:</strong> Well, I mean, it\u2019s kind of hard to see big companies saying that they\u2019re altruistic. I\u2019m not saying Apple\u2019s evil or anything like that. I\u2019m just saying you always have to take a grain of salt with a big company movement. That\u2019s a well thought out movement and they have, I\u2019m sure, some under the hood ideas that they\u2019re not telling everybody.</p>\n<p><strong>Scott:</strong> And there\u2019s a competitive landscape that you\u2019re in as well. Hey, you\u2019re a company, other people are getting data, and maybe you are taking a stance so that you don\u2019t. Okay, now you have a competitive disadvantage.</p>\n<p>Maybe this is why he\u2019s saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.</p>\n<p><strong>Susan:</strong> Also, <a href="https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/">if you come out early as an advocate, knowing that it\u2019s going to go down the route of tighter and stricter laws, maybe you have more influence</a>. Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, \u201CHey, make it work for me, as best as I can.\u201D So you come out waving the flag of privacy first, and you get a bit more of a voice and that\u2019s inevitable.</p>\n<p><strong>Scott:</strong> Sure.\nYou want to build a company, or you want to build products, that people aren\u2019t going to hate, they\u2019re going to like, they\u2019re going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.</p>\n<p><strong>Susan:</strong> It\u2019s true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.</p>\n<p><strong>Scott:</strong> Understandably.</p>\n<p><strong>Susan:</strong> Understandably. And the complexity is growing with the complexity of the problems we\u2019re tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it\u2019s like, \u201CYeah, of course that\u2019s easy.\u201D We\u2019re tackling really deep, hard problems now.</p>\n<p>Another <a href="https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html">great dataset that just came out, Twitter</a>.</p>\n<p><strong>Scott:</strong> Text datasets, Twitter.</p>\n<p><strong>Susan:</strong> That\u2019s a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We\u2019ll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?</p>\n<p>Maybe we have a first dataset on there. But there\u2019s a lot of concerns with that.</p>\n<h3 id="what-data-policies-do-we-need-what-exists">What data policies do we need? What exists?</h3>\n<p><strong>Scott:</strong> So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?</p>\n<p><strong>Susan:</strong> What\u2019s the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.</p>\n<p><strong>Scott:</strong> It\u2019s like 1900 trying to talk about electricity.</p>\n<p><strong>Susan:</strong> Exactly. I mean, I think first of all, without talking about restricting what is and isn\u2019t there. Susan\u2019s personal take is, openness is the number one thing.\nBeing open about what data\u2019s being collected and what it\u2019s being used for. I\u2019m not saying restrictions anything like that, but that will help. That\u2019ll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That\u2019s the nature of the digital age. If you\u2019re more open right about now, it\u2019ll go a lot easier when the harder privacy laws inevitably start hitting.</p>\n<p><strong>Scott:</strong> If you\u2019re asking me to make a prediction, \u201CHey, how are people going to feel about this in the future or what\u2019s going to happen?\u201D I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody\u2019s afraid of it. They\u2019re like, \u201CI don\u2019t know if I\u2019m going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I\u2019m not going to trust anything. How could I get anything through the mail, through eBay and trust that?\u201D</p>\n<p>There\u2019s a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.</p>\n<p><strong>Susan:</strong>\nFear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there\u2019s only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.</p>\n<p><strong>Scott:</strong> In the back and watch what happens.</p>\n<p>But to answer our big question, how is data going to influence the future of machine learning? Okay, so we\u2019ve got to worry about privacy, you\u2019ve got the different types of machine learning. We talked a bit about text, audio, images, other stuff.</p>\n<h3 id="whats-the-future-going-to-hold">What\u2019s the future going to hold?</h3>\n<p><strong>Susan:</strong> I think that we\u2019re going to see more and more of these big data dumps trying be the cornerstone of solving a problem.</p>\n<p><strong>Scott:</strong> Like a jumping off point?</p>\n<p><strong>Susan:</strong> Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I\u2019m already calling it The Twitter Dataset! Their name is out there and they\u2019re looking like they\u2019re doing something about this problem. So it\u2019s good PR, although it\u2019s really challenging and it can be a disaster if you do it wrong. But, we\u2019re going to see more of those cornerstone datasets come out there, help define these problems with data.</p>\n<p>Data defining the problems. That\u2019s a big piece of what\u2019s going to shape what the machine learning world looks like five, ten years down the road.</p>\n<p><strong>Scott:</strong>\nThis is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That\u2019s not really going to end because that\u2019s where all the data is. The big companies have the big data and in order to do AI well, you need big data.</p>\n<p><strong>Susan:</strong> And, people that want to solve problems want to solve problems where the problems are interesting. Early on it\u2019s interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.</p>\n<p><strong>Scott:</strong> Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it\u2019ll be very common place: \u201CYeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we\u2019re collecting what we\u2019re doing, and doing all the things.\u201D But, what\u2019s the new good stuff, general AI, or whatever, where\u2019s that going to be seeded? It may be in the companies, but probably more like there\u2019ll be some kind of data partnership with academic institutions or something like that.</p>\n<p><strong>Susan:</strong> You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you\u2019re going to release something.</p>\n<p><strong>Scott:</strong> Oh, yeah, like it has to fit these rules.</p>\n<p><strong>Susan:</strong> Yeah. Or, \u201CYou must have learned from this dataset, and we\u2019re going to test you against your ability to deal with these datasets.\u201D</p>\n<p><strong>Scott:</strong> Kind of an adversarial, like \u201CIf you can\u2019t deal with this, then you\u2019re not a good enough model?\u201D</p>\n<p><strong>Susan:</strong> Well, think about judging. We\u2019ll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.</p>\n<p><strong>Scott:</strong> Answer yes or no.</p>\n<p><strong>Susan:</strong> Yeah, this becomes how to board-certify an algorithm.</p>\n<p><strong>Scott:</strong> A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There\u2019s a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it\u2019s not trade secrets or something like that, but sort of underlying ways that humans work. It\u2019s what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.</p>\n<p><strong>Susan:</strong> Yeah, it\u2019s a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.</p>\n<h3 id="what-are-the-future-datasets-going-to-be">What are the future datasets going to be?</h3>\n<p><strong>Scott:</strong> I think it\u2019s going to be interesting. I think we are just in the very beginning stages. It\u2019s like the first railroad was built across the US or something, now there\u2019s going to be 3,000 railroads. It\u2019s a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It\u2019s going to work it\u2019s way into every part of life and, at least from my perspective, people shouldn\u2019t be too afraid of it because it\u2019s going to make your life so much easier.</p>\n<p>So as long as the path is taken in a way that isn\u2019t crazy, which, companies are pretty non-crazy now. They don\u2019t want to scare you off from being a customer. Then it\u2019s like, \u201CHey, this is going to evolve. It\u2019s going to make your life way easier. Things are going to be more efficient. Then, you\u2019ll just be very glad.\u201D</p>\n<p>Similarly to text messaging or Facebook or something like that. Hey, you\u2019re giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?</p>\n<p><strong>Susan:</strong> Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they\u2019re going to drop off social media, they\u2019re going to drop off and you never hear from them again.</p>\n<p><strong>Scott:</strong> But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?</p>\n<p>I think data obviously plays a big part now, but it\u2019s going to play a very big part in the future. You\u2019ll get your baselines set over the next few years, but then there\u2019ll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. \u201CHey, here\u2019s some data. Hey, we labeled it. Hey we trained a model and then it did this task.\u201DThen people will become used to it and they go, \u201CWell, this is awesome. I don\u2019t have to do all these menial tasks anymore.\u201D</p>\n<p><strong>Susan:</strong> It gives you that bootstrap. So one more final interesting aspect of all this is people don\u2019t realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn\u2019t as targeted as you\u2019d like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.</p>\n<p><strong>Scott:</strong> It\u2019s something to build off of. If you just have an example, you have a template, and it\u2019s like, \u201COkay, maybe I\u2019ll add one hour from my time to make that.\u201D Now it\u2019s a two hour dataset, and then it starts to build a community around it.</p>\n<p><strong>Susan:</strong> Yeah, these things are like little seeds. These little datasets are just seeds.</p>\n<p><strong>Scott:</strong> You\u2019ve got to form it in the right way and then it grows.</p>' };
const frontmatter = { "title": "How Will Data Influence the Future of Machine Learning? \u2014 AI Show", "description": "Curious about what the future of data looks like for machine learning? Check out this episode of the AI Show!", "date": "2018-10-26T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661981323/blog/ai-show-how-will-data-influence-the-future-of-machine-learning/how-will-data-influence-future-ML%402x.jpg", "authors": ["natalie-rutgers"], "category": "ai-and-engineering", "tags": ["machine-learning"], "seo": { "title": "How will data influence the future of machine learning? \u2014 AI Show", "description": "" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661981323/blog/ai-show-how-will-data-influence-the-future-of-machine-learning/how-will-data-influence-future-ML%402x.jpg" }, "shorturls": { "share": "https://dpgr.am/dcc16aa", "twitter": "https://dpgr.am/fccf518", "linkedin": "https://dpgr.am/7f19b8b", "reddit": "https://dpgr.am/b9410a7", "facebook": "https://dpgr.am/2b63b3d" }, "astro": { "headings": [{ "depth": 2, "slug": "how-will-data-influence-the-future-of-machine-learning", "text": "How will data influence the future of machine learning?" }, { "depth": 2, "slug": "how-do-normal-machine-learning-problems-go", "text": "How do normal machine learning problems go?" }, { "depth": 3, "slug": "how-datasets-come-to-be", "text": "How datasets come to be" }, { "depth": 3, "slug": "the-challenging-link-between-data-and-privacy", "text": "The challenging link between data and privacy" }, { "depth": 3, "slug": "what-data-policies-do-we-need-what-exists", "text": "What data policies do we need? What exists?" }, { "depth": 3, "slug": "whats-the-future-going-to-hold", "text": "What\u2019s the future going to hold?" }, { "depth": 3, "slug": "what-are-the-future-datasets-going-to-be", "text": "What are the future datasets going to be?" }], "source": `<iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

**Scott:** Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:

## How will data influence the future of machine learning?

**Susan:** You know, it's a pretty key thing, as we've discussed many times before.

**Scott:** Well, you have to have the trifecta, right?

* You've got to have computing power,
* You've got to have data,
* You've got to have good models.

**Susan:** You know, I think we're starting to see some trends here.

## How do normal machine learning problems go?

**Scott:** Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That's usually how that goes. But, it isn't necessarily that the bigger the data, the better your model is going to be, right?

**Susan:** No, definitely not. Data plays a key role, and the size of data definitely helps if you've got more, but there's a lot more that goes into it. But, we're starting to see a lot of these problems evolve along a standard path. We've seen this a couple times now.

**Scott:** How do they evolve?

**Susan:** It seems like there's a couple key points in the life of a machine-learning problem. At least, I've noticed this. Have you noticed this?

**Scott:** I, probably. I don't know. I'm not sure what you're thinking.

**Susan:** Well, here's what I'm thinking, I'll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I've noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There's a lot of classic datasets that, once those were published, people could try different algorithms and compare them.

**Scott:** Yep. So if you're drawing "0, 1, 2, 3, 4, 5, 6, 7, 8, 9," just writing it. "Hey, can you recognize those?" That type of dataset. Maybe another simple one like, "What category does this fall into? Is it a human? Is it an airplane? Is it a cat?"

![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)

*[The MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database)*

**Susan:** Yeah, we've talked about [CIFAR dataset](https://en.wikipedia.org/wiki/CIFAR-10) and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We're seeing [Tensorflow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), all these standardized tools kind of follow along. But, people start standardizing: [ImageNet](http://www.image-net.org/) and stuff like that. Like, "Hey, here's eight ways to attack this problem."

> "We see the evolution of this problem go from understanding there's a problem, a classic dataset's released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time."

**Scott:** And the progress is rapid. You can look back and be like, "Wow, how did so much get accomplished?" But, it also still takes place over the span of decades. Like, [MNIST](https://en.wikipedia.org/wiki/MNIST_database), the hand written digits, was 20 years ago.

**Susan:** Maybe more.

**Scott:** Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.

**Susan:** It's pretty cool to see that we've had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they're at. It's like charting a star: "This is how old it is based on how it looks."

**Scott:** That's a good point. That's sort of based on

* How hard is the problem?
* How easy is it to get the data?
* How scintillating is the data?
* Is it something that you can find for free easily on the Internet, nicely labeled?

Images are like that a lot. It's easy to find a lot of images that are labeled. Not super easy, but you can search for a "tool" and you'll find tons of pictures of tools. Okay, that's pretty easy. But, there isn't an easy way for speech recognition to say the word, "tool." "Give me all the examples of everybody saying that word." That's a harder problem.

![Alt](https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg)

**Susan:** Well, by the time that becomes easy it probably means that the problem has been

**Scott:** Problem has been solved!

**Susan:** Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they're still kind of following that arc.

**Scott:** Well, it's not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.

**Susan:** Yes.

**Scott:** Here's the caption: "A picture of a tool."

"Oh, okay. So that probably means that's what the image is." But, that's not how it goes in audio. If you just recorded your meetings, you're not going to sit down and label all the moments.

**Susan:** No.

**Scott:** Not generally. Usually not.

**Susan:** There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.

To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.

**Scott:** Sit down, try to get it exactly. You already know what you're talking about. You already know all the vocabulary words.

**Susan:** You're the one who said it!

**Scott:** Yeah! You know your voice, right? And then you're like, "Wow, this takes a lot longer than I would expect."

### How datasets come to be

**Scott:**

* Is the data fairly easy to get?
* Is it pretty freely available?
* Is it all that hard to label?
* Is it a problem that's worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.

**Susan:** There's one more angle here that's been popping up more and more lately. That, in the early datasets, we really just didn't concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we're putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.

You thought you were anonymizing your history here, and suddenly now everybody knows what movies you've been watching. Remember [the Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)?

**Scott:** Yeah, maybe eight years ago now? It was a machine-learning prize. It was, "Get a million dollars if you're able to make a recommendation that's better than 90% accurate," or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that's how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.

![Alt](https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg) *Winners of the Netflix prize; photo: dannypeled.com*

**Susan:** It kind of did follow the same curve we were talking about earlier:

1. A big dataset was put out there
2. A bunch of different people, academics, started throwing a lot of different answers to it,
3. They finally got to an acceptable solution.

Now, from what I understand, the solution that won wasn't what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.

**Scott:** It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.

### The challenging link between data and privacy

**Susan:** This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you're getting challenges publishing it because you've got privacy concerns, that could put the brakes on a lot of problems that might be solved. There's tradeoffs here. I'm not advocating throwing out privacy, let me be very clear about this.

**Scott:** In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it's been fairly free up until recent times. [GDPR](https://eugdpr.org/) happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.

People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it'll probably work is that if you say, "No," then you probably are giving up some functionality there, because now it can't learn from you.

**Susan:** So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.

This is what you see everywhere and honestly, we're kind of at the beginning of this. We're starting to really see big legal entities come in and move and start doing this, and they think they've got enough information to start building laws and stuff like that. This is the beginning of a process that's going to take decades to shake out. So it's a huge, huge, huge thing that you have to pay attention to when dealing with this.

**Scott:** This has been in the [news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference](https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/) giving a keynote there and sort of lampooning a lot of the other tech companies, saying, "Hey, you're stepping on people's data rights."

> We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:
>
> * Tim Cook (@tim_cook) [October 24, 2018](https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw)

**Susan:** Yeah, it's interesting to see a very large company, especially one with access to so much personal data.

**Scott:** With tons of data. With machine learning groups.

**Susan:** And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.

<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

**Scott:** They've always planted a flag in the ground and said, "We are security conscious. We are data privacy conscious, et cetera," Apple has been.

Famously saying, "Hey, we're not going to give you the keys to unlock somebody who's been arrested's iPhone." Things like that.

**Susan:** I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they've been doing this but (this is the jaded side of me) I'm going to have to ...

**Scott:** You don't really believe it?

**Susan:** Well, I mean, it's kind of hard to see big companies saying that they're altruistic. I'm not saying Apple's evil or anything like that. I'm just saying you always have to take a grain of salt with a big company movement. That's a well thought out movement and they have, I'm sure, some under the hood ideas that they're not telling everybody.

**Scott:** And there's a competitive landscape that you're in as well. Hey, you're a company, other people are getting data, and maybe you are taking a stance so that you don't. Okay, now you have a competitive disadvantage.

Maybe this is why he's saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.

**Susan:** Also, [if you come out early as an advocate, knowing that it's going to go down the route of tighter and stricter laws, maybe you have more influence](https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/). Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, "Hey, make it work for me, as best as I can." So you come out waving the flag of privacy first, and you get a bit more of a voice and that's inevitable.

**Scott:** Sure.
 You want to build a company, or you want to build products, that people aren't going to hate, they're going to like, they're going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.

**Susan:** It's true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.

**Scott:** Understandably.

**Susan:** Understandably. And the complexity is growing with the complexity of the problems we're tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it's like, "Yeah, of course that's easy." We're tackling really deep, hard problems now.

Another [great dataset that just came out, Twitter](https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html).

**Scott:** Text datasets, Twitter.

**Susan:** That's a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We'll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?

Maybe we have a first dataset on there. But there's a lot of concerns with that.

### What data policies do we need? What exists?

**Scott:** So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?

**Susan:** What's the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.

**Scott:** It's like 1900 trying to talk about electricity.

**Susan:** Exactly. I mean, I think first of all, without talking about restricting what is and isn't there. Susan's personal take is, openness is the number one thing.
 Being open about what data's being collected and what it's being used for. I'm not saying restrictions anything like that, but that will help. That'll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That's the nature of the digital age. If you're more open right about now, it'll go a lot easier when the harder privacy laws inevitably start hitting.

**Scott:** If you're asking me to make a prediction, "Hey, how are people going to feel about this in the future or what's going to happen?" I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody's afraid of it. They're like, "I don't know if I'm going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I'm not going to trust anything. How could I get anything through the mail, through eBay and trust that?"

There's a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.

**Susan:**
 Fear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there's only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.

**Scott:** In the back and watch what happens.

But to answer our big question, how is data going to influence the future of machine learning? Okay, so we've got to worry about privacy, you've got the different types of machine learning. We talked a bit about text, audio, images, other stuff.

### What's the future going to hold?

**Susan:** I think that we're going to see more and more of these big data dumps trying be the cornerstone of solving a problem.

**Scott:** Like a jumping off point?

**Susan:** Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I'm already calling it The Twitter Dataset! Their name is out there and they're looking like they're doing something about this problem. So it's good PR, although it's really challenging and it can be a disaster if you do it wrong. But, we're going to see more of those cornerstone datasets come out there, help define these problems with data.

Data defining the problems. That's a big piece of what's going to shape what the machine learning world looks like five, ten years down the road.

**Scott:**
 This is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That's not really going to end because that's where all the data is. The big companies have the big data and in order to do AI well, you need big data.

**Susan:** And, people that want to solve problems want to solve problems where the problems are interesting. Early on it's interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.

**Scott:** Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it'll be very common place: "Yeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we're collecting what we're doing, and doing all the things." But, what's the new good stuff, general AI, or whatever, where's that going to be seeded? It may be in the companies, but probably more like there'll be some kind of data partnership with academic institutions or something like that.

**Susan:** You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you're going to release something.

**Scott:** Oh, yeah, like it has to fit these rules.

**Susan:** Yeah. Or, "You must have learned from this dataset, and we're going to test you against your ability to deal with these datasets."

**Scott:** Kind of an adversarial, like "If you can't deal with this, then you're not a good enough model?"

**Susan:** Well, think about judging. We'll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.

**Scott:** Answer yes or no.

**Susan:** Yeah, this becomes how to board-certify an algorithm.

**Scott:** A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There's a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it's not trade secrets or something like that, but sort of underlying ways that humans work. It's what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.

**Susan:** Yeah, it's a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.

### What are the future datasets going to be?

**Scott:** I think it's going to be interesting. I think we are just in the very beginning stages. It's like the first railroad was built across the US or something, now there's going to be 3,000 railroads. It's a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It's going to work it's way into every part of life and, at least from my perspective, people shouldn't be too afraid of it because it's going to make your life so much easier.

So as long as the path is taken in a way that isn't crazy, which, companies are pretty non-crazy now. They don't want to scare you off from being a customer. Then it's like, "Hey, this is going to evolve. It's going to make your life way easier. Things are going to be more efficient. Then, you'll just be very glad."

Similarly to text messaging or Facebook or something like that. Hey, you're giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?

**Susan:** Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they're going to drop off social media, they're going to drop off and you never hear from them again.

**Scott:** But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?

I think data obviously plays a big part now, but it's going to play a very big part in the future. You'll get your baselines set over the next few years, but then there'll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. "Hey, here's some data. Hey, we labeled it. Hey we trained a model and then it did this task."Then people will become used to it and they go, "Well, this is awesome. I don't have to do all these menial tasks anymore."

**Susan:** It gives you that bootstrap. So one more final interesting aspect of all this is people don't realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn't as targeted as you'd like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.

**Scott:** It's something to build off of. If you just have an example, you have a template, and it's like, "Okay, maybe I'll add one hour from my time to make that." Now it's a two hour dataset, and then it starts to build a community around it.

**Susan:** Yeah, these things are like little seeds. These little datasets are just seeds.

**Scott:** You've got to form it in the right way and then it grows.`, "html": '<iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" />\n<p><strong>Scott:</strong> Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:</p>\n<h2 id="how-will-data-influence-the-future-of-machine-learning">How will data influence the future of machine learning?</h2>\n<p><strong>Susan:</strong> You know, it\u2019s a pretty key thing, as we\u2019ve discussed many times before.</p>\n<p><strong>Scott:</strong> Well, you have to have the trifecta, right?</p>\n<ul>\n<li>You\u2019ve got to have computing power,</li>\n<li>You\u2019ve got to have data,</li>\n<li>You\u2019ve got to have good models.</li>\n</ul>\n<p><strong>Susan:</strong> You know, I think we\u2019re starting to see some trends here.</p>\n<h2 id="how-do-normal-machine-learning-problems-go">How do normal machine learning problems go?</h2>\n<p><strong>Scott:</strong> Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That\u2019s usually how that goes. But, it isn\u2019t necessarily that the bigger the data, the better your model is going to be, right?</p>\n<p><strong>Susan:</strong> No, definitely not. Data plays a key role, and the size of data definitely helps if you\u2019ve got more, but there\u2019s a lot more that goes into it. But, we\u2019re starting to see a lot of these problems evolve along a standard path. We\u2019ve seen this a couple times now.</p>\n<p><strong>Scott:</strong> How do they evolve?</p>\n<p><strong>Susan:</strong> It seems like there\u2019s a couple key points in the life of a machine-learning problem. At least, I\u2019ve noticed this. Have you noticed this?</p>\n<p><strong>Scott:</strong> I, probably. I don\u2019t know. I\u2019m not sure what you\u2019re thinking.</p>\n<p><strong>Susan:</strong> Well, here\u2019s what I\u2019m thinking, I\u2019ll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I\u2019ve noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There\u2019s a lot of classic datasets that, once those were published, people could try different algorithms and compare them.</p>\n<p><strong>Scott:</strong> Yep. So if you\u2019re drawing \u201C0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\u201D just writing it. \u201CHey, can you recognize those?\u201D That type of dataset. Maybe another simple one like, \u201CWhat category does this fall into? Is it a human? Is it an airplane? Is it a cat?\u201D</p>\n<p><img src="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png" alt=""></p>\n<p><em><a href="https://en.wikipedia.org/wiki/MNIST_database">The MNIST dataset</a></em></p>\n<p><strong>Susan:</strong> Yeah, we\u2019ve talked about <a href="https://en.wikipedia.org/wiki/CIFAR-10">CIFAR dataset</a> and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We\u2019re seeing <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://pytorch.org/">PyTorch</a>, all these standardized tools kind of follow along. But, people start standardizing: <a href="http://www.image-net.org/">ImageNet</a> and stuff like that. Like, \u201CHey, here\u2019s eight ways to attack this problem.\u201D</p>\n<blockquote>\n<p>\u201CWe see the evolution of this problem go from understanding there\u2019s a problem, a classic dataset\u2019s released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time.\u201D</p>\n</blockquote>\n<p><strong>Scott:</strong> And the progress is rapid. You can look back and be like, \u201CWow, how did so much get accomplished?\u201D But, it also still takes place over the span of decades. Like, <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>, the hand written digits, was 20 years ago.</p>\n<p><strong>Susan:</strong> Maybe more.</p>\n<p><strong>Scott:</strong> Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.</p>\n<p><strong>Susan:</strong> It\u2019s pretty cool to see that we\u2019ve had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they\u2019re at. It\u2019s like charting a star: \u201CThis is how old it is based on how it looks.\u201D</p>\n<p><strong>Scott:</strong> That\u2019s a good point. That\u2019s sort of based on</p>\n<ul>\n<li>How hard is the problem?</li>\n<li>How easy is it to get the data?</li>\n<li>How scintillating is the data?</li>\n<li>Is it something that you can find for free easily on the Internet, nicely labeled?</li>\n</ul>\n<p>Images are like that a lot. It\u2019s easy to find a lot of images that are labeled. Not super easy, but you can search for a \u201Ctool\u201D and you\u2019ll find tons of pictures of tools. Okay, that\u2019s pretty easy. But, there isn\u2019t an easy way for speech recognition to say the word, \u201Ctool.\u201D \u201CGive me all the examples of everybody saying that word.\u201D That\u2019s a harder problem.</p>\n<p><img src="https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg" alt="Alt"></p>\n<p><strong>Susan:</strong> Well, by the time that becomes easy it probably means that the problem has been</p>\n<p><strong>Scott:</strong> Problem has been solved!</p>\n<p><strong>Susan:</strong> Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they\u2019re still kind of following that arc.</p>\n<p><strong>Scott:</strong> Well, it\u2019s not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.</p>\n<p><strong>Susan:</strong> Yes.</p>\n<p><strong>Scott:</strong> Here\u2019s the caption: \u201CA picture of a tool.\u201D</p>\n<p>\u201COh, okay. So that probably means that\u2019s what the image is.\u201D But, that\u2019s not how it goes in audio. If you just recorded your meetings, you\u2019re not going to sit down and label all the moments.</p>\n<p><strong>Susan:</strong> No.</p>\n<p><strong>Scott:</strong> Not generally. Usually not.</p>\n<p><strong>Susan:</strong> There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.</p>\n<p>To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.</p>\n<p><strong>Scott:</strong> Sit down, try to get it exactly. You already know what you\u2019re talking about. You already know all the vocabulary words.</p>\n<p><strong>Susan:</strong> You\u2019re the one who said it!</p>\n<p><strong>Scott:</strong> Yeah! You know your voice, right? And then you\u2019re like, \u201CWow, this takes a lot longer than I would expect.\u201D</p>\n<h3 id="how-datasets-come-to-be">How datasets come to be</h3>\n<p><strong>Scott:</strong></p>\n<ul>\n<li>Is the data fairly easy to get?</li>\n<li>Is it pretty freely available?</li>\n<li>Is it all that hard to label?</li>\n<li>Is it a problem that\u2019s worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.</li>\n</ul>\n<p><strong>Susan:</strong> There\u2019s one more angle here that\u2019s been popping up more and more lately. That, in the early datasets, we really just didn\u2019t concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we\u2019re putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.</p>\n<p>You thought you were anonymizing your history here, and suddenly now everybody knows what movies you\u2019ve been watching. Remember <a href="https://en.wikipedia.org/wiki/Netflix_Prize">the Netflix prize</a>?</p>\n<p><strong>Scott:</strong> Yeah, maybe eight years ago now? It was a machine-learning prize. It was, \u201CGet a million dollars if you\u2019re able to make a recommendation that\u2019s better than 90% accurate,\u201D or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that\u2019s how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.</p>\n<p><img src="https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg" alt="Alt"> <em>Winners of the Netflix prize; photo: dannypeled.com</em></p>\n<p><strong>Susan:</strong> It kind of did follow the same curve we were talking about earlier:</p>\n<ol>\n<li>A big dataset was put out there</li>\n<li>A bunch of different people, academics, started throwing a lot of different answers to it,</li>\n<li>They finally got to an acceptable solution.</li>\n</ol>\n<p>Now, from what I understand, the solution that won wasn\u2019t what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.</p>\n<p><strong>Scott:</strong> It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.</p>\n<h3 id="the-challenging-link-between-data-and-privacy">The challenging link between data and privacy</h3>\n<p><strong>Susan:</strong> This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you\u2019re getting challenges publishing it because you\u2019ve got privacy concerns, that could put the brakes on a lot of problems that might be solved. There\u2019s tradeoffs here. I\u2019m not advocating throwing out privacy, let me be very clear about this.</p>\n<p><strong>Scott:</strong> In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it\u2019s been fairly free up until recent times. <a href="https://eugdpr.org/">GDPR</a> happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.</p>\n<p>People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it\u2019ll probably work is that if you say, \u201CNo,\u201D then you probably are giving up some functionality there, because now it can\u2019t learn from you.</p>\n<p><strong>Susan:</strong> So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.</p>\n<p>This is what you see everywhere and honestly, we\u2019re kind of at the beginning of this. We\u2019re starting to really see big legal entities come in and move and start doing this, and they think they\u2019ve got enough information to start building laws and stuff like that. This is the beginning of a process that\u2019s going to take decades to shake out. So it\u2019s a huge, huge, huge thing that you have to pay attention to when dealing with this.</p>\n<p><strong>Scott:</strong> This has been in the <a href="https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/">news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference</a> giving a keynote there and sort of lampooning a lot of the other tech companies, saying, \u201CHey, you\u2019re stepping on people\u2019s data rights.\u201D</p>\n<blockquote>\n<p>We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:</p>\n<ul>\n<li>Tim Cook (@tim_cook) <a href="https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw">October 24, 2018</a></li>\n</ul>\n</blockquote>\n<p><strong>Susan:</strong> Yeah, it\u2019s interesting to see a very large company, especially one with access to so much personal data.</p>\n<p><strong>Scott:</strong> With tons of data. With machine learning groups.</p>\n<p><strong>Susan:</strong> And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.</p>\n<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" />\n<p><strong>Scott:</strong> They\u2019ve always planted a flag in the ground and said, \u201CWe are security conscious. We are data privacy conscious, et cetera,\u201D Apple has been.</p>\n<p>Famously saying, \u201CHey, we\u2019re not going to give you the keys to unlock somebody who\u2019s been arrested\u2019s iPhone.\u201D Things like that.</p>\n<p><strong>Susan:</strong> I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they\u2019ve been doing this but (this is the jaded side of me) I\u2019m going to have to \u2026</p>\n<p><strong>Scott:</strong> You don\u2019t really believe it?</p>\n<p><strong>Susan:</strong> Well, I mean, it\u2019s kind of hard to see big companies saying that they\u2019re altruistic. I\u2019m not saying Apple\u2019s evil or anything like that. I\u2019m just saying you always have to take a grain of salt with a big company movement. That\u2019s a well thought out movement and they have, I\u2019m sure, some under the hood ideas that they\u2019re not telling everybody.</p>\n<p><strong>Scott:</strong> And there\u2019s a competitive landscape that you\u2019re in as well. Hey, you\u2019re a company, other people are getting data, and maybe you are taking a stance so that you don\u2019t. Okay, now you have a competitive disadvantage.</p>\n<p>Maybe this is why he\u2019s saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.</p>\n<p><strong>Susan:</strong> Also, <a href="https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/">if you come out early as an advocate, knowing that it\u2019s going to go down the route of tighter and stricter laws, maybe you have more influence</a>. Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, \u201CHey, make it work for me, as best as I can.\u201D So you come out waving the flag of privacy first, and you get a bit more of a voice and that\u2019s inevitable.</p>\n<p><strong>Scott:</strong> Sure.\nYou want to build a company, or you want to build products, that people aren\u2019t going to hate, they\u2019re going to like, they\u2019re going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.</p>\n<p><strong>Susan:</strong> It\u2019s true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.</p>\n<p><strong>Scott:</strong> Understandably.</p>\n<p><strong>Susan:</strong> Understandably. And the complexity is growing with the complexity of the problems we\u2019re tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it\u2019s like, \u201CYeah, of course that\u2019s easy.\u201D We\u2019re tackling really deep, hard problems now.</p>\n<p>Another <a href="https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html">great dataset that just came out, Twitter</a>.</p>\n<p><strong>Scott:</strong> Text datasets, Twitter.</p>\n<p><strong>Susan:</strong> That\u2019s a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We\u2019ll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?</p>\n<p>Maybe we have a first dataset on there. But there\u2019s a lot of concerns with that.</p>\n<h3 id="what-data-policies-do-we-need-what-exists">What data policies do we need? What exists?</h3>\n<p><strong>Scott:</strong> So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?</p>\n<p><strong>Susan:</strong> What\u2019s the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.</p>\n<p><strong>Scott:</strong> It\u2019s like 1900 trying to talk about electricity.</p>\n<p><strong>Susan:</strong> Exactly. I mean, I think first of all, without talking about restricting what is and isn\u2019t there. Susan\u2019s personal take is, openness is the number one thing.\nBeing open about what data\u2019s being collected and what it\u2019s being used for. I\u2019m not saying restrictions anything like that, but that will help. That\u2019ll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That\u2019s the nature of the digital age. If you\u2019re more open right about now, it\u2019ll go a lot easier when the harder privacy laws inevitably start hitting.</p>\n<p><strong>Scott:</strong> If you\u2019re asking me to make a prediction, \u201CHey, how are people going to feel about this in the future or what\u2019s going to happen?\u201D I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody\u2019s afraid of it. They\u2019re like, \u201CI don\u2019t know if I\u2019m going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I\u2019m not going to trust anything. How could I get anything through the mail, through eBay and trust that?\u201D</p>\n<p>There\u2019s a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.</p>\n<p><strong>Susan:</strong>\nFear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there\u2019s only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.</p>\n<p><strong>Scott:</strong> In the back and watch what happens.</p>\n<p>But to answer our big question, how is data going to influence the future of machine learning? Okay, so we\u2019ve got to worry about privacy, you\u2019ve got the different types of machine learning. We talked a bit about text, audio, images, other stuff.</p>\n<h3 id="whats-the-future-going-to-hold">What\u2019s the future going to hold?</h3>\n<p><strong>Susan:</strong> I think that we\u2019re going to see more and more of these big data dumps trying be the cornerstone of solving a problem.</p>\n<p><strong>Scott:</strong> Like a jumping off point?</p>\n<p><strong>Susan:</strong> Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I\u2019m already calling it The Twitter Dataset! Their name is out there and they\u2019re looking like they\u2019re doing something about this problem. So it\u2019s good PR, although it\u2019s really challenging and it can be a disaster if you do it wrong. But, we\u2019re going to see more of those cornerstone datasets come out there, help define these problems with data.</p>\n<p>Data defining the problems. That\u2019s a big piece of what\u2019s going to shape what the machine learning world looks like five, ten years down the road.</p>\n<p><strong>Scott:</strong>\nThis is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That\u2019s not really going to end because that\u2019s where all the data is. The big companies have the big data and in order to do AI well, you need big data.</p>\n<p><strong>Susan:</strong> And, people that want to solve problems want to solve problems where the problems are interesting. Early on it\u2019s interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.</p>\n<p><strong>Scott:</strong> Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it\u2019ll be very common place: \u201CYeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we\u2019re collecting what we\u2019re doing, and doing all the things.\u201D But, what\u2019s the new good stuff, general AI, or whatever, where\u2019s that going to be seeded? It may be in the companies, but probably more like there\u2019ll be some kind of data partnership with academic institutions or something like that.</p>\n<p><strong>Susan:</strong> You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you\u2019re going to release something.</p>\n<p><strong>Scott:</strong> Oh, yeah, like it has to fit these rules.</p>\n<p><strong>Susan:</strong> Yeah. Or, \u201CYou must have learned from this dataset, and we\u2019re going to test you against your ability to deal with these datasets.\u201D</p>\n<p><strong>Scott:</strong> Kind of an adversarial, like \u201CIf you can\u2019t deal with this, then you\u2019re not a good enough model?\u201D</p>\n<p><strong>Susan:</strong> Well, think about judging. We\u2019ll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.</p>\n<p><strong>Scott:</strong> Answer yes or no.</p>\n<p><strong>Susan:</strong> Yeah, this becomes how to board-certify an algorithm.</p>\n<p><strong>Scott:</strong> A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There\u2019s a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it\u2019s not trade secrets or something like that, but sort of underlying ways that humans work. It\u2019s what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.</p>\n<p><strong>Susan:</strong> Yeah, it\u2019s a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.</p>\n<h3 id="what-are-the-future-datasets-going-to-be">What are the future datasets going to be?</h3>\n<p><strong>Scott:</strong> I think it\u2019s going to be interesting. I think we are just in the very beginning stages. It\u2019s like the first railroad was built across the US or something, now there\u2019s going to be 3,000 railroads. It\u2019s a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It\u2019s going to work it\u2019s way into every part of life and, at least from my perspective, people shouldn\u2019t be too afraid of it because it\u2019s going to make your life so much easier.</p>\n<p>So as long as the path is taken in a way that isn\u2019t crazy, which, companies are pretty non-crazy now. They don\u2019t want to scare you off from being a customer. Then it\u2019s like, \u201CHey, this is going to evolve. It\u2019s going to make your life way easier. Things are going to be more efficient. Then, you\u2019ll just be very glad.\u201D</p>\n<p>Similarly to text messaging or Facebook or something like that. Hey, you\u2019re giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?</p>\n<p><strong>Susan:</strong> Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they\u2019re going to drop off social media, they\u2019re going to drop off and you never hear from them again.</p>\n<p><strong>Scott:</strong> But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?</p>\n<p>I think data obviously plays a big part now, but it\u2019s going to play a very big part in the future. You\u2019ll get your baselines set over the next few years, but then there\u2019ll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. \u201CHey, here\u2019s some data. Hey, we labeled it. Hey we trained a model and then it did this task.\u201DThen people will become used to it and they go, \u201CWell, this is awesome. I don\u2019t have to do all these menial tasks anymore.\u201D</p>\n<p><strong>Susan:</strong> It gives you that bootstrap. So one more final interesting aspect of all this is people don\u2019t realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn\u2019t as targeted as you\u2019d like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.</p>\n<p><strong>Scott:</strong> It\u2019s something to build off of. If you just have an example, you have a template, and it\u2019s like, \u201COkay, maybe I\u2019ll add one hour from my time to make that.\u201D Now it\u2019s a two hour dataset, and then it starts to build a community around it.</p>\n<p><strong>Susan:</strong> Yeah, these things are like little seeds. These little datasets are just seeds.</p>\n<p><strong>Scott:</strong> You\u2019ve got to form it in the right way and then it grows.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/ai-show-how-will-data-influence-the-future-of-machine-learning/index.md" };
function rawContent() {
  return `<iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>

**Scott:** Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:

## How will data influence the future of machine learning?

**Susan:** You know, it's a pretty key thing, as we've discussed many times before.

**Scott:** Well, you have to have the trifecta, right?

* You've got to have computing power,
* You've got to have data,
* You've got to have good models.

**Susan:** You know, I think we're starting to see some trends here.

## How do normal machine learning problems go?

**Scott:** Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That's usually how that goes. But, it isn't necessarily that the bigger the data, the better your model is going to be, right?

**Susan:** No, definitely not. Data plays a key role, and the size of data definitely helps if you've got more, but there's a lot more that goes into it. But, we're starting to see a lot of these problems evolve along a standard path. We've seen this a couple times now.

**Scott:** How do they evolve?

**Susan:** It seems like there's a couple key points in the life of a machine-learning problem. At least, I've noticed this. Have you noticed this?

**Scott:** I, probably. I don't know. I'm not sure what you're thinking.

**Susan:** Well, here's what I'm thinking, I'll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I've noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There's a lot of classic datasets that, once those were published, people could try different algorithms and compare them.

**Scott:** Yep. So if you're drawing "0, 1, 2, 3, 4, 5, 6, 7, 8, 9," just writing it. "Hey, can you recognize those?" That type of dataset. Maybe another simple one like, "What category does this fall into? Is it a human? Is it an airplane? Is it a cat?"

![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)

*[The MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database)*

**Susan:** Yeah, we've talked about [CIFAR dataset](https://en.wikipedia.org/wiki/CIFAR-10) and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We're seeing [Tensorflow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), all these standardized tools kind of follow along. But, people start standardizing: [ImageNet](http://www.image-net.org/) and stuff like that. Like, "Hey, here's eight ways to attack this problem."

> "We see the evolution of this problem go from understanding there's a problem, a classic dataset's released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time."

**Scott:** And the progress is rapid. You can look back and be like, "Wow, how did so much get accomplished?" But, it also still takes place over the span of decades. Like, [MNIST](https://en.wikipedia.org/wiki/MNIST_database), the hand written digits, was 20 years ago.

**Susan:** Maybe more.

**Scott:** Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.

**Susan:** It's pretty cool to see that we've had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they're at. It's like charting a star: "This is how old it is based on how it looks."

**Scott:** That's a good point. That's sort of based on

* How hard is the problem?
* How easy is it to get the data?
* How scintillating is the data?
* Is it something that you can find for free easily on the Internet, nicely labeled?

Images are like that a lot. It's easy to find a lot of images that are labeled. Not super easy, but you can search for a "tool" and you'll find tons of pictures of tools. Okay, that's pretty easy. But, there isn't an easy way for speech recognition to say the word, "tool." "Give me all the examples of everybody saying that word." That's a harder problem.

![Alt](https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg)

**Susan:** Well, by the time that becomes easy it probably means that the problem has been

**Scott:** Problem has been solved!

**Susan:** Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they're still kind of following that arc.

**Scott:** Well, it's not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.

**Susan:** Yes.

**Scott:** Here's the caption: "A picture of a tool."

"Oh, okay. So that probably means that's what the image is." But, that's not how it goes in audio. If you just recorded your meetings, you're not going to sit down and label all the moments.

**Susan:** No.

**Scott:** Not generally. Usually not.

**Susan:** There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.

To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.

**Scott:** Sit down, try to get it exactly. You already know what you're talking about. You already know all the vocabulary words.

**Susan:** You're the one who said it!

**Scott:** Yeah! You know your voice, right? And then you're like, "Wow, this takes a lot longer than I would expect."

### How datasets come to be

**Scott:**

* Is the data fairly easy to get?
* Is it pretty freely available?
* Is it all that hard to label?
* Is it a problem that's worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.

**Susan:** There's one more angle here that's been popping up more and more lately. That, in the early datasets, we really just didn't concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we're putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.

You thought you were anonymizing your history here, and suddenly now everybody knows what movies you've been watching. Remember [the Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)?

**Scott:** Yeah, maybe eight years ago now? It was a machine-learning prize. It was, "Get a million dollars if you're able to make a recommendation that's better than 90% accurate," or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that's how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.

![Alt](https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg) *Winners of the Netflix prize; photo: dannypeled.com*

**Susan:** It kind of did follow the same curve we were talking about earlier:

1. A big dataset was put out there
2. A bunch of different people, academics, started throwing a lot of different answers to it,
3. They finally got to an acceptable solution.

Now, from what I understand, the solution that won wasn't what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.

**Scott:** It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.

### The challenging link between data and privacy

**Susan:** This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you're getting challenges publishing it because you've got privacy concerns, that could put the brakes on a lot of problems that might be solved. There's tradeoffs here. I'm not advocating throwing out privacy, let me be very clear about this.

**Scott:** In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it's been fairly free up until recent times. [GDPR](https://eugdpr.org/) happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.

People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it'll probably work is that if you say, "No," then you probably are giving up some functionality there, because now it can't learn from you.

**Susan:** So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.

This is what you see everywhere and honestly, we're kind of at the beginning of this. We're starting to really see big legal entities come in and move and start doing this, and they think they've got enough information to start building laws and stuff like that. This is the beginning of a process that's going to take decades to shake out. So it's a huge, huge, huge thing that you have to pay attention to when dealing with this.

**Scott:** This has been in the [news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference](https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/) giving a keynote there and sort of lampooning a lot of the other tech companies, saying, "Hey, you're stepping on people's data rights."

> We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:
>
> * Tim Cook (@tim_cook) [October 24, 2018](https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw)

**Susan:** Yeah, it's interesting to see a very large company, especially one with access to so much personal data.

**Scott:** With tons of data. With machine learning groups.

**Susan:** And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.

<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

**Scott:** They've always planted a flag in the ground and said, "We are security conscious. We are data privacy conscious, et cetera," Apple has been.

Famously saying, "Hey, we're not going to give you the keys to unlock somebody who's been arrested's iPhone." Things like that.

**Susan:** I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they've been doing this but (this is the jaded side of me) I'm going to have to ...

**Scott:** You don't really believe it?

**Susan:** Well, I mean, it's kind of hard to see big companies saying that they're altruistic. I'm not saying Apple's evil or anything like that. I'm just saying you always have to take a grain of salt with a big company movement. That's a well thought out movement and they have, I'm sure, some under the hood ideas that they're not telling everybody.

**Scott:** And there's a competitive landscape that you're in as well. Hey, you're a company, other people are getting data, and maybe you are taking a stance so that you don't. Okay, now you have a competitive disadvantage.

Maybe this is why he's saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.

**Susan:** Also, [if you come out early as an advocate, knowing that it's going to go down the route of tighter and stricter laws, maybe you have more influence](https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/). Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, "Hey, make it work for me, as best as I can." So you come out waving the flag of privacy first, and you get a bit more of a voice and that's inevitable.

**Scott:** Sure.
 You want to build a company, or you want to build products, that people aren't going to hate, they're going to like, they're going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.

**Susan:** It's true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.

**Scott:** Understandably.

**Susan:** Understandably. And the complexity is growing with the complexity of the problems we're tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it's like, "Yeah, of course that's easy." We're tackling really deep, hard problems now.

Another [great dataset that just came out, Twitter](https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html).

**Scott:** Text datasets, Twitter.

**Susan:** That's a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We'll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?

Maybe we have a first dataset on there. But there's a lot of concerns with that.

### What data policies do we need? What exists?

**Scott:** So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?

**Susan:** What's the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.

**Scott:** It's like 1900 trying to talk about electricity.

**Susan:** Exactly. I mean, I think first of all, without talking about restricting what is and isn't there. Susan's personal take is, openness is the number one thing.
 Being open about what data's being collected and what it's being used for. I'm not saying restrictions anything like that, but that will help. That'll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That's the nature of the digital age. If you're more open right about now, it'll go a lot easier when the harder privacy laws inevitably start hitting.

**Scott:** If you're asking me to make a prediction, "Hey, how are people going to feel about this in the future or what's going to happen?" I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody's afraid of it. They're like, "I don't know if I'm going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I'm not going to trust anything. How could I get anything through the mail, through eBay and trust that?"

There's a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.

**Susan:**
 Fear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there's only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.

**Scott:** In the back and watch what happens.

But to answer our big question, how is data going to influence the future of machine learning? Okay, so we've got to worry about privacy, you've got the different types of machine learning. We talked a bit about text, audio, images, other stuff.

### What's the future going to hold?

**Susan:** I think that we're going to see more and more of these big data dumps trying be the cornerstone of solving a problem.

**Scott:** Like a jumping off point?

**Susan:** Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I'm already calling it The Twitter Dataset! Their name is out there and they're looking like they're doing something about this problem. So it's good PR, although it's really challenging and it can be a disaster if you do it wrong. But, we're going to see more of those cornerstone datasets come out there, help define these problems with data.

Data defining the problems. That's a big piece of what's going to shape what the machine learning world looks like five, ten years down the road.

**Scott:**
 This is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That's not really going to end because that's where all the data is. The big companies have the big data and in order to do AI well, you need big data.

**Susan:** And, people that want to solve problems want to solve problems where the problems are interesting. Early on it's interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.

**Scott:** Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it'll be very common place: "Yeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we're collecting what we're doing, and doing all the things." But, what's the new good stuff, general AI, or whatever, where's that going to be seeded? It may be in the companies, but probably more like there'll be some kind of data partnership with academic institutions or something like that.

**Susan:** You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you're going to release something.

**Scott:** Oh, yeah, like it has to fit these rules.

**Susan:** Yeah. Or, "You must have learned from this dataset, and we're going to test you against your ability to deal with these datasets."

**Scott:** Kind of an adversarial, like "If you can't deal with this, then you're not a good enough model?"

**Susan:** Well, think about judging. We'll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.

**Scott:** Answer yes or no.

**Susan:** Yeah, this becomes how to board-certify an algorithm.

**Scott:** A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There's a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it's not trade secrets or something like that, but sort of underlying ways that humans work. It's what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.

**Susan:** Yeah, it's a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.

### What are the future datasets going to be?

**Scott:** I think it's going to be interesting. I think we are just in the very beginning stages. It's like the first railroad was built across the US or something, now there's going to be 3,000 railroads. It's a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It's going to work it's way into every part of life and, at least from my perspective, people shouldn't be too afraid of it because it's going to make your life so much easier.

So as long as the path is taken in a way that isn't crazy, which, companies are pretty non-crazy now. They don't want to scare you off from being a customer. Then it's like, "Hey, this is going to evolve. It's going to make your life way easier. Things are going to be more efficient. Then, you'll just be very glad."

Similarly to text messaging or Facebook or something like that. Hey, you're giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?

**Susan:** Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they're going to drop off social media, they're going to drop off and you never hear from them again.

**Scott:** But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?

I think data obviously plays a big part now, but it's going to play a very big part in the future. You'll get your baselines set over the next few years, but then there'll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. "Hey, here's some data. Hey, we labeled it. Hey we trained a model and then it did this task."Then people will become used to it and they go, "Well, this is awesome. I don't have to do all these menial tasks anymore."

**Susan:** It gives you that bootstrap. So one more final interesting aspect of all this is people don't realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn't as targeted as you'd like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.

**Scott:** It's something to build off of. If you just have an example, you have a template, and it's like, "Okay, maybe I'll add one hour from my time to make that." Now it's a two hour dataset, and then it starts to build a community around it.

**Susan:** Yeah, these things are like little seeds. These little datasets are just seeds.

**Scott:** You've got to form it in the right way and then it grows.`;
}
function compiledContent() {
  return '<iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" />\n<p><strong>Scott:</strong> Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:</p>\n<h2 id="how-will-data-influence-the-future-of-machine-learning">How will data influence the future of machine learning?</h2>\n<p><strong>Susan:</strong> You know, it\u2019s a pretty key thing, as we\u2019ve discussed many times before.</p>\n<p><strong>Scott:</strong> Well, you have to have the trifecta, right?</p>\n<ul>\n<li>You\u2019ve got to have computing power,</li>\n<li>You\u2019ve got to have data,</li>\n<li>You\u2019ve got to have good models.</li>\n</ul>\n<p><strong>Susan:</strong> You know, I think we\u2019re starting to see some trends here.</p>\n<h2 id="how-do-normal-machine-learning-problems-go">How do normal machine learning problems go?</h2>\n<p><strong>Scott:</strong> Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That\u2019s usually how that goes. But, it isn\u2019t necessarily that the bigger the data, the better your model is going to be, right?</p>\n<p><strong>Susan:</strong> No, definitely not. Data plays a key role, and the size of data definitely helps if you\u2019ve got more, but there\u2019s a lot more that goes into it. But, we\u2019re starting to see a lot of these problems evolve along a standard path. We\u2019ve seen this a couple times now.</p>\n<p><strong>Scott:</strong> How do they evolve?</p>\n<p><strong>Susan:</strong> It seems like there\u2019s a couple key points in the life of a machine-learning problem. At least, I\u2019ve noticed this. Have you noticed this?</p>\n<p><strong>Scott:</strong> I, probably. I don\u2019t know. I\u2019m not sure what you\u2019re thinking.</p>\n<p><strong>Susan:</strong> Well, here\u2019s what I\u2019m thinking, I\u2019ll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I\u2019ve noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There\u2019s a lot of classic datasets that, once those were published, people could try different algorithms and compare them.</p>\n<p><strong>Scott:</strong> Yep. So if you\u2019re drawing \u201C0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\u201D just writing it. \u201CHey, can you recognize those?\u201D That type of dataset. Maybe another simple one like, \u201CWhat category does this fall into? Is it a human? Is it an airplane? Is it a cat?\u201D</p>\n<p><img src="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png" alt=""></p>\n<p><em><a href="https://en.wikipedia.org/wiki/MNIST_database">The MNIST dataset</a></em></p>\n<p><strong>Susan:</strong> Yeah, we\u2019ve talked about <a href="https://en.wikipedia.org/wiki/CIFAR-10">CIFAR dataset</a> and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We\u2019re seeing <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://pytorch.org/">PyTorch</a>, all these standardized tools kind of follow along. But, people start standardizing: <a href="http://www.image-net.org/">ImageNet</a> and stuff like that. Like, \u201CHey, here\u2019s eight ways to attack this problem.\u201D</p>\n<blockquote>\n<p>\u201CWe see the evolution of this problem go from understanding there\u2019s a problem, a classic dataset\u2019s released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time.\u201D</p>\n</blockquote>\n<p><strong>Scott:</strong> And the progress is rapid. You can look back and be like, \u201CWow, how did so much get accomplished?\u201D But, it also still takes place over the span of decades. Like, <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>, the hand written digits, was 20 years ago.</p>\n<p><strong>Susan:</strong> Maybe more.</p>\n<p><strong>Scott:</strong> Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.</p>\n<p><strong>Susan:</strong> It\u2019s pretty cool to see that we\u2019ve had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they\u2019re at. It\u2019s like charting a star: \u201CThis is how old it is based on how it looks.\u201D</p>\n<p><strong>Scott:</strong> That\u2019s a good point. That\u2019s sort of based on</p>\n<ul>\n<li>How hard is the problem?</li>\n<li>How easy is it to get the data?</li>\n<li>How scintillating is the data?</li>\n<li>Is it something that you can find for free easily on the Internet, nicely labeled?</li>\n</ul>\n<p>Images are like that a lot. It\u2019s easy to find a lot of images that are labeled. Not super easy, but you can search for a \u201Ctool\u201D and you\u2019ll find tons of pictures of tools. Okay, that\u2019s pretty easy. But, there isn\u2019t an easy way for speech recognition to say the word, \u201Ctool.\u201D \u201CGive me all the examples of everybody saying that word.\u201D That\u2019s a harder problem.</p>\n<p><img src="https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg" alt="Alt"></p>\n<p><strong>Susan:</strong> Well, by the time that becomes easy it probably means that the problem has been</p>\n<p><strong>Scott:</strong> Problem has been solved!</p>\n<p><strong>Susan:</strong> Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they\u2019re still kind of following that arc.</p>\n<p><strong>Scott:</strong> Well, it\u2019s not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.</p>\n<p><strong>Susan:</strong> Yes.</p>\n<p><strong>Scott:</strong> Here\u2019s the caption: \u201CA picture of a tool.\u201D</p>\n<p>\u201COh, okay. So that probably means that\u2019s what the image is.\u201D But, that\u2019s not how it goes in audio. If you just recorded your meetings, you\u2019re not going to sit down and label all the moments.</p>\n<p><strong>Susan:</strong> No.</p>\n<p><strong>Scott:</strong> Not generally. Usually not.</p>\n<p><strong>Susan:</strong> There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.</p>\n<p>To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.</p>\n<p><strong>Scott:</strong> Sit down, try to get it exactly. You already know what you\u2019re talking about. You already know all the vocabulary words.</p>\n<p><strong>Susan:</strong> You\u2019re the one who said it!</p>\n<p><strong>Scott:</strong> Yeah! You know your voice, right? And then you\u2019re like, \u201CWow, this takes a lot longer than I would expect.\u201D</p>\n<h3 id="how-datasets-come-to-be">How datasets come to be</h3>\n<p><strong>Scott:</strong></p>\n<ul>\n<li>Is the data fairly easy to get?</li>\n<li>Is it pretty freely available?</li>\n<li>Is it all that hard to label?</li>\n<li>Is it a problem that\u2019s worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.</li>\n</ul>\n<p><strong>Susan:</strong> There\u2019s one more angle here that\u2019s been popping up more and more lately. That, in the early datasets, we really just didn\u2019t concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we\u2019re putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.</p>\n<p>You thought you were anonymizing your history here, and suddenly now everybody knows what movies you\u2019ve been watching. Remember <a href="https://en.wikipedia.org/wiki/Netflix_Prize">the Netflix prize</a>?</p>\n<p><strong>Scott:</strong> Yeah, maybe eight years ago now? It was a machine-learning prize. It was, \u201CGet a million dollars if you\u2019re able to make a recommendation that\u2019s better than 90% accurate,\u201D or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that\u2019s how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.</p>\n<p><img src="https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg" alt="Alt"> <em>Winners of the Netflix prize; photo: dannypeled.com</em></p>\n<p><strong>Susan:</strong> It kind of did follow the same curve we were talking about earlier:</p>\n<ol>\n<li>A big dataset was put out there</li>\n<li>A bunch of different people, academics, started throwing a lot of different answers to it,</li>\n<li>They finally got to an acceptable solution.</li>\n</ol>\n<p>Now, from what I understand, the solution that won wasn\u2019t what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.</p>\n<p><strong>Scott:</strong> It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.</p>\n<h3 id="the-challenging-link-between-data-and-privacy">The challenging link between data and privacy</h3>\n<p><strong>Susan:</strong> This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you\u2019re getting challenges publishing it because you\u2019ve got privacy concerns, that could put the brakes on a lot of problems that might be solved. There\u2019s tradeoffs here. I\u2019m not advocating throwing out privacy, let me be very clear about this.</p>\n<p><strong>Scott:</strong> In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it\u2019s been fairly free up until recent times. <a href="https://eugdpr.org/">GDPR</a> happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.</p>\n<p>People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it\u2019ll probably work is that if you say, \u201CNo,\u201D then you probably are giving up some functionality there, because now it can\u2019t learn from you.</p>\n<p><strong>Susan:</strong> So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.</p>\n<p>This is what you see everywhere and honestly, we\u2019re kind of at the beginning of this. We\u2019re starting to really see big legal entities come in and move and start doing this, and they think they\u2019ve got enough information to start building laws and stuff like that. This is the beginning of a process that\u2019s going to take decades to shake out. So it\u2019s a huge, huge, huge thing that you have to pay attention to when dealing with this.</p>\n<p><strong>Scott:</strong> This has been in the <a href="https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/">news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference</a> giving a keynote there and sort of lampooning a lot of the other tech companies, saying, \u201CHey, you\u2019re stepping on people\u2019s data rights.\u201D</p>\n<blockquote>\n<p>We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:</p>\n<ul>\n<li>Tim Cook (@tim_cook) <a href="https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw">October 24, 2018</a></li>\n</ul>\n</blockquote>\n<p><strong>Susan:</strong> Yeah, it\u2019s interesting to see a very large company, especially one with access to so much personal data.</p>\n<p><strong>Scott:</strong> With tons of data. With machine learning groups.</p>\n<p><strong>Susan:</strong> And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.</p>\n<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" />\n<p><strong>Scott:</strong> They\u2019ve always planted a flag in the ground and said, \u201CWe are security conscious. We are data privacy conscious, et cetera,\u201D Apple has been.</p>\n<p>Famously saying, \u201CHey, we\u2019re not going to give you the keys to unlock somebody who\u2019s been arrested\u2019s iPhone.\u201D Things like that.</p>\n<p><strong>Susan:</strong> I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they\u2019ve been doing this but (this is the jaded side of me) I\u2019m going to have to \u2026</p>\n<p><strong>Scott:</strong> You don\u2019t really believe it?</p>\n<p><strong>Susan:</strong> Well, I mean, it\u2019s kind of hard to see big companies saying that they\u2019re altruistic. I\u2019m not saying Apple\u2019s evil or anything like that. I\u2019m just saying you always have to take a grain of salt with a big company movement. That\u2019s a well thought out movement and they have, I\u2019m sure, some under the hood ideas that they\u2019re not telling everybody.</p>\n<p><strong>Scott:</strong> And there\u2019s a competitive landscape that you\u2019re in as well. Hey, you\u2019re a company, other people are getting data, and maybe you are taking a stance so that you don\u2019t. Okay, now you have a competitive disadvantage.</p>\n<p>Maybe this is why he\u2019s saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.</p>\n<p><strong>Susan:</strong> Also, <a href="https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/">if you come out early as an advocate, knowing that it\u2019s going to go down the route of tighter and stricter laws, maybe you have more influence</a>. Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, \u201CHey, make it work for me, as best as I can.\u201D So you come out waving the flag of privacy first, and you get a bit more of a voice and that\u2019s inevitable.</p>\n<p><strong>Scott:</strong> Sure.\nYou want to build a company, or you want to build products, that people aren\u2019t going to hate, they\u2019re going to like, they\u2019re going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.</p>\n<p><strong>Susan:</strong> It\u2019s true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.</p>\n<p><strong>Scott:</strong> Understandably.</p>\n<p><strong>Susan:</strong> Understandably. And the complexity is growing with the complexity of the problems we\u2019re tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it\u2019s like, \u201CYeah, of course that\u2019s easy.\u201D We\u2019re tackling really deep, hard problems now.</p>\n<p>Another <a href="https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html">great dataset that just came out, Twitter</a>.</p>\n<p><strong>Scott:</strong> Text datasets, Twitter.</p>\n<p><strong>Susan:</strong> That\u2019s a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We\u2019ll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?</p>\n<p>Maybe we have a first dataset on there. But there\u2019s a lot of concerns with that.</p>\n<h3 id="what-data-policies-do-we-need-what-exists">What data policies do we need? What exists?</h3>\n<p><strong>Scott:</strong> So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?</p>\n<p><strong>Susan:</strong> What\u2019s the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.</p>\n<p><strong>Scott:</strong> It\u2019s like 1900 trying to talk about electricity.</p>\n<p><strong>Susan:</strong> Exactly. I mean, I think first of all, without talking about restricting what is and isn\u2019t there. Susan\u2019s personal take is, openness is the number one thing.\nBeing open about what data\u2019s being collected and what it\u2019s being used for. I\u2019m not saying restrictions anything like that, but that will help. That\u2019ll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That\u2019s the nature of the digital age. If you\u2019re more open right about now, it\u2019ll go a lot easier when the harder privacy laws inevitably start hitting.</p>\n<p><strong>Scott:</strong> If you\u2019re asking me to make a prediction, \u201CHey, how are people going to feel about this in the future or what\u2019s going to happen?\u201D I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody\u2019s afraid of it. They\u2019re like, \u201CI don\u2019t know if I\u2019m going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I\u2019m not going to trust anything. How could I get anything through the mail, through eBay and trust that?\u201D</p>\n<p>There\u2019s a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.</p>\n<p><strong>Susan:</strong>\nFear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there\u2019s only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.</p>\n<p><strong>Scott:</strong> In the back and watch what happens.</p>\n<p>But to answer our big question, how is data going to influence the future of machine learning? Okay, so we\u2019ve got to worry about privacy, you\u2019ve got the different types of machine learning. We talked a bit about text, audio, images, other stuff.</p>\n<h3 id="whats-the-future-going-to-hold">What\u2019s the future going to hold?</h3>\n<p><strong>Susan:</strong> I think that we\u2019re going to see more and more of these big data dumps trying be the cornerstone of solving a problem.</p>\n<p><strong>Scott:</strong> Like a jumping off point?</p>\n<p><strong>Susan:</strong> Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I\u2019m already calling it The Twitter Dataset! Their name is out there and they\u2019re looking like they\u2019re doing something about this problem. So it\u2019s good PR, although it\u2019s really challenging and it can be a disaster if you do it wrong. But, we\u2019re going to see more of those cornerstone datasets come out there, help define these problems with data.</p>\n<p>Data defining the problems. That\u2019s a big piece of what\u2019s going to shape what the machine learning world looks like five, ten years down the road.</p>\n<p><strong>Scott:</strong>\nThis is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That\u2019s not really going to end because that\u2019s where all the data is. The big companies have the big data and in order to do AI well, you need big data.</p>\n<p><strong>Susan:</strong> And, people that want to solve problems want to solve problems where the problems are interesting. Early on it\u2019s interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.</p>\n<p><strong>Scott:</strong> Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it\u2019ll be very common place: \u201CYeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we\u2019re collecting what we\u2019re doing, and doing all the things.\u201D But, what\u2019s the new good stuff, general AI, or whatever, where\u2019s that going to be seeded? It may be in the companies, but probably more like there\u2019ll be some kind of data partnership with academic institutions or something like that.</p>\n<p><strong>Susan:</strong> You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you\u2019re going to release something.</p>\n<p><strong>Scott:</strong> Oh, yeah, like it has to fit these rules.</p>\n<p><strong>Susan:</strong> Yeah. Or, \u201CYou must have learned from this dataset, and we\u2019re going to test you against your ability to deal with these datasets.\u201D</p>\n<p><strong>Scott:</strong> Kind of an adversarial, like \u201CIf you can\u2019t deal with this, then you\u2019re not a good enough model?\u201D</p>\n<p><strong>Susan:</strong> Well, think about judging. We\u2019ll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.</p>\n<p><strong>Scott:</strong> Answer yes or no.</p>\n<p><strong>Susan:</strong> Yeah, this becomes how to board-certify an algorithm.</p>\n<p><strong>Scott:</strong> A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There\u2019s a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it\u2019s not trade secrets or something like that, but sort of underlying ways that humans work. It\u2019s what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.</p>\n<p><strong>Susan:</strong> Yeah, it\u2019s a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.</p>\n<h3 id="what-are-the-future-datasets-going-to-be">What are the future datasets going to be?</h3>\n<p><strong>Scott:</strong> I think it\u2019s going to be interesting. I think we are just in the very beginning stages. It\u2019s like the first railroad was built across the US or something, now there\u2019s going to be 3,000 railroads. It\u2019s a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It\u2019s going to work it\u2019s way into every part of life and, at least from my perspective, people shouldn\u2019t be too afraid of it because it\u2019s going to make your life so much easier.</p>\n<p>So as long as the path is taken in a way that isn\u2019t crazy, which, companies are pretty non-crazy now. They don\u2019t want to scare you off from being a customer. Then it\u2019s like, \u201CHey, this is going to evolve. It\u2019s going to make your life way easier. Things are going to be more efficient. Then, you\u2019ll just be very glad.\u201D</p>\n<p>Similarly to text messaging or Facebook or something like that. Hey, you\u2019re giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?</p>\n<p><strong>Susan:</strong> Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they\u2019re going to drop off social media, they\u2019re going to drop off and you never hear from them again.</p>\n<p><strong>Scott:</strong> But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?</p>\n<p>I think data obviously plays a big part now, but it\u2019s going to play a very big part in the future. You\u2019ll get your baselines set over the next few years, but then there\u2019ll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. \u201CHey, here\u2019s some data. Hey, we labeled it. Hey we trained a model and then it did this task.\u201DThen people will become used to it and they go, \u201CWell, this is awesome. I don\u2019t have to do all these menial tasks anymore.\u201D</p>\n<p><strong>Susan:</strong> It gives you that bootstrap. So one more final interesting aspect of all this is people don\u2019t realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn\u2019t as targeted as you\u2019d like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.</p>\n<p><strong>Scott:</strong> It\u2019s something to build off of. If you just have an example, you have a template, and it\u2019s like, \u201COkay, maybe I\u2019ll add one hour from my time to make that.\u201D Now it\u2019s a two hour dataset, and then it starts to build a community around it.</p>\n<p><strong>Susan:</strong> Yeah, these things are like little seeds. These little datasets are just seeds.</p>\n<p><strong>Scott:</strong> You\u2019ve got to form it in the right way and then it grows.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/ai-show-how-will-data-influence-the-future-of-machine-learning/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><iframe width="600" height="315" src="https://www.youtube.com/embed/HqVoulU4uRA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
<p><strong>Scott:</strong> Welcome to the AI Show. On the AI Show, we talk about all things AI. Today we have the question, our big question today:</p>
<h2 id="how-will-data-influence-the-future-of-machine-learning">How will data influence the future of machine learning?</h2>
<p><strong>Susan:</strong> You know, it’s a pretty key thing, as we’ve discussed many times before.</p>
<p><strong>Scott:</strong> Well, you have to have the trifecta, right?</p>
<ul>
<li>You’ve got to have computing power,</li>
<li>You’ve got to have data,</li>
<li>You’ve got to have good models.</li>
</ul>
<p><strong>Susan:</strong> You know, I think we’re starting to see some trends here.</p>
<h2 id="how-do-normal-machine-learning-problems-go">How do normal machine learning problems go?</h2>
<p><strong>Scott:</strong> Well, if you have a small amount of data, then you use some simplistic models and things like that. If you have a large amount of data you probably will have to use a lot of computational power. But, also it can shape your model and make it more intricate, more nuanced. That’s usually how that goes. But, it isn’t necessarily that the bigger the data, the better your model is going to be, right?</p>
<p><strong>Susan:</strong> No, definitely not. Data plays a key role, and the size of data definitely helps if you’ve got more, but there’s a lot more that goes into it. But, we’re starting to see a lot of these problems evolve along a standard path. We’ve seen this a couple times now.</p>
<p><strong>Scott:</strong> How do they evolve?</p>
<p><strong>Susan:</strong> It seems like there’s a couple key points in the life of a machine-learning problem. At least, I’ve noticed this. Have you noticed this?</p>
<p><strong>Scott:</strong> I, probably. I don’t know. I’m not sure what you’re thinking.</p>
<p><strong>Susan:</strong> Well, here’s what I’m thinking, I’ll just lay it all out on the table right here. In general, we see a problem emerge, that people finally recognize as a problem. And I’ve noticed, and a lot of people have noticed, that pretty soon someone publishes a dataset. It becomes the dataset that everybody works their magic against to try to attack this problem the first time. Like, the classic - handwriting digits or image recognition. There’s a lot of classic datasets that, once those were published, people could try different algorithms and compare them.</p>
<p><strong>Scott:</strong> Yep. So if you’re drawing “0, 1, 2, 3, 4, 5, 6, 7, 8, 9,” just writing it. “Hey, can you recognize those?” That type of dataset. Maybe another simple one like, “What category does this fall into? Is it a human? Is it an airplane? Is it a cat?”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png" alt=""></p>
<p><em><a href="https://en.wikipedia.org/wiki/MNIST_database">The MNIST dataset</a></em></p>
<p><strong>Susan:</strong> Yeah, we’ve talked about <a href="https://en.wikipedia.org/wiki/CIFAR-10">CIFAR dataset</a> and stuff like that. But, those standardized public datasets really help frame the problem. Then following that, you get some tools that will generally come out. We’re seeing <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://pytorch.org/">PyTorch</a>, all these standardized tools kind of follow along. But, people start standardizing: <a href="http://www.image-net.org/">ImageNet</a> and stuff like that. Like, “Hey, here’s eight ways to attack this problem.”</p>
<blockquote>
<p>“We see the evolution of this problem go from understanding there’s a problem, a classic dataset’s released, a bunch of people and academic papers get published, some standardized solutions start coming out, and you see the polish on the solutions start evolving over time.”</p>
</blockquote>
<p><strong>Scott:</strong> And the progress is rapid. You can look back and be like, “Wow, how did so much get accomplished?” But, it also still takes place over the span of decades. Like, <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>, the hand written digits, was 20 years ago.</p>
<p><strong>Susan:</strong> Maybe more.</p>
<p><strong>Scott:</strong> Maybe a little longer. But yeah, CIFAR, probably a similar age, at least close, not quite as old. ImageNet, 10 years roughly, et cetera.</p>
<p><strong>Susan:</strong> It’s pretty cool to see that we’ve had enough of these problems that we can see those arcs going through them. From that we can see new problems and gauge where they’re at. It’s like charting a star: “This is how old it is based on how it looks.”</p>
<p><strong>Scott:</strong> That’s a good point. That’s sort of based on</p>
<ul>
<li>How hard is the problem?</li>
<li>How easy is it to get the data?</li>
<li>How scintillating is the data?</li>
<li>Is it something that you can find for free easily on the Internet, nicely labeled?</li>
</ul>
<p>Images are like that a lot. It’s easy to find a lot of images that are labeled. Not super easy, but you can search for a “tool” and you’ll find tons of pictures of tools. Okay, that’s pretty easy. But, there isn’t an easy way for speech recognition to say the word, “tool.” “Give me all the examples of everybody saying that word.” That’s a harder problem.</p>
<p><img src="https://1.bp.blogspot.com/-2WefVFMGytE/VL_k4Wh-R-I/AAAAAAAAGFE/DNkTHbE4Bx4/s1600/Tool%2BBelt%2BLabeled.jpg" alt="Alt"></p>
<p><strong>Susan:</strong> Well, by the time that becomes easy it probably means that the problem has been</p>
<p><strong>Scott:</strong> Problem has been solved!</p>
<p><strong>Susan:</strong> Which is the other cool thing. But it does bring up, as these problems have gotten tougher, they’re still kind of following that arc.</p>
<p><strong>Scott:</strong> Well, it’s not trivial. The reason that you could search for a tool and get pictures of a tool is because people would label them.</p>
<p><strong>Susan:</strong> Yes.</p>
<p><strong>Scott:</strong> Here’s the caption: “A picture of a tool.”</p>
<p>“Oh, okay. So that probably means that’s what the image is.” But, that’s not how it goes in audio. If you just recorded your meetings, you’re not going to sit down and label all the moments.</p>
<p><strong>Susan:</strong> No.</p>
<p><strong>Scott:</strong> Not generally. Usually not.</p>
<p><strong>Susan:</strong> There are more and more academic sources that are helping to do that. And, the problem is growing over time. But yeah, that is just hard.</p>
<p>To the viewers at home, if you want to appreciate how hard speech is, just say something in your own voice for five minutes and record it. Then transcribe what you said and see how long it takes.</p>
<p><strong>Scott:</strong> Sit down, try to get it exactly. You already know what you’re talking about. You already know all the vocabulary words.</p>
<p><strong>Susan:</strong> You’re the one who said it!</p>
<p><strong>Scott:</strong> Yeah! You know your voice, right? And then you’re like, “Wow, this takes a lot longer than I would expect.”</p>
<h3 id="how-datasets-come-to-be">How datasets come to be</h3>
<p><strong>Scott:</strong></p>
<ul>
<li>Is the data fairly easy to get?</li>
<li>Is it pretty freely available?</li>
<li>Is it all that hard to label?</li>
<li>Is it a problem that’s worth solving or interesting to solve? You have to have all of those things, and then the datasets pop up.</li>
</ul>
<p><strong>Susan:</strong> There’s one more angle here that’s been popping up more and more lately. That, in the early datasets, we really just didn’t concern ourselves with. That is the privacy angle of the dataset. As these tools are getting better and better, as we’re putting more and more attention to them, and as the amount of data grows, even what you might think are trivial datasets become big privacy concerns.</p>
<p>You thought you were anonymizing your history here, and suddenly now everybody knows what movies you’ve been watching. Remember <a href="https://en.wikipedia.org/wiki/Netflix_Prize">the Netflix prize</a>?</p>
<p><strong>Scott:</strong> Yeah, maybe eight years ago now? It was a machine-learning prize. It was, “Get a million dollars if you’re able to make a recommendation that’s better than 90% accurate,” or something like that. Recommend movies to people. Then, if that matches the taste of something that they would like, that’s how you gauge your accuracy. They ran that and a bunch of different academics and companies and whatnot went after that problem.</p>
<p><img src="https://cdn.vox-cdn.com/thumbor/afYE-AVV0fNqW4eSdBRWVV24O4I=/0x0:1100x825/1820x1213/filters:focal(0x0:1100x825):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/49520055/netflix-prize1.0.jpg" alt="Alt"> <em>Winners of the Netflix prize; photo: dannypeled.com</em></p>
<p><strong>Susan:</strong> It kind of did follow the same curve we were talking about earlier:</p>
<ol>
<li>A big dataset was put out there</li>
<li>A bunch of different people, academics, started throwing a lot of different answers to it,</li>
<li>They finally got to an acceptable solution.</li>
</ol>
<p>Now, from what I understand, the solution that won wasn’t what they actually implemented, because it was a fairly complex, heavyweight thing and they wanted a more stripped down version of it. But, it does show that arc, and it also shows how privacy really came into this, because afterwards the security researchers got a hold of this dataset and they started linking real people back to these anonymized movie records.</p>
<p><strong>Scott:</strong> It was like, can you guess, even with 30% accuracy or 10% accuracy, who this person is? Based on just the movies that they like.</p>
<h3 id="the-challenging-link-between-data-and-privacy">The challenging link between data and privacy</h3>
<p><strong>Susan:</strong> This is a growing trend in these datasets and it also is a growing challenge. Because, like we said, when you publish those datasets, it helps frame the problem. But, if you’re getting challenges publishing it because you’ve got privacy concerns, that could put the brakes on a lot of problems that might be solved. There’s tradeoffs here. I’m not advocating throwing out privacy, let me be very clear about this.</p>
<p><strong>Scott:</strong> In order to make AI work well, you need data. And, how do you get data? You get it from people. People say things, or people do things, or they take pictures of things, or they write things, or whatever. So laws surround the use of this data and it’s been fairly free up until recent times. <a href="https://eugdpr.org/">GDPR</a> happened in Europe, and so that means that you have to very explicitly give permission to use your data, rather than it defaulting to being able to use the data. The US is still pretty free about this.</p>
<p>People are probably going to have to choose, in the future or now, in the next ensuing years, what do we want that to look like? Do I have to give you my data in order to use a very useful service, yes or no? Is there some other protection in there? How does that work? But the way that it’ll probably work is that if you say, “No,” then you probably are giving up some functionality there, because now it can’t learn from you.</p>
<p><strong>Susan:</strong> So one thing you and I have talked a lot about is a symbiotic evolution of these things. What you see is huge privacy concerns through big data breaches and things like that, you get a swing on the other side, privacy laws start coming in, which shapes the next set of concerns, which shapes the next set of laws.</p>
<p>This is what you see everywhere and honestly, we’re kind of at the beginning of this. We’re starting to really see big legal entities come in and move and start doing this, and they think they’ve got enough information to start building laws and stuff like that. This is the beginning of a process that’s going to take decades to shake out. So it’s a huge, huge, huge thing that you have to pay attention to when dealing with this.</p>
<p><strong>Scott:</strong> This has been in the <a href="https://techcrunch.com/2018/10/24/apples-tim-cook-makes-blistering-attack-on-the-data-industrial-complex/">news recently with Apple, Tim Cook. Apple CEO Tim Cook at a data privacy conference</a> giving a keynote there and sort of lampooning a lot of the other tech companies, saying, “Hey, you’re stepping on people’s data rights.”</p>
<blockquote>
<p>We believe that privacy is a fundamental human right. No matter what country you live in, that right should be protected in keeping with four essential principles:</p>
<ul>
<li>Tim Cook (@tim_cook) <a href="https://twitter.com/tim_cook/status/1055035539915718656?ref_src=twsrc%5Etfw">October 24, 2018</a></li>
</ul>
</blockquote>
<p><strong>Susan:</strong> Yeah, it’s interesting to see a very large company, especially one with access to so much personal data.</p>
<p><strong>Scott:</strong> With tons of data. With machine learning groups.</p>
<p><strong>Susan:</strong> And moving into huge fields like personal health monitoring and stuff like that which they do a huge, huge amount of that.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wFTmQ27S7OQ?start=1206" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><strong>Scott:</strong> They’ve always planted a flag in the ground and said, “We are security conscious. We are data privacy conscious, et cetera,” Apple has been.</p>
<p>Famously saying, “Hey, we’re not going to give you the keys to unlock somebody who’s been arrested’s iPhone.” Things like that.</p>
<p><strong>Susan:</strong> I think they just shut down a major tool, with the last iOS 12 and above upgrade. So, they’ve been doing this but (this is the jaded side of me) I’m going to have to …</p>
<p><strong>Scott:</strong> You don’t really believe it?</p>
<p><strong>Susan:</strong> Well, I mean, it’s kind of hard to see big companies saying that they’re altruistic. I’m not saying Apple’s evil or anything like that. I’m just saying you always have to take a grain of salt with a big company movement. That’s a well thought out movement and they have, I’m sure, some under the hood ideas that they’re not telling everybody.</p>
<p><strong>Scott:</strong> And there’s a competitive landscape that you’re in as well. Hey, you’re a company, other people are getting data, and maybe you are taking a stance so that you don’t. Okay, now you have a competitive disadvantage.</p>
<p>Maybe this is why he’s saying those things, so that competitors like Google, Facebook, et cetera, have more heat put on them from the government.</p>
<p><strong>Susan:</strong> Also, <a href="https://www.cnet.com/news/us-privacy-law-is-on-the-horizon-heres-how-tech-companies-want-to-shape-it/">if you come out early as an advocate, knowing that it’s going to go down the route of tighter and stricter laws, maybe you have more influence</a>. Maybe you can shape those laws more in your favor. Apple definitely would want to shape those laws in their favor, any big company is going to say, “Hey, make it work for me, as best as I can.” So you come out waving the flag of privacy first, and you get a bit more of a voice and that’s inevitable.</p>
<p><strong>Scott:</strong> Sure.
You want to build a company, or you want to build products, that people aren’t going to hate, they’re going to like, they’re going to want to keep using, and they provide value. You just have to find that balance. Apple will have to find that balance. Every company will have to find that balance. With data and the models that they build.</p>
<p><strong>Susan:</strong> It’s true. But it is interesting, again, going back to the general theme here, seeing the arc of these problems, and seeing that simple arc is getting more and more complex by the day. But that complexity is also growing.</p>
<p><strong>Scott:</strong> Understandably.</p>
<p><strong>Susan:</strong> Understandably. And the complexity is growing with the complexity of the problems we’re tackling. When we first wanted to figure out, is this a 1 or a 7? Is this a horse or a pig? When they first came out, they were incredibly hard problems to solve. Now it’s like, “Yeah, of course that’s easy.” We’re tackling really deep, hard problems now.</p>
<p>Another <a href="https://boingboing.net/2018/10/17/twitter-publishes-tweet-archiv.html">great dataset that just came out, Twitter</a>.</p>
<p><strong>Scott:</strong> Text datasets, Twitter.</p>
<p><strong>Susan:</strong> That’s a big one. It hits all of these fronts. This is talking about really complex social issues and really complex technological issues all wrapped up in a big brand-new dataset. We’ll see if it becomes adopted as a cornerstone for figuring out this problem - the problem of basically weaponized social media. How do you fight that?</p>
<p>Maybe we have a first dataset on there. But there’s a lot of concerns with that.</p>
<h3 id="what-data-policies-do-we-need-what-exists">What data policies do we need? What exists?</h3>
<p><strong>Scott:</strong> So what do you think our people should do from a policy perspective? What exists? What should exist in the future in order to enable an ideal landscape for AI to flourish but privacy to still be a thing?</p>
<p><strong>Susan:</strong> What’s the balance? Man, this is so early. Like, throwing a dart about what the right balance is, is really, really, hard.</p>
<p><strong>Scott:</strong> It’s like 1900 trying to talk about electricity.</p>
<p><strong>Susan:</strong> Exactly. I mean, I think first of all, without talking about restricting what is and isn’t there. Susan’s personal take is, openness is the number one thing.
Being open about what data’s being collected and what it’s being used for. I’m not saying restrictions anything like that, but that will help. That’ll help frame the conversation, and help educate consumers and individuals and companies. That way we can go into an informed future and make more informed decisions. I can guarantee you that whatever is being hidden right now, eventually will come out. That’s the nature of the digital age. If you’re more open right about now, it’ll go a lot easier when the harder privacy laws inevitably start hitting.</p>
<p><strong>Scott:</strong> If you’re asking me to make a prediction, “Hey, how are people going to feel about this in the future or what’s going to happen?” I think if you just look back into the past - year 2000, Internet hits the world in a big way and everybody’s afraid of it. They’re like, “I don’t know if I’m going to go on there. Is this thing watching me? I have a webcam. Oh, no, it can see my entire life. Should I put my credit card in here? I’m not going to trust anything. How could I get anything through the mail, through eBay and trust that?”</p>
<p>There’s a lot of things that have to be figured out. But, they get figured out. So, a similar thing with AI. A lot of things have to be figured out. Do you have to fear everything? No. Are people going to fear everything at some point in time? Yes. Are they going to be resolved? For the most part, yeah.</p>
<p><strong>Susan:</strong>
Fear is not a good way to approach the future, no matter the problem.It should be a motivator to understand, but not to stop you from going into the future. Because no matter what, there’s only really one guarantee, the future is going to happen. So you can either be part of shaping it, or you can hide in the corner.</p>
<p><strong>Scott:</strong> In the back and watch what happens.</p>
<p>But to answer our big question, how is data going to influence the future of machine learning? Okay, so we’ve got to worry about privacy, you’ve got the different types of machine learning. We talked a bit about text, audio, images, other stuff.</p>
<h3 id="whats-the-future-going-to-hold">What’s the future going to hold?</h3>
<p><strong>Susan:</strong> I think that we’re going to see more and more of these big data dumps trying be the cornerstone of solving a problem.</p>
<p><strong>Scott:</strong> Like a jumping off point?</p>
<p><strong>Susan:</strong> Yeah, a jumping off point. Especially, honestly, from bigger companies, because now, just the fact that Twitter released it. I’m already calling it The Twitter Dataset! Their name is out there and they’re looking like they’re doing something about this problem. So it’s good PR, although it’s really challenging and it can be a disaster if you do it wrong. But, we’re going to see more of those cornerstone datasets come out there, help define these problems with data.</p>
<p>Data defining the problems. That’s a big piece of what’s going to shape what the machine learning world looks like five, ten years down the road.</p>
<p><strong>Scott:</strong>
This is a really interesting part of AI, in that the data that is collected, labeled, used to train models, has transferred very heavily from being small academic datasets to very large datasets that are captured by companies and used to build models. So this is why you see talent moving from academia to big companies. That’s not really going to end because that’s where all the data is. The big companies have the big data and in order to do AI well, you need big data.</p>
<p><strong>Susan:</strong> And, people that want to solve problems want to solve problems where the problems are interesting. Early on it’s interesting in the public sector and later on it becomes interesting in the academic world. It gets its seeds in academia, flourishes in public, and then goes back to academia.</p>
<p><strong>Scott:</strong> Yeah, I think so. Because, a lot of the baseline problems will be solved, people will be tired of it, it’ll be very common place: “Yeah, yeah, yeah, the AI system, and whatever. Yeah we got our data flywheel and we’re collecting what we’re doing, and doing all the things.” But, what’s the new good stuff, general AI, or whatever, where’s that going to be seeded? It may be in the companies, but probably more like there’ll be some kind of data partnership with academic institutions or something like that.</p>
<p><strong>Susan:</strong> You know, an interesting kind of area that data, this is pure speculation here, but where data could really start playing a different role is government-supplied datasets that you must conform to if you’re going to release something.</p>
<p><strong>Scott:</strong> Oh, yeah, like it has to fit these rules.</p>
<p><strong>Susan:</strong> Yeah. Or, “You must have learned from this dataset, and we’re going to test you against your ability to deal with these datasets.”</p>
<p><strong>Scott:</strong> Kind of an adversarial, like “If you can’t deal with this, then you’re not a good enough model?”</p>
<p><strong>Susan:</strong> Well, think about judging. We’ll make up a hypothetical doctor program. They have their test set of diagnostic cases that you must pass.</p>
<p><strong>Scott:</strong> Answer yes or no.</p>
<p><strong>Susan:</strong> Yeah, this becomes how to board-certify an algorithm.</p>
<p><strong>Scott:</strong> A really good point. Machine learning models in the future will probably be tested a lot like humans are now. There’s a curriculum and tests that you should pass and maybe you specialize in certain areas, but if you go work for one company the things that you learn there will probably also be transferred to other companies. Maybe it’s not trade secrets or something like that, but sort of underlying ways that humans work. It’s what happens for humans now. You go work for one company, fine. You leave, you go work for another company. Did you forget everything that happened for those years that you worked for that one company? No. So you bring those along with you. People will start to think of models that way.</p>
<p><strong>Susan:</strong> Yeah, it’s a really interesting world, just on the data side. Just so much that goes into curating a really good dataset, publicizing it and getting it accepted and all the areas.</p>
<h3 id="what-are-the-future-datasets-going-to-be">What are the future datasets going to be?</h3>
<p><strong>Scott:</strong> I think it’s going to be interesting. I think we are just in the very beginning stages. It’s like the first railroad was built across the US or something, now there’s going to be 3,000 railroads. It’s a similar type of thing. The first telephones were a long time ago, but it took a very long time after that until everybody had a telephone. It’s going to work it’s way into every part of life and, at least from my perspective, people shouldn’t be too afraid of it because it’s going to make your life so much easier.</p>
<p>So as long as the path is taken in a way that isn’t crazy, which, companies are pretty non-crazy now. They don’t want to scare you off from being a customer. Then it’s like, “Hey, this is going to evolve. It’s going to make your life way easier. Things are going to be more efficient. Then, you’ll just be very glad.”</p>
<p>Similarly to text messaging or Facebook or something like that. Hey, you’re giving up all this data and some privacy and things like that, but your life is so much better now that you can connect to your network that is spread across the world, essentially. Right?</p>
<p><strong>Susan:</strong> Yeah. I mean, as much as we are definitely challenged by the privacy, where it is today, no one is talking about giving up their connectivity. Well, I should say, I definitely know people who say they’re going to drop off social media, they’re going to drop off and you never hear from them again.</p>
<p><strong>Scott:</strong> But, are you going to stop using Google just because they used your search terms to help train their models to serve you better search terms? Probably not, right?</p>
<p>I think data obviously plays a big part now, but it’s going to play a very big part in the future. You’ll get your baselines set over the next few years, but then there’ll be all these offshoots that the rest of the world and life just starts to become easier because you get that labeling, flywheel going. “Hey, here’s some data. Hey, we labeled it. Hey we trained a model and then it did this task.”Then people will become used to it and they go, “Well, this is awesome. I don’t have to do all these menial tasks anymore.”</p>
<p><strong>Susan:</strong> It gives you that bootstrap. So one more final interesting aspect of all this is people don’t realize it, but the first hour is the hardest hour. The ten thousandth hour is way easier than the first hour. Even if the first hour isn’t as targeted as you’d like it to be, just having someone to have kicked out that first hour for you saves you so much work and effort, mentally, because now it gives you a structure- what the ten thousand hours might look like.</p>
<p><strong>Scott:</strong> It’s something to build off of. If you just have an example, you have a template, and it’s like, “Okay, maybe I’ll add one hour from my time to make that.” Now it’s a two hour dataset, and then it starts to build a community around it.</p>
<p><strong>Susan:</strong> Yeah, these things are like little seeds. These little datasets are just seeds.</p>
<p><strong>Scott:</strong> You’ve got to form it in the right way and then it grows.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/ai-show-how-will-data-influence-the-future-of-machine-learning/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
