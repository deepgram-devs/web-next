import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           */import '@storyblok/js';
/* empty css                          *//* empty css                              */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import 'camelcase';
/* empty css                              */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "getting-started-with-react", "text": "Getting Started with React" }, { "depth": 2, "slug": "adding-speech-to-text-with-deepgrams-node-sdk", "text": "Adding Speech-to-Text with Deepgram\u2019s Node SDK" }, { "depth": 2, "slug": "updating-your-front-end", "text": "Updating Your Front-End" }, { "depth": 2, "slug": "creating-a-server-connection", "text": "Creating a Server Connection" }, { "depth": 2, "slug": "connecting-the-websocket-to-the-front-end", "text": "Connecting the WebSocket to the Front-end" }], "source": "\nOne of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I\u2019ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don't, I've got you covered with a React project called *Affirmation*, that uses automatic speech recognition to boost self-confidence.\n\nBefore you jump into the code, I want to share a little bit about the inspiration for the project. According to [Christopher N Cascio, et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/), \u201CSelf-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.\u201D Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You\u2019ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.\n\n## Getting Started with React\n\n**Prerequisites**\n\n*   Understanding of JavaScript and React\n*   Familiarity of [hooks](https://reactjs.org/docs/hooks-intro.html)\n*   Understanding of HTML and CSS\n*   [Node.js](https://nodejs.org/en/download/) installed on your computer\n\nIf you want to follow along with this project, you can find the [code for the front-end here](https://github.com/deepgram-devs/react-app/tree/bare-react-app). To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you\u2019ll notice that you have a component called `Affirmation.js`.\n\nOnce you\u2019ve forked or cloned the code, cd into the app.\n\nIn your terminal run `npm install` to install the dependencies you can find the `package.json` file. Then run `npm run start` and navigate to `http://localhost:3000/`. You should see your app up and running. Right now, everything you see is being rendered from the `App.js` file. Here\u2019s what you should see.\n\n![Image of affirmation screen](https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png)\n\n## Adding Speech-to-Text with Deepgram's Node SDK\n\nNow that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You\u2019ll add a new button that allows the user to give microphone access and share their affirmation aloud.\n\nWhen they do this, the audio will be processed using [Deepgram\u2019s Node SDK](https://developers.deepgram.com/sdks-tools/sdks/node-sdk/), and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you\u2019ll be showing one transcript at a time.\n\n## Updating Your Front-End\n\nBefore you add your backend, update your `Affirmations.js` file. Below your Submit button, add a Voice button with the following code:\n\n```js\n<button>\n	onClick={activateMicrophone}\n	type='button'\n	className='submit-button'>\n	Voice \u{1F4AC}\n</button>\n```\n\nYou\u2019ll notice that you have an `onClick` function called `activateMicrophone`, which doesn\u2019t exist yet. So next, create that function.\n\nJust below your `handleChange` function, add the function with a console.log and the steps you need to take to get things working.\n\n```js\nconst activateMicrophone = ( ) => {\n\n	console.log(\"Submit\")\n\n	//Add microphone access\n\n	//create a WebSocket connection\n\n}\n```\n\nTo add microphone access, you\u2019ll use the [Media Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API). Setting this up allows the browser to ask the user for access to their microphone. You do this by using the [MediaDevices interface](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices). Designate that you\u2019re using audio and then create a new variable `const mediaRecorder` to use when implementing Deepgram.\n\nBelow the \"Add microphone access\" comment, add the following:\n\n```js\nnavigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {\n	const mediaRecorder = new MediaRecorder(stream)\n	// You\u2019ll add more code here later\n})\n```\n\nIt's time to pause. You've made it as far as you can without connecting to the server.\n\n## Creating a Server Connection\n\nNow you\u2019re going to work on setting up your connection to Deepgram\u2019s Node.js SDK and WebSocket connection.\n\nBecause you\u2019re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin\u2019s post [Browser Live Transcription - Protecting Your API Key](https://blog.deepgram.com/protecting-api-key/). Using the terminal, let\u2019s run\n`npm i @deepgram/sdk dotenv` to add Deepgram and `dotenv` to your project.\n\nNext, you\u2019ll need to:\n\n*   Create a Deepgram API Key with an admin or owner role - get it [here](https://console.deepgram.com/signup?jump=keys).\n*   Create a file called .env and add `DG_KEY='your-API-key'`.\n\nAt the root of your project, add a `server` folder with a `server.js` file. In that file, you need three things to happen:\n\n1.  Create a WebSocket connection\n2.  When the WebSocket connection is open, Deepgram will create a live transcription.\n3.  Once the data is received, send the transcript (as `data`) to your `Affirmation.js` component to record in your app.\n\nTo do this, use the following code:\n\n```js\nrequire('dotenv').config()\n\n// Add Deepgram so you can get the transcription\nconst { Deepgram } = require('@deepgram/sdk')\nconst deepgram = new Deepgram(process.env.DEEPGRAM_KEY)\n\n// Add WebSocket\nconst WebSocket = require('ws')\nconst wss = new WebSocket.Server({ port: 3002 })\n\n// Open WebSocket connection and initiate live transcription\nwss.on('connection', (ws) => {\n	const deepgramLive = deepgram.transcription.live({\n		interim_results: true,\n		punctuate: true,\n		endpointing: true,\n		vad_turnoff: 500,\n	})\n\n	deepgramLive.addListener('open', () => console.log('dg onopen'))\n	deepgramLive.addListener('error', (error) => console.log({ error }))\n\n	ws.onmessage = (event) => deepgramLive.send(event.data)\n	ws.onclose = () => deepgramLive.finish()\n\n	deepgramLive.addListener('transcriptReceived', (data) => ws.send(data))\n})\n\n\n```\n\nYour server is ready to go! Now you just need to put the finishing touches on your `Affirmation.js` file.\n\n## Connecting the WebSocket to the Front-end\n\nYou need to be able to check if the WebSocket is open. To do this, you\u2019re going to use the built-in hook from React, [useRef](https://reactjs.org/docs/hooks-reference.html#useref).\n\nMake sure you import `useRef`. Once you\u2019ve done that, add `const socketRef = useRef(null)` just below your `finalAffirmation` hook.\n\nNow you\u2019re ready to connect our frontend code to your server.\n\nWithin the `activateMicrophone` function-below the `mediaRecorder` variable-you\u2019ll:\n\n*   Create and open a new WebSocket.\n*   Update the value of `setAffirmation` with the results of the transcript.\n*   Close the socket and handle errors.\n\nGo ahead and add this to your file:\n\n```js\nconst socket = new WebSocket('ws://localhost:3002')\n\nsocket.onopen = () => {\n	console.log({ event: 'onopen' })\n	mediaRecorder.addEventListener('dataavailable', async (event) => {\n		if (event.data.size > 0 && socket.readyState === 1) {\n			socket.send(event.data)\n		}\n	})\n	mediaRecorder.start(1000)\n}\n\nsocket.onmessage = (message) => {\n	const received = JSON.parse(message.data)\n	const transcript = received.channel.alternatives[0].transcript\n	if (transcript) {\n		console.log(transcript)\n		setAffirmation(transcript)\n	}\n}\n\nsocket.onclose = () => {\n	console.log({ event: 'onclose' })\n}\n\nsocket.onerror = (error) => {\n	console.log({ event: 'onerror', error })\n}\n\nsocketRef.current = socket\n\n```\n\nYou\u2019re almost there. Your very last step is to close your WebSocket in your `handleSubmit` function if it\u2019s open. Just before `setFinalAffirmation(true)` add the following:\n\n```js\nif (socketRef.current !== null) {\n	socketRef.current.close()\n}\n```\n\nGo ahead and run this now. You should still have your React app running on `localhost:3000`, but you need to get that server running. To do that, go to your terminal and run `node server/server.js`. Click the Voice button.\n\nYou should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: \u201CI am intelligent.\u201D\n\nYou should see that text in your text box. Hit submit. There it is!\n\nAs you\u2019ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you\u2019ve done it. And now you\u2019ve done it! You can also find all the code in the [repo for this project](https://github.com/deepgram-devs/react-app). To learn more about the features you have access to with our Node SDK, check out our [Node SDK documentation](https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/). If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, [@DeepgramDevs](https://twitter.com/DeepgramDevs).\n\n        ", "html": `<p>One of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I\u2019ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don\u2019t, I\u2019ve got you covered with a React project called <em>Affirmation</em>, that uses automatic speech recognition to boost self-confidence.</p>
<p>Before you jump into the code, I want to share a little bit about the inspiration for the project. According to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/">Christopher N Cascio, et al.</a>, \u201CSelf-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.\u201D Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You\u2019ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.</p>
<h2 id="getting-started-with-react">Getting Started with React</h2>
<p><strong>Prerequisites</strong></p>
<ul>
<li>Understanding of JavaScript and React</li>
<li>Familiarity of <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a></li>
<li>Understanding of HTML and CSS</li>
<li><a href="https://nodejs.org/en/download/">Node.js</a> installed on your computer</li>
</ul>
<p>If you want to follow along with this project, you can find the <a href="https://github.com/deepgram-devs/react-app/tree/bare-react-app">code for the front-end here</a>. To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you\u2019ll notice that you have a component called <code is:raw>Affirmation.js</code>.</p>
<p>Once you\u2019ve forked or cloned the code, cd into the app.</p>
<p>In your terminal run <code is:raw>npm install</code> to install the dependencies you can find the <code is:raw>package.json</code> file. Then run <code is:raw>npm run start</code> and navigate to <code is:raw>http://localhost:3000/</code>. You should see your app up and running. Right now, everything you see is being rendered from the <code is:raw>App.js</code> file. Here\u2019s what you should see.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png" alt="Image of affirmation screen"></p>
<h2 id="adding-speech-to-text-with-deepgrams-node-sdk">Adding Speech-to-Text with Deepgram\u2019s Node SDK</h2>
<p>Now that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You\u2019ll add a new button that allows the user to give microphone access and share their affirmation aloud.</p>
<p>When they do this, the audio will be processed using <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/">Deepgram\u2019s Node SDK</a>, and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you\u2019ll be showing one transcript at a time.</p>
<h2 id="updating-your-front-end">Updating Your Front-End</h2>
<p>Before you add your backend, update your <code is:raw>Affirmations.js</code> file. Below your Submit button, add a Voice button with the following code:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">&lt;</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	onClick=</span><span style="color: #FF7B72">{</span><span style="color: #C9D1D9">activateMicrophone</span><span style="color: #FF7B72">}</span></span>
<span class="line"><span style="color: #C9D1D9">	type=&#39;button&#39;</span></span>
<span class="line"><span style="color: #C9D1D9">	className=&#39;submit-button&#39;&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	Voice \u{1F4AC}</span></span>
<span class="line"><span style="color: #C9D1D9">&lt;/</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span></code></pre>
<p>You\u2019ll notice that you have an <code is:raw>onClick</code> function called <code is:raw>activateMicrophone</code>, which doesn\u2019t exist yet. So next, create that function.</p>
<p>Just below your <code is:raw>handleChange</code> function, add the function with a console.log and the steps you need to take to get things working.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">activateMicrophone</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ( ) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Submit&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//Add microphone access</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//create a WebSocket connection</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>To add microphone access, you\u2019ll use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API">Media Streams API</a>. Setting this up allows the browser to ask the user for access to their microphone. You do this by using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">MediaDevices interface</a>. Designate that you\u2019re using audio and then create a new variable <code is:raw>const mediaRecorder</code> to use when implementing Deepgram.</p>
<p>Below the \u201CAdd microphone access\u201D comment, add the following:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">navigator.mediaDevices.</span><span style="color: #D2A8FF">getUserMedia</span><span style="color: #C9D1D9">({ audio: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9"> }).</span><span style="color: #D2A8FF">then</span><span style="color: #C9D1D9">((</span><span style="color: #FFA657">stream</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">mediaRecorder</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">MediaRecorder</span><span style="color: #C9D1D9">(stream)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">// You\u2019ll add more code here later</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span></code></pre>
<p>It\u2019s time to pause. You\u2019ve made it as far as you can without connecting to the server.</p>
<h2 id="creating-a-server-connection">Creating a Server Connection</h2>
<p>Now you\u2019re going to work on setting up your connection to Deepgram\u2019s Node.js SDK and WebSocket connection.</p>
<p>Because you\u2019re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin\u2019s post <a href="https://blog.deepgram.com/protecting-api-key/">Browser Live Transcription - Protecting Your API Key</a>. Using the terminal, let\u2019s run
<code is:raw>npm i @deepgram/sdk dotenv</code> to add Deepgram and <code is:raw>dotenv</code> to your project.</p>
<p>Next, you\u2019ll need to:</p>
<ul>
<li>Create a Deepgram API Key with an admin or owner role - get it <a href="https://console.deepgram.com/signup?jump=keys">here</a>.</li>
<li>Create a file called .env and add <code is:raw>DG_KEY='your-API-key'</code>.</li>
</ul>
<p>At the root of your project, add a <code is:raw>server</code> folder with a <code is:raw>server.js</code> file. In that file, you need three things to happen:</p>
<ol>
<li>Create a WebSocket connection</li>
<li>When the WebSocket connection is open, Deepgram will create a live transcription.</li>
<li>Once the data is received, send the transcript (as <code is:raw>data</code>) to your <code is:raw>Affirmation.js</code> component to record in your app.</li>
</ol>
<p>To do this, use the following code:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dotenv&#39;</span><span style="color: #C9D1D9">).</span><span style="color: #D2A8FF">config</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add Deepgram so you can get the transcription</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> { </span><span style="color: #79C0FF">Deepgram</span><span style="color: #C9D1D9"> } </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;@deepgram/sdk&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgram</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">Deepgram</span><span style="color: #C9D1D9">(process.env.</span><span style="color: #79C0FF">DEEPGRAM_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add WebSocket</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">WebSocket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">wss</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> WebSocket.</span><span style="color: #D2A8FF">Server</span><span style="color: #C9D1D9">({ port: </span><span style="color: #79C0FF">3002</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Open WebSocket connection and initiate live transcription</span></span>
<span class="line"><span style="color: #C9D1D9">wss.</span><span style="color: #D2A8FF">on</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;connection&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">ws</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgramLive</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> deepgram.transcription.</span><span style="color: #D2A8FF">live</span><span style="color: #C9D1D9">({</span></span>
<span class="line"><span style="color: #C9D1D9">		interim_results: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		punctuate: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		endpointing: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		vad_turnoff: </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;open&#39;</span><span style="color: #C9D1D9">, () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dg onopen&#39;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;error&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ error }))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">finish</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;transcriptReceived&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">data</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> ws.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(data))</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
<p>Your server is ready to go! Now you just need to put the finishing touches on your <code is:raw>Affirmation.js</code> file.</p>
<h2 id="connecting-the-websocket-to-the-front-end">Connecting the WebSocket to the Front-end</h2>
<p>You need to be able to check if the WebSocket is open. To do this, you\u2019re going to use the built-in hook from React, <a href="https://reactjs.org/docs/hooks-reference.html#useref">useRef</a>.</p>
<p>Make sure you import <code is:raw>useRef</code>. Once you\u2019ve done that, add <code is:raw>const socketRef = useRef(null)</code> just below your <code is:raw>finalAffirmation</code> hook.</p>
<p>Now you\u2019re ready to connect our frontend code to your server.</p>
<p>Within the <code is:raw>activateMicrophone</code> function-below the <code is:raw>mediaRecorder</code> variable-you\u2019ll:</p>
<ul>
<li>Create and open a new WebSocket.</li>
<li>Update the value of <code is:raw>setAffirmation</code> with the results of the transcript.</li>
<li>Close the socket and handle errors.</li>
</ul>
<p>Go ahead and add this to your file:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">socket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">WebSocket</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws://localhost:3002&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onopen</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onopen&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">addEventListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dataavailable&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (event.data.size </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">&amp;&amp;</span><span style="color: #C9D1D9"> socket.readyState </span><span style="color: #FF7B72">===</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">			socket.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">		}</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">start</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">message</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">received</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">JSON</span><span style="color: #C9D1D9">.</span><span style="color: #D2A8FF">parse</span><span style="color: #C9D1D9">(message.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">transcript</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> received.channel.alternatives[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].transcript</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (transcript) {</span></span>
<span class="line"><span style="color: #C9D1D9">		console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #D2A8FF">setAffirmation</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">	}</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onclose&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onerror</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onerror&#39;</span><span style="color: #C9D1D9">, error })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socketRef.current </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> socket</span></span>
<span class="line"></span></code></pre>
<p>You\u2019re almost there. Your very last step is to close your WebSocket in your <code is:raw>handleSubmit</code> function if it\u2019s open. Just before <code is:raw>setFinalAffirmation(true)</code> add the following:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (socketRef.current </span><span style="color: #FF7B72">!==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">null</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">	socketRef.current.</span><span style="color: #D2A8FF">close</span><span style="color: #C9D1D9">()</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>Go ahead and run this now. You should still have your React app running on <code is:raw>localhost:3000</code>, but you need to get that server running. To do that, go to your terminal and run <code is:raw>node server/server.js</code>. Click the Voice button.</p>
<p>You should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: \u201CI am intelligent.\u201D</p>
<p>You should see that text in your text box. Hit submit. There it is!</p>
<p>As you\u2019ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you\u2019ve done it. And now you\u2019ve done it! You can also find all the code in the <a href="https://github.com/deepgram-devs/react-app">repo for this project</a>. To learn more about the features you have access to with our Node SDK, check out our <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/">Node SDK documentation</a>. If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, <a href="https://twitter.com/DeepgramDevs">@DeepgramDevs</a>.</p>` };
const frontmatter = { "title": "How to Add Speech Recognition to Your React and Node.js project", "description": "Do you have a React project that could use speech-to-text? This tutorial will go through the steps to upgrade your React project with Deepgram transcriptions.", "date": "2022-06-20T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1655815938/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/How-to-Add-Speech-Recognition-to-Your-React-Project-blog.png", "authors": ["bekah-hawrot-weigel"], "category": "tutorial", "tags": ["reactjs"], "seo": { "title": "How to Add Speech Recognition to Your React and Node.js project", "description": "Do you have a React project that could use speech-to-text? This tutorial will go through the steps to upgrade your React project with Deepgram transcriptions." }, "shorturls": { "share": "https://dpgr.am/d4e9f5a", "twitter": "https://dpgr.am/6a86a1c", "linkedin": "https://dpgr.am/3508bf1", "reddit": "https://dpgr.am/c31ff53", "facebook": "https://dpgr.am/859f3ae" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454098/blog/how-to-add-speech-recognition-to-your-react-project/ograph.png" }, "astro": { "headings": [{ "depth": 2, "slug": "getting-started-with-react", "text": "Getting Started with React" }, { "depth": 2, "slug": "adding-speech-to-text-with-deepgrams-node-sdk", "text": "Adding Speech-to-Text with Deepgram\u2019s Node SDK" }, { "depth": 2, "slug": "updating-your-front-end", "text": "Updating Your Front-End" }, { "depth": 2, "slug": "creating-a-server-connection", "text": "Creating a Server Connection" }, { "depth": 2, "slug": "connecting-the-websocket-to-the-front-end", "text": "Connecting the WebSocket to the Front-end" }], "source": "\nOne of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I\u2019ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don't, I've got you covered with a React project called *Affirmation*, that uses automatic speech recognition to boost self-confidence.\n\nBefore you jump into the code, I want to share a little bit about the inspiration for the project. According to [Christopher N Cascio, et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/), \u201CSelf-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.\u201D Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You\u2019ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.\n\n## Getting Started with React\n\n**Prerequisites**\n\n*   Understanding of JavaScript and React\n*   Familiarity of [hooks](https://reactjs.org/docs/hooks-intro.html)\n*   Understanding of HTML and CSS\n*   [Node.js](https://nodejs.org/en/download/) installed on your computer\n\nIf you want to follow along with this project, you can find the [code for the front-end here](https://github.com/deepgram-devs/react-app/tree/bare-react-app). To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you\u2019ll notice that you have a component called `Affirmation.js`.\n\nOnce you\u2019ve forked or cloned the code, cd into the app.\n\nIn your terminal run `npm install` to install the dependencies you can find the `package.json` file. Then run `npm run start` and navigate to `http://localhost:3000/`. You should see your app up and running. Right now, everything you see is being rendered from the `App.js` file. Here\u2019s what you should see.\n\n![Image of affirmation screen](https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png)\n\n## Adding Speech-to-Text with Deepgram's Node SDK\n\nNow that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You\u2019ll add a new button that allows the user to give microphone access and share their affirmation aloud.\n\nWhen they do this, the audio will be processed using [Deepgram\u2019s Node SDK](https://developers.deepgram.com/sdks-tools/sdks/node-sdk/), and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you\u2019ll be showing one transcript at a time.\n\n## Updating Your Front-End\n\nBefore you add your backend, update your `Affirmations.js` file. Below your Submit button, add a Voice button with the following code:\n\n```js\n<button>\n	onClick={activateMicrophone}\n	type='button'\n	className='submit-button'>\n	Voice \u{1F4AC}\n</button>\n```\n\nYou\u2019ll notice that you have an `onClick` function called `activateMicrophone`, which doesn\u2019t exist yet. So next, create that function.\n\nJust below your `handleChange` function, add the function with a console.log and the steps you need to take to get things working.\n\n```js\nconst activateMicrophone = ( ) => {\n\n	console.log(\"Submit\")\n\n	//Add microphone access\n\n	//create a WebSocket connection\n\n}\n```\n\nTo add microphone access, you\u2019ll use the [Media Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API). Setting this up allows the browser to ask the user for access to their microphone. You do this by using the [MediaDevices interface](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices). Designate that you\u2019re using audio and then create a new variable `const mediaRecorder` to use when implementing Deepgram.\n\nBelow the \"Add microphone access\" comment, add the following:\n\n```js\nnavigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {\n	const mediaRecorder = new MediaRecorder(stream)\n	// You\u2019ll add more code here later\n})\n```\n\nIt's time to pause. You've made it as far as you can without connecting to the server.\n\n## Creating a Server Connection\n\nNow you\u2019re going to work on setting up your connection to Deepgram\u2019s Node.js SDK and WebSocket connection.\n\nBecause you\u2019re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin\u2019s post [Browser Live Transcription - Protecting Your API Key](https://blog.deepgram.com/protecting-api-key/). Using the terminal, let\u2019s run\n`npm i @deepgram/sdk dotenv` to add Deepgram and `dotenv` to your project.\n\nNext, you\u2019ll need to:\n\n*   Create a Deepgram API Key with an admin or owner role - get it [here](https://console.deepgram.com/signup?jump=keys).\n*   Create a file called .env and add `DG_KEY='your-API-key'`.\n\nAt the root of your project, add a `server` folder with a `server.js` file. In that file, you need three things to happen:\n\n1.  Create a WebSocket connection\n2.  When the WebSocket connection is open, Deepgram will create a live transcription.\n3.  Once the data is received, send the transcript (as `data`) to your `Affirmation.js` component to record in your app.\n\nTo do this, use the following code:\n\n```js\nrequire('dotenv').config()\n\n// Add Deepgram so you can get the transcription\nconst { Deepgram } = require('@deepgram/sdk')\nconst deepgram = new Deepgram(process.env.DEEPGRAM_KEY)\n\n// Add WebSocket\nconst WebSocket = require('ws')\nconst wss = new WebSocket.Server({ port: 3002 })\n\n// Open WebSocket connection and initiate live transcription\nwss.on('connection', (ws) => {\n	const deepgramLive = deepgram.transcription.live({\n		interim_results: true,\n		punctuate: true,\n		endpointing: true,\n		vad_turnoff: 500,\n	})\n\n	deepgramLive.addListener('open', () => console.log('dg onopen'))\n	deepgramLive.addListener('error', (error) => console.log({ error }))\n\n	ws.onmessage = (event) => deepgramLive.send(event.data)\n	ws.onclose = () => deepgramLive.finish()\n\n	deepgramLive.addListener('transcriptReceived', (data) => ws.send(data))\n})\n\n\n```\n\nYour server is ready to go! Now you just need to put the finishing touches on your `Affirmation.js` file.\n\n## Connecting the WebSocket to the Front-end\n\nYou need to be able to check if the WebSocket is open. To do this, you\u2019re going to use the built-in hook from React, [useRef](https://reactjs.org/docs/hooks-reference.html#useref).\n\nMake sure you import `useRef`. Once you\u2019ve done that, add `const socketRef = useRef(null)` just below your `finalAffirmation` hook.\n\nNow you\u2019re ready to connect our frontend code to your server.\n\nWithin the `activateMicrophone` function-below the `mediaRecorder` variable-you\u2019ll:\n\n*   Create and open a new WebSocket.\n*   Update the value of `setAffirmation` with the results of the transcript.\n*   Close the socket and handle errors.\n\nGo ahead and add this to your file:\n\n```js\nconst socket = new WebSocket('ws://localhost:3002')\n\nsocket.onopen = () => {\n	console.log({ event: 'onopen' })\n	mediaRecorder.addEventListener('dataavailable', async (event) => {\n		if (event.data.size > 0 && socket.readyState === 1) {\n			socket.send(event.data)\n		}\n	})\n	mediaRecorder.start(1000)\n}\n\nsocket.onmessage = (message) => {\n	const received = JSON.parse(message.data)\n	const transcript = received.channel.alternatives[0].transcript\n	if (transcript) {\n		console.log(transcript)\n		setAffirmation(transcript)\n	}\n}\n\nsocket.onclose = () => {\n	console.log({ event: 'onclose' })\n}\n\nsocket.onerror = (error) => {\n	console.log({ event: 'onerror', error })\n}\n\nsocketRef.current = socket\n\n```\n\nYou\u2019re almost there. Your very last step is to close your WebSocket in your `handleSubmit` function if it\u2019s open. Just before `setFinalAffirmation(true)` add the following:\n\n```js\nif (socketRef.current !== null) {\n	socketRef.current.close()\n}\n```\n\nGo ahead and run this now. You should still have your React app running on `localhost:3000`, but you need to get that server running. To do that, go to your terminal and run `node server/server.js`. Click the Voice button.\n\nYou should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: \u201CI am intelligent.\u201D\n\nYou should see that text in your text box. Hit submit. There it is!\n\nAs you\u2019ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you\u2019ve done it. And now you\u2019ve done it! You can also find all the code in the [repo for this project](https://github.com/deepgram-devs/react-app). To learn more about the features you have access to with our Node SDK, check out our [Node SDK documentation](https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/). If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, [@DeepgramDevs](https://twitter.com/DeepgramDevs).\n\n        ", "html": `<p>One of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I\u2019ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don\u2019t, I\u2019ve got you covered with a React project called <em>Affirmation</em>, that uses automatic speech recognition to boost self-confidence.</p>
<p>Before you jump into the code, I want to share a little bit about the inspiration for the project. According to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/">Christopher N Cascio, et al.</a>, \u201CSelf-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.\u201D Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You\u2019ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.</p>
<h2 id="getting-started-with-react">Getting Started with React</h2>
<p><strong>Prerequisites</strong></p>
<ul>
<li>Understanding of JavaScript and React</li>
<li>Familiarity of <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a></li>
<li>Understanding of HTML and CSS</li>
<li><a href="https://nodejs.org/en/download/">Node.js</a> installed on your computer</li>
</ul>
<p>If you want to follow along with this project, you can find the <a href="https://github.com/deepgram-devs/react-app/tree/bare-react-app">code for the front-end here</a>. To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you\u2019ll notice that you have a component called <code is:raw>Affirmation.js</code>.</p>
<p>Once you\u2019ve forked or cloned the code, cd into the app.</p>
<p>In your terminal run <code is:raw>npm install</code> to install the dependencies you can find the <code is:raw>package.json</code> file. Then run <code is:raw>npm run start</code> and navigate to <code is:raw>http://localhost:3000/</code>. You should see your app up and running. Right now, everything you see is being rendered from the <code is:raw>App.js</code> file. Here\u2019s what you should see.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png" alt="Image of affirmation screen"></p>
<h2 id="adding-speech-to-text-with-deepgrams-node-sdk">Adding Speech-to-Text with Deepgram\u2019s Node SDK</h2>
<p>Now that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You\u2019ll add a new button that allows the user to give microphone access and share their affirmation aloud.</p>
<p>When they do this, the audio will be processed using <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/">Deepgram\u2019s Node SDK</a>, and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you\u2019ll be showing one transcript at a time.</p>
<h2 id="updating-your-front-end">Updating Your Front-End</h2>
<p>Before you add your backend, update your <code is:raw>Affirmations.js</code> file. Below your Submit button, add a Voice button with the following code:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">&lt;</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	onClick=</span><span style="color: #FF7B72">{</span><span style="color: #C9D1D9">activateMicrophone</span><span style="color: #FF7B72">}</span></span>
<span class="line"><span style="color: #C9D1D9">	type=&#39;button&#39;</span></span>
<span class="line"><span style="color: #C9D1D9">	className=&#39;submit-button&#39;&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	Voice \u{1F4AC}</span></span>
<span class="line"><span style="color: #C9D1D9">&lt;/</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span></code></pre>
<p>You\u2019ll notice that you have an <code is:raw>onClick</code> function called <code is:raw>activateMicrophone</code>, which doesn\u2019t exist yet. So next, create that function.</p>
<p>Just below your <code is:raw>handleChange</code> function, add the function with a console.log and the steps you need to take to get things working.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">activateMicrophone</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ( ) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Submit&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//Add microphone access</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//create a WebSocket connection</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>To add microphone access, you\u2019ll use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API">Media Streams API</a>. Setting this up allows the browser to ask the user for access to their microphone. You do this by using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">MediaDevices interface</a>. Designate that you\u2019re using audio and then create a new variable <code is:raw>const mediaRecorder</code> to use when implementing Deepgram.</p>
<p>Below the \u201CAdd microphone access\u201D comment, add the following:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">navigator.mediaDevices.</span><span style="color: #D2A8FF">getUserMedia</span><span style="color: #C9D1D9">({ audio: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9"> }).</span><span style="color: #D2A8FF">then</span><span style="color: #C9D1D9">((</span><span style="color: #FFA657">stream</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">mediaRecorder</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">MediaRecorder</span><span style="color: #C9D1D9">(stream)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">// You\u2019ll add more code here later</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span></code></pre>
<p>It\u2019s time to pause. You\u2019ve made it as far as you can without connecting to the server.</p>
<h2 id="creating-a-server-connection">Creating a Server Connection</h2>
<p>Now you\u2019re going to work on setting up your connection to Deepgram\u2019s Node.js SDK and WebSocket connection.</p>
<p>Because you\u2019re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin\u2019s post <a href="https://blog.deepgram.com/protecting-api-key/">Browser Live Transcription - Protecting Your API Key</a>. Using the terminal, let\u2019s run
<code is:raw>npm i @deepgram/sdk dotenv</code> to add Deepgram and <code is:raw>dotenv</code> to your project.</p>
<p>Next, you\u2019ll need to:</p>
<ul>
<li>Create a Deepgram API Key with an admin or owner role - get it <a href="https://console.deepgram.com/signup?jump=keys">here</a>.</li>
<li>Create a file called .env and add <code is:raw>DG_KEY='your-API-key'</code>.</li>
</ul>
<p>At the root of your project, add a <code is:raw>server</code> folder with a <code is:raw>server.js</code> file. In that file, you need three things to happen:</p>
<ol>
<li>Create a WebSocket connection</li>
<li>When the WebSocket connection is open, Deepgram will create a live transcription.</li>
<li>Once the data is received, send the transcript (as <code is:raw>data</code>) to your <code is:raw>Affirmation.js</code> component to record in your app.</li>
</ol>
<p>To do this, use the following code:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dotenv&#39;</span><span style="color: #C9D1D9">).</span><span style="color: #D2A8FF">config</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add Deepgram so you can get the transcription</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> { </span><span style="color: #79C0FF">Deepgram</span><span style="color: #C9D1D9"> } </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;@deepgram/sdk&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgram</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">Deepgram</span><span style="color: #C9D1D9">(process.env.</span><span style="color: #79C0FF">DEEPGRAM_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add WebSocket</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">WebSocket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">wss</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> WebSocket.</span><span style="color: #D2A8FF">Server</span><span style="color: #C9D1D9">({ port: </span><span style="color: #79C0FF">3002</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Open WebSocket connection and initiate live transcription</span></span>
<span class="line"><span style="color: #C9D1D9">wss.</span><span style="color: #D2A8FF">on</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;connection&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">ws</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgramLive</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> deepgram.transcription.</span><span style="color: #D2A8FF">live</span><span style="color: #C9D1D9">({</span></span>
<span class="line"><span style="color: #C9D1D9">		interim_results: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		punctuate: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		endpointing: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		vad_turnoff: </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;open&#39;</span><span style="color: #C9D1D9">, () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dg onopen&#39;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;error&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ error }))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">finish</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;transcriptReceived&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">data</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> ws.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(data))</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
<p>Your server is ready to go! Now you just need to put the finishing touches on your <code is:raw>Affirmation.js</code> file.</p>
<h2 id="connecting-the-websocket-to-the-front-end">Connecting the WebSocket to the Front-end</h2>
<p>You need to be able to check if the WebSocket is open. To do this, you\u2019re going to use the built-in hook from React, <a href="https://reactjs.org/docs/hooks-reference.html#useref">useRef</a>.</p>
<p>Make sure you import <code is:raw>useRef</code>. Once you\u2019ve done that, add <code is:raw>const socketRef = useRef(null)</code> just below your <code is:raw>finalAffirmation</code> hook.</p>
<p>Now you\u2019re ready to connect our frontend code to your server.</p>
<p>Within the <code is:raw>activateMicrophone</code> function-below the <code is:raw>mediaRecorder</code> variable-you\u2019ll:</p>
<ul>
<li>Create and open a new WebSocket.</li>
<li>Update the value of <code is:raw>setAffirmation</code> with the results of the transcript.</li>
<li>Close the socket and handle errors.</li>
</ul>
<p>Go ahead and add this to your file:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">socket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">WebSocket</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws://localhost:3002&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onopen</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onopen&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">addEventListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dataavailable&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (event.data.size </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">&amp;&amp;</span><span style="color: #C9D1D9"> socket.readyState </span><span style="color: #FF7B72">===</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">			socket.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">		}</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">start</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">message</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">received</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">JSON</span><span style="color: #C9D1D9">.</span><span style="color: #D2A8FF">parse</span><span style="color: #C9D1D9">(message.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">transcript</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> received.channel.alternatives[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].transcript</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (transcript) {</span></span>
<span class="line"><span style="color: #C9D1D9">		console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #D2A8FF">setAffirmation</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">	}</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onclose&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onerror</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onerror&#39;</span><span style="color: #C9D1D9">, error })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socketRef.current </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> socket</span></span>
<span class="line"></span></code></pre>
<p>You\u2019re almost there. Your very last step is to close your WebSocket in your <code is:raw>handleSubmit</code> function if it\u2019s open. Just before <code is:raw>setFinalAffirmation(true)</code> add the following:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (socketRef.current </span><span style="color: #FF7B72">!==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">null</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">	socketRef.current.</span><span style="color: #D2A8FF">close</span><span style="color: #C9D1D9">()</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>Go ahead and run this now. You should still have your React app running on <code is:raw>localhost:3000</code>, but you need to get that server running. To do that, go to your terminal and run <code is:raw>node server/server.js</code>. Click the Voice button.</p>
<p>You should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: \u201CI am intelligent.\u201D</p>
<p>You should see that text in your text box. Hit submit. There it is!</p>
<p>As you\u2019ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you\u2019ve done it. And now you\u2019ve done it! You can also find all the code in the <a href="https://github.com/deepgram-devs/react-app">repo for this project</a>. To learn more about the features you have access to with our Node SDK, check out our <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/">Node SDK documentation</a>. If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, <a href="https://twitter.com/DeepgramDevs">@DeepgramDevs</a>.</p>` }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/how-to-add-speech-recognition-to-your-react-project/index.md" };
function rawContent() {
  return "\nOne of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I\u2019ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don't, I've got you covered with a React project called *Affirmation*, that uses automatic speech recognition to boost self-confidence.\n\nBefore you jump into the code, I want to share a little bit about the inspiration for the project. According to [Christopher N Cascio, et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/), \u201CSelf-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.\u201D Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You\u2019ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.\n\n## Getting Started with React\n\n**Prerequisites**\n\n*   Understanding of JavaScript and React\n*   Familiarity of [hooks](https://reactjs.org/docs/hooks-intro.html)\n*   Understanding of HTML and CSS\n*   [Node.js](https://nodejs.org/en/download/) installed on your computer\n\nIf you want to follow along with this project, you can find the [code for the front-end here](https://github.com/deepgram-devs/react-app/tree/bare-react-app). To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you\u2019ll notice that you have a component called `Affirmation.js`.\n\nOnce you\u2019ve forked or cloned the code, cd into the app.\n\nIn your terminal run `npm install` to install the dependencies you can find the `package.json` file. Then run `npm run start` and navigate to `http://localhost:3000/`. You should see your app up and running. Right now, everything you see is being rendered from the `App.js` file. Here\u2019s what you should see.\n\n![Image of affirmation screen](https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png)\n\n## Adding Speech-to-Text with Deepgram's Node SDK\n\nNow that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You\u2019ll add a new button that allows the user to give microphone access and share their affirmation aloud.\n\nWhen they do this, the audio will be processed using [Deepgram\u2019s Node SDK](https://developers.deepgram.com/sdks-tools/sdks/node-sdk/), and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you\u2019ll be showing one transcript at a time.\n\n## Updating Your Front-End\n\nBefore you add your backend, update your `Affirmations.js` file. Below your Submit button, add a Voice button with the following code:\n\n```js\n<button>\n	onClick={activateMicrophone}\n	type='button'\n	className='submit-button'>\n	Voice \u{1F4AC}\n</button>\n```\n\nYou\u2019ll notice that you have an `onClick` function called `activateMicrophone`, which doesn\u2019t exist yet. So next, create that function.\n\nJust below your `handleChange` function, add the function with a console.log and the steps you need to take to get things working.\n\n```js\nconst activateMicrophone = ( ) => {\n\n	console.log(\"Submit\")\n\n	//Add microphone access\n\n	//create a WebSocket connection\n\n}\n```\n\nTo add microphone access, you\u2019ll use the [Media Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API). Setting this up allows the browser to ask the user for access to their microphone. You do this by using the [MediaDevices interface](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices). Designate that you\u2019re using audio and then create a new variable `const mediaRecorder` to use when implementing Deepgram.\n\nBelow the \"Add microphone access\" comment, add the following:\n\n```js\nnavigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {\n	const mediaRecorder = new MediaRecorder(stream)\n	// You\u2019ll add more code here later\n})\n```\n\nIt's time to pause. You've made it as far as you can without connecting to the server.\n\n## Creating a Server Connection\n\nNow you\u2019re going to work on setting up your connection to Deepgram\u2019s Node.js SDK and WebSocket connection.\n\nBecause you\u2019re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin\u2019s post [Browser Live Transcription - Protecting Your API Key](https://blog.deepgram.com/protecting-api-key/). Using the terminal, let\u2019s run\n`npm i @deepgram/sdk dotenv` to add Deepgram and `dotenv` to your project.\n\nNext, you\u2019ll need to:\n\n*   Create a Deepgram API Key with an admin or owner role - get it [here](https://console.deepgram.com/signup?jump=keys).\n*   Create a file called .env and add `DG_KEY='your-API-key'`.\n\nAt the root of your project, add a `server` folder with a `server.js` file. In that file, you need three things to happen:\n\n1.  Create a WebSocket connection\n2.  When the WebSocket connection is open, Deepgram will create a live transcription.\n3.  Once the data is received, send the transcript (as `data`) to your `Affirmation.js` component to record in your app.\n\nTo do this, use the following code:\n\n```js\nrequire('dotenv').config()\n\n// Add Deepgram so you can get the transcription\nconst { Deepgram } = require('@deepgram/sdk')\nconst deepgram = new Deepgram(process.env.DEEPGRAM_KEY)\n\n// Add WebSocket\nconst WebSocket = require('ws')\nconst wss = new WebSocket.Server({ port: 3002 })\n\n// Open WebSocket connection and initiate live transcription\nwss.on('connection', (ws) => {\n	const deepgramLive = deepgram.transcription.live({\n		interim_results: true,\n		punctuate: true,\n		endpointing: true,\n		vad_turnoff: 500,\n	})\n\n	deepgramLive.addListener('open', () => console.log('dg onopen'))\n	deepgramLive.addListener('error', (error) => console.log({ error }))\n\n	ws.onmessage = (event) => deepgramLive.send(event.data)\n	ws.onclose = () => deepgramLive.finish()\n\n	deepgramLive.addListener('transcriptReceived', (data) => ws.send(data))\n})\n\n\n```\n\nYour server is ready to go! Now you just need to put the finishing touches on your `Affirmation.js` file.\n\n## Connecting the WebSocket to the Front-end\n\nYou need to be able to check if the WebSocket is open. To do this, you\u2019re going to use the built-in hook from React, [useRef](https://reactjs.org/docs/hooks-reference.html#useref).\n\nMake sure you import `useRef`. Once you\u2019ve done that, add `const socketRef = useRef(null)` just below your `finalAffirmation` hook.\n\nNow you\u2019re ready to connect our frontend code to your server.\n\nWithin the `activateMicrophone` function-below the `mediaRecorder` variable-you\u2019ll:\n\n*   Create and open a new WebSocket.\n*   Update the value of `setAffirmation` with the results of the transcript.\n*   Close the socket and handle errors.\n\nGo ahead and add this to your file:\n\n```js\nconst socket = new WebSocket('ws://localhost:3002')\n\nsocket.onopen = () => {\n	console.log({ event: 'onopen' })\n	mediaRecorder.addEventListener('dataavailable', async (event) => {\n		if (event.data.size > 0 && socket.readyState === 1) {\n			socket.send(event.data)\n		}\n	})\n	mediaRecorder.start(1000)\n}\n\nsocket.onmessage = (message) => {\n	const received = JSON.parse(message.data)\n	const transcript = received.channel.alternatives[0].transcript\n	if (transcript) {\n		console.log(transcript)\n		setAffirmation(transcript)\n	}\n}\n\nsocket.onclose = () => {\n	console.log({ event: 'onclose' })\n}\n\nsocket.onerror = (error) => {\n	console.log({ event: 'onerror', error })\n}\n\nsocketRef.current = socket\n\n```\n\nYou\u2019re almost there. Your very last step is to close your WebSocket in your `handleSubmit` function if it\u2019s open. Just before `setFinalAffirmation(true)` add the following:\n\n```js\nif (socketRef.current !== null) {\n	socketRef.current.close()\n}\n```\n\nGo ahead and run this now. You should still have your React app running on `localhost:3000`, but you need to get that server running. To do that, go to your terminal and run `node server/server.js`. Click the Voice button.\n\nYou should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: \u201CI am intelligent.\u201D\n\nYou should see that text in your text box. Hit submit. There it is!\n\nAs you\u2019ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you\u2019ve done it. And now you\u2019ve done it! You can also find all the code in the [repo for this project](https://github.com/deepgram-devs/react-app). To learn more about the features you have access to with our Node SDK, check out our [Node SDK documentation](https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/). If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, [@DeepgramDevs](https://twitter.com/DeepgramDevs).\n\n        ";
}
function compiledContent() {
  return `<p>One of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I\u2019ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don\u2019t, I\u2019ve got you covered with a React project called <em>Affirmation</em>, that uses automatic speech recognition to boost self-confidence.</p>
<p>Before you jump into the code, I want to share a little bit about the inspiration for the project. According to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/">Christopher N Cascio, et al.</a>, \u201CSelf-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.\u201D Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You\u2019ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.</p>
<h2 id="getting-started-with-react">Getting Started with React</h2>
<p><strong>Prerequisites</strong></p>
<ul>
<li>Understanding of JavaScript and React</li>
<li>Familiarity of <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a></li>
<li>Understanding of HTML and CSS</li>
<li><a href="https://nodejs.org/en/download/">Node.js</a> installed on your computer</li>
</ul>
<p>If you want to follow along with this project, you can find the <a href="https://github.com/deepgram-devs/react-app/tree/bare-react-app">code for the front-end here</a>. To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you\u2019ll notice that you have a component called <code is:raw>Affirmation.js</code>.</p>
<p>Once you\u2019ve forked or cloned the code, cd into the app.</p>
<p>In your terminal run <code is:raw>npm install</code> to install the dependencies you can find the <code is:raw>package.json</code> file. Then run <code is:raw>npm run start</code> and navigate to <code is:raw>http://localhost:3000/</code>. You should see your app up and running. Right now, everything you see is being rendered from the <code is:raw>App.js</code> file. Here\u2019s what you should see.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png" alt="Image of affirmation screen"></p>
<h2 id="adding-speech-to-text-with-deepgrams-node-sdk">Adding Speech-to-Text with Deepgram\u2019s Node SDK</h2>
<p>Now that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You\u2019ll add a new button that allows the user to give microphone access and share their affirmation aloud.</p>
<p>When they do this, the audio will be processed using <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/">Deepgram\u2019s Node SDK</a>, and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you\u2019ll be showing one transcript at a time.</p>
<h2 id="updating-your-front-end">Updating Your Front-End</h2>
<p>Before you add your backend, update your <code is:raw>Affirmations.js</code> file. Below your Submit button, add a Voice button with the following code:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">&lt;</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	onClick=</span><span style="color: #FF7B72">{</span><span style="color: #C9D1D9">activateMicrophone</span><span style="color: #FF7B72">}</span></span>
<span class="line"><span style="color: #C9D1D9">	type=&#39;button&#39;</span></span>
<span class="line"><span style="color: #C9D1D9">	className=&#39;submit-button&#39;&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	Voice \u{1F4AC}</span></span>
<span class="line"><span style="color: #C9D1D9">&lt;/</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span></code></pre>
<p>You\u2019ll notice that you have an <code is:raw>onClick</code> function called <code is:raw>activateMicrophone</code>, which doesn\u2019t exist yet. So next, create that function.</p>
<p>Just below your <code is:raw>handleChange</code> function, add the function with a console.log and the steps you need to take to get things working.</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">activateMicrophone</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ( ) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Submit&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//Add microphone access</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//create a WebSocket connection</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>To add microphone access, you\u2019ll use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API">Media Streams API</a>. Setting this up allows the browser to ask the user for access to their microphone. You do this by using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">MediaDevices interface</a>. Designate that you\u2019re using audio and then create a new variable <code is:raw>const mediaRecorder</code> to use when implementing Deepgram.</p>
<p>Below the \u201CAdd microphone access\u201D comment, add the following:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">navigator.mediaDevices.</span><span style="color: #D2A8FF">getUserMedia</span><span style="color: #C9D1D9">({ audio: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9"> }).</span><span style="color: #D2A8FF">then</span><span style="color: #C9D1D9">((</span><span style="color: #FFA657">stream</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">mediaRecorder</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">MediaRecorder</span><span style="color: #C9D1D9">(stream)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">// You\u2019ll add more code here later</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span></code></pre>
<p>It\u2019s time to pause. You\u2019ve made it as far as you can without connecting to the server.</p>
<h2 id="creating-a-server-connection">Creating a Server Connection</h2>
<p>Now you\u2019re going to work on setting up your connection to Deepgram\u2019s Node.js SDK and WebSocket connection.</p>
<p>Because you\u2019re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin\u2019s post <a href="https://blog.deepgram.com/protecting-api-key/">Browser Live Transcription - Protecting Your API Key</a>. Using the terminal, let\u2019s run
<code is:raw>npm i @deepgram/sdk dotenv</code> to add Deepgram and <code is:raw>dotenv</code> to your project.</p>
<p>Next, you\u2019ll need to:</p>
<ul>
<li>Create a Deepgram API Key with an admin or owner role - get it <a href="https://console.deepgram.com/signup?jump=keys">here</a>.</li>
<li>Create a file called .env and add <code is:raw>DG_KEY='your-API-key'</code>.</li>
</ul>
<p>At the root of your project, add a <code is:raw>server</code> folder with a <code is:raw>server.js</code> file. In that file, you need three things to happen:</p>
<ol>
<li>Create a WebSocket connection</li>
<li>When the WebSocket connection is open, Deepgram will create a live transcription.</li>
<li>Once the data is received, send the transcript (as <code is:raw>data</code>) to your <code is:raw>Affirmation.js</code> component to record in your app.</li>
</ol>
<p>To do this, use the following code:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dotenv&#39;</span><span style="color: #C9D1D9">).</span><span style="color: #D2A8FF">config</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add Deepgram so you can get the transcription</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> { </span><span style="color: #79C0FF">Deepgram</span><span style="color: #C9D1D9"> } </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;@deepgram/sdk&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgram</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">Deepgram</span><span style="color: #C9D1D9">(process.env.</span><span style="color: #79C0FF">DEEPGRAM_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add WebSocket</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">WebSocket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">wss</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> WebSocket.</span><span style="color: #D2A8FF">Server</span><span style="color: #C9D1D9">({ port: </span><span style="color: #79C0FF">3002</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Open WebSocket connection and initiate live transcription</span></span>
<span class="line"><span style="color: #C9D1D9">wss.</span><span style="color: #D2A8FF">on</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;connection&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">ws</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgramLive</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> deepgram.transcription.</span><span style="color: #D2A8FF">live</span><span style="color: #C9D1D9">({</span></span>
<span class="line"><span style="color: #C9D1D9">		interim_results: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		punctuate: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		endpointing: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		vad_turnoff: </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;open&#39;</span><span style="color: #C9D1D9">, () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dg onopen&#39;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;error&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ error }))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">finish</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;transcriptReceived&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">data</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> ws.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(data))</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
<p>Your server is ready to go! Now you just need to put the finishing touches on your <code is:raw>Affirmation.js</code> file.</p>
<h2 id="connecting-the-websocket-to-the-front-end">Connecting the WebSocket to the Front-end</h2>
<p>You need to be able to check if the WebSocket is open. To do this, you\u2019re going to use the built-in hook from React, <a href="https://reactjs.org/docs/hooks-reference.html#useref">useRef</a>.</p>
<p>Make sure you import <code is:raw>useRef</code>. Once you\u2019ve done that, add <code is:raw>const socketRef = useRef(null)</code> just below your <code is:raw>finalAffirmation</code> hook.</p>
<p>Now you\u2019re ready to connect our frontend code to your server.</p>
<p>Within the <code is:raw>activateMicrophone</code> function-below the <code is:raw>mediaRecorder</code> variable-you\u2019ll:</p>
<ul>
<li>Create and open a new WebSocket.</li>
<li>Update the value of <code is:raw>setAffirmation</code> with the results of the transcript.</li>
<li>Close the socket and handle errors.</li>
</ul>
<p>Go ahead and add this to your file:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">socket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">WebSocket</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws://localhost:3002&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onopen</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onopen&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">addEventListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dataavailable&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (event.data.size </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">&amp;&amp;</span><span style="color: #C9D1D9"> socket.readyState </span><span style="color: #FF7B72">===</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">			socket.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">		}</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">start</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">message</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">received</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">JSON</span><span style="color: #C9D1D9">.</span><span style="color: #D2A8FF">parse</span><span style="color: #C9D1D9">(message.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">transcript</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> received.channel.alternatives[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].transcript</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (transcript) {</span></span>
<span class="line"><span style="color: #C9D1D9">		console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #D2A8FF">setAffirmation</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">	}</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onclose&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onerror</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onerror&#39;</span><span style="color: #C9D1D9">, error })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socketRef.current </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> socket</span></span>
<span class="line"></span></code></pre>
<p>You\u2019re almost there. Your very last step is to close your WebSocket in your <code is:raw>handleSubmit</code> function if it\u2019s open. Just before <code is:raw>setFinalAffirmation(true)</code> add the following:</p>
<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (socketRef.current </span><span style="color: #FF7B72">!==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">null</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">	socketRef.current.</span><span style="color: #D2A8FF">close</span><span style="color: #C9D1D9">()</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>Go ahead and run this now. You should still have your React app running on <code is:raw>localhost:3000</code>, but you need to get that server running. To do that, go to your terminal and run <code is:raw>node server/server.js</code>. Click the Voice button.</p>
<p>You should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: \u201CI am intelligent.\u201D</p>
<p>You should see that text in your text box. Hit submit. There it is!</p>
<p>As you\u2019ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you\u2019ve done it. And now you\u2019ve done it! You can also find all the code in the <a href="https://github.com/deepgram-devs/react-app">repo for this project</a>. To learn more about the features you have access to with our Node SDK, check out our <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/">Node SDK documentation</a>. If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, <a href="https://twitter.com/DeepgramDevs">@DeepgramDevs</a>.</p>`;
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/how-to-add-speech-recognition-to-your-react-project/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>One of my favorite pieces of advice for learning a new technology is to build a project that solves a need or interests you. I’ve been interested in finding ways to improve mental health for a long time. If you have a React project you can follow along with this post to add Deepgram for speech-to-text transcription to your project. If you don’t, I’ve got you covered with a React project called <em>Affirmation</em>, that uses automatic speech recognition to boost self-confidence.</p>
<p>Before you jump into the code, I want to share a little bit about the inspiration for the project. According to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814782/">Christopher N Cascio, et al.</a>, “Self-affirmation activates brain systems associated with self-related processing and reward and is reinforced by future orientation.” Other studies have indicated that motivational self-affirmations can impact how you view youself and your performance; they also can be more effective if spoken aloud. You’ll be taking an existing React project with a complete front-end and adding the capability to speak and transcribe your affirmation.</p>
<h2 id="getting-started-with-react">Getting Started with React</h2>
<p><strong>Prerequisites</strong></p>
<ul>
<li>Understanding of JavaScript and React</li>
<li>Familiarity of <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a></li>
<li>Understanding of HTML and CSS</li>
<li><a href="https://nodejs.org/en/download/">Node.js</a> installed on your computer</li>
</ul>
<p>If you want to follow along with this project, you can find the <a href="https://github.com/deepgram-devs/react-app/tree/bare-react-app">code for the front-end here</a>. To get started quickly, I used Create React App. The file structure for this project will be similar to what you get with Create React App, but you’ll notice that you have a component called <code>Affirmation.js</code>.</p>
<p>Once you’ve forked or cloned the code, cd into the app.</p>
<p>In your terminal run <code>npm install</code> to install the dependencies you can find the <code>package.json</code> file. Then run <code>npm run start</code> and navigate to <code>http://localhost:3000/</code>. You should see your app up and running. Right now, everything you see is being rendered from the <code>App.js</code> file. Here’s what you should see.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654259676/blog/2022/06/how-to-add-speech-recognition-to-your-react-project/affirmation-screen.png" alt="Image of affirmation screen"></p>
<h2 id="adding-speech-to-text-with-deepgrams-node-sdk">Adding Speech-to-Text with Deepgram’s Node SDK</h2>
<p>Now that your project is up and running, you can get started with adding the speaking capabilities with our Automatic Speech Recognition (ASR) technology. You’ll add a new button that allows the user to give microphone access and share their affirmation aloud.</p>
<p>When they do this, the audio will be processed using <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/">Deepgram’s Node SDK</a>, and the transcription will be submitted and appear on the screen. Although you could go deeper with this project by allowing the user to save the affirmation or collect all the affirmations, for the scope of this project, you’ll be showing one transcript at a time.</p>
<h2 id="updating-your-front-end">Updating Your Front-End</h2>
<p>Before you add your backend, update your <code>Affirmations.js</code> file. Below your Submit button, add a Voice button with the following code:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">&lt;</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	onClick=</span><span style="color: #FF7B72">{</span><span style="color: #C9D1D9">activateMicrophone</span><span style="color: #FF7B72">}</span></span>
<span class="line"><span style="color: #C9D1D9">	type=&#39;button&#39;</span></span>
<span class="line"><span style="color: #C9D1D9">	className=&#39;submit-button&#39;&gt;</span></span>
<span class="line"><span style="color: #C9D1D9">	Voice 💬</span></span>
<span class="line"><span style="color: #C9D1D9">&lt;/</span><span style="color: #7EE787">button</span><span style="color: #C9D1D9">&gt;</span></span></code></pre>
<p>You’ll notice that you have an <code>onClick</code> function called <code>activateMicrophone</code>, which doesn’t exist yet. So next, create that function.</p>
<p>Just below your <code>handleChange</code> function, add the function with a console.log and the steps you need to take to get things working.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">activateMicrophone</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ( ) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Submit&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//Add microphone access</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">//create a WebSocket connection</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>To add microphone access, you’ll use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API">Media Streams API</a>. Setting this up allows the browser to ask the user for access to their microphone. You do this by using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">MediaDevices interface</a>. Designate that you’re using audio and then create a new variable <code>const mediaRecorder</code> to use when implementing Deepgram.</p>
<p>Below the “Add microphone access” comment, add the following:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">navigator.mediaDevices.</span><span style="color: #D2A8FF">getUserMedia</span><span style="color: #C9D1D9">({ audio: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9"> }).</span><span style="color: #D2A8FF">then</span><span style="color: #C9D1D9">((</span><span style="color: #FFA657">stream</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">mediaRecorder</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">MediaRecorder</span><span style="color: #C9D1D9">(stream)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #8B949E">// You’ll add more code here later</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span></code></pre>
<p>It’s time to pause. You’ve made it as far as you can without connecting to the server.</p>
<h2 id="creating-a-server-connection">Creating a Server Connection</h2>
<p>Now you’re going to work on setting up your connection to Deepgram’s Node.js SDK and WebSocket connection.</p>
<p>Because you’re using API keys, you want to keep them safe. To learn more about keeping your API keys safe, check out Kevin’s post <a href="https://blog.deepgram.com/protecting-api-key/">Browser Live Transcription - Protecting Your API Key</a>. Using the terminal, let’s run
<code>npm i @deepgram/sdk dotenv</code> to add Deepgram and <code>dotenv</code> to your project.</p>
<p>Next, you’ll need to:</p>
<ul>
<li>Create a Deepgram API Key with an admin or owner role - get it <a href="https://console.deepgram.com/signup?jump=keys">here</a>.</li>
<li>Create a file called .env and add <code>DG_KEY='your-API-key'</code>.</li>
</ul>
<p>At the root of your project, add a <code>server</code> folder with a <code>server.js</code> file. In that file, you need three things to happen:</p>
<ol>
<li>Create a WebSocket connection</li>
<li>When the WebSocket connection is open, Deepgram will create a live transcription.</li>
<li>Once the data is received, send the transcript (as <code>data</code>) to your <code>Affirmation.js</code> component to record in your app.</li>
</ol>
<p>To do this, use the following code:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dotenv&#39;</span><span style="color: #C9D1D9">).</span><span style="color: #D2A8FF">config</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add Deepgram so you can get the transcription</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> { </span><span style="color: #79C0FF">Deepgram</span><span style="color: #C9D1D9"> } </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;@deepgram/sdk&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgram</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">Deepgram</span><span style="color: #C9D1D9">(process.env.</span><span style="color: #79C0FF">DEEPGRAM_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Add WebSocket</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">WebSocket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">require</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">wss</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> WebSocket.</span><span style="color: #D2A8FF">Server</span><span style="color: #C9D1D9">({ port: </span><span style="color: #79C0FF">3002</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E">// Open WebSocket connection and initiate live transcription</span></span>
<span class="line"><span style="color: #C9D1D9">wss.</span><span style="color: #D2A8FF">on</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;connection&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">ws</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">deepgramLive</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> deepgram.transcription.</span><span style="color: #D2A8FF">live</span><span style="color: #C9D1D9">({</span></span>
<span class="line"><span style="color: #C9D1D9">		interim_results: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		punctuate: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		endpointing: </span><span style="color: #79C0FF">true</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">		vad_turnoff: </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;open&#39;</span><span style="color: #C9D1D9">, () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dg onopen&#39;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;error&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ error }))</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	ws.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> deepgramLive.</span><span style="color: #D2A8FF">finish</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">	deepgramLive.</span><span style="color: #D2A8FF">addListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;transcriptReceived&#39;</span><span style="color: #C9D1D9">, (</span><span style="color: #FFA657">data</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> ws.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(data))</span></span>
<span class="line"><span style="color: #C9D1D9">})</span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
<p>Your server is ready to go! Now you just need to put the finishing touches on your <code>Affirmation.js</code> file.</p>
<h2 id="connecting-the-websocket-to-the-front-end">Connecting the WebSocket to the Front-end</h2>
<p>You need to be able to check if the WebSocket is open. To do this, you’re going to use the built-in hook from React, <a href="https://reactjs.org/docs/hooks-reference.html#useref">useRef</a>.</p>
<p>Make sure you import <code>useRef</code>. Once you’ve done that, add <code>const socketRef = useRef(null)</code> just below your <code>finalAffirmation</code> hook.</p>
<p>Now you’re ready to connect our frontend code to your server.</p>
<p>Within the <code>activateMicrophone</code> function-below the <code>mediaRecorder</code> variable-you’ll:</p>
<ul>
<li>Create and open a new WebSocket.</li>
<li>Update the value of <code>setAffirmation</code> with the results of the transcript.</li>
<li>Close the socket and handle errors.</li>
</ul>
<p>Go ahead and add this to your file:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">socket</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">new</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">WebSocket</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;ws://localhost:3002&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onopen</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onopen&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">addEventListener</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&#39;dataavailable&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">event</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (event.data.size </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">&amp;&amp;</span><span style="color: #C9D1D9"> socket.readyState </span><span style="color: #FF7B72">===</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">			socket.</span><span style="color: #D2A8FF">send</span><span style="color: #C9D1D9">(event.data)</span></span>
<span class="line"><span style="color: #C9D1D9">		}</span></span>
<span class="line"><span style="color: #C9D1D9">	})</span></span>
<span class="line"><span style="color: #C9D1D9">	mediaRecorder.</span><span style="color: #D2A8FF">start</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onmessage</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">message</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">received</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">JSON</span><span style="color: #C9D1D9">.</span><span style="color: #D2A8FF">parse</span><span style="color: #C9D1D9">(message.data)</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">const</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">transcript</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> received.channel.alternatives[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].transcript</span></span>
<span class="line"><span style="color: #C9D1D9">	</span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (transcript) {</span></span>
<span class="line"><span style="color: #C9D1D9">		console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">		</span><span style="color: #D2A8FF">setAffirmation</span><span style="color: #C9D1D9">(transcript)</span></span>
<span class="line"><span style="color: #C9D1D9">	}</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onclose</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> () </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onclose&#39;</span><span style="color: #C9D1D9"> })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socket.</span><span style="color: #D2A8FF">onerror</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> (</span><span style="color: #FFA657">error</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">=&gt;</span><span style="color: #C9D1D9"> {</span></span>
<span class="line"><span style="color: #C9D1D9">	console.</span><span style="color: #D2A8FF">log</span><span style="color: #C9D1D9">({ event: </span><span style="color: #A5D6FF">&#39;onerror&#39;</span><span style="color: #C9D1D9">, error })</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">socketRef.current </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> socket</span></span>
<span class="line"></span></code></pre>
<p>You’re almost there. Your very last step is to close your WebSocket in your <code>handleSubmit</code> function if it’s open. Just before <code>setFinalAffirmation(true)</code> add the following:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> (socketRef.current </span><span style="color: #FF7B72">!==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">null</span><span style="color: #C9D1D9">) {</span></span>
<span class="line"><span style="color: #C9D1D9">	socketRef.current.</span><span style="color: #D2A8FF">close</span><span style="color: #C9D1D9">()</span></span>
<span class="line"><span style="color: #C9D1D9">}</span></span></code></pre>
<p>Go ahead and run this now. You should still have your React app running on <code>localhost:3000</code>, but you need to get that server running. To do that, go to your terminal and run <code>node server/server.js</code>. Click the Voice button.</p>
<p>You should get a pop-up asking you to allow the use of your microphone. Go ahead and give your browser permission. Now, test it out. Try using this affirmation: “I am intelligent.”</p>
<p>You should see that text in your text box. Hit submit. There it is!</p>
<p>As you’ve seen, there are a couple of steps involved to get Deepgram live transcription in your React project, but luckily, the process is very repeatable once you’ve done it. And now you’ve done it! You can also find all the code in the <a href="https://github.com/deepgram-devs/react-app">repo for this project</a>. To learn more about the features you have access to with our Node SDK, check out our <a href="https://developers.deepgram.com/sdks-tools/sdks/node-sdk/streaming-transcription/">Node SDK documentation</a>. If you have questions or want to learn more about using Automatic Speech Recognition in your React project, please hit us up on Twitter, <a href="https://twitter.com/DeepgramDevs">@DeepgramDevs</a>.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/how-to-add-speech-recognition-to-your-react-project/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
