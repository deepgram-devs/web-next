import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           *//* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "setting-up-pytorch-torchaudio-for-audio-data-augmentation", "text": "Setting up PyTorch TorchAudio for Audio Data Augmentation" }, { "depth": 2, "slug": "adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio", "text": "Adding Effects for Audio Data Augmentation with PyTorch TorchAudio" }, { "depth": 2, "slug": "using-sound-effects-in-torchaudio", "text": "Using Sound Effects in Torchaudio" }, { "depth": 2, "slug": "adding-background-noise", "text": "Adding Background Noise" }, { "depth": 2, "slug": "adding-room-reverberation", "text": "Adding Room Reverberation" }, { "depth": 2, "slug": "advanced-resampling-of-audio-data-with-torchaudio", "text": "Advanced Resampling of Audio Data with TorchAudio" }, { "depth": 2, "slug": "audio-feature-extraction-with-pytorch-torchaudio", "text": "Audio Feature Extraction with PyTorch TorchAudio" }, { "depth": 2, "slug": "in-summary", "text": "In Summary" }], "source": 'PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, [TorchAudio](https://github.com/pytorch/audio). TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.\n\nIn this post, we\'ll cover:\n\n* [Setting up PyTorch TorchAudio for Audio Data Augmentation](#setting-up-pytorch-torchaudio-for-audio-data-augmentation)\n* [Adding Effects for Audio Data Augmentation with PyTorch TorchAudio](#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio)\n* [Using Sound Effects in Torchaudio](#using-sound-effects-in-torchaudio)\n* [Adding Background Noise](#adding-background-noise)\n* [Adding Room Reverberation](#adding-room-reverberation)\n* [Advanced Resampling of Audio Data with TorchAudio](#advanced-resampling-of-audio-data-with-torchaudio)\n* [Audio Feature Extraction with PyTorch TorchAudio](#audio-feature-extraction-with-pytorch-torchaudio)\n* [In Summary](#in-summary)\n\n## Setting up PyTorch TorchAudio for Audio Data Augmentation\n\nAt the time of writing, `torchaudio` is on version `0.11.0` and only works with Python versions 3.6 to 3.9. For this example, we\u2019ll be using Python 3.9. We\u2019ll also need to install some libraries before we dive in. The first libraries we\u2019ll need are `torch` and `torchaudio` from PyTorch. We\u2019ll be using `matplotlib` to plot our visual representations, `requests` to get the data, and `librosa` to do some more visual manipulations for spectrograms.\n\nTo get started we\u2019ll pip install all of these into a new virtual environment. [To start a virtual environment](https://blog.deepgram.com/python-virtual-environments/) run `python3 -m venv <new environment name>`. Then run `pip install torch torchaudio matplotlib requests librosa` and let `pip` install all the libraries necessary for this tutorial.\n\n## Adding Effects for Audio Data Augmentation with PyTorch TorchAudio\n\nRecently, we covered the basics of [how to manipulate audio data in Python](https://blog.deepgram.com/best-python-audio-manipulation-tools/). In this section we\u2019re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we\u2019ll go into specifics about how to add background noise at different sound levels and how to add room reverb.\n\nBefore we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can [skip](#using-sound-effects-in-torchaudio). It would be good to understand this code if you\u2019d like to continue testing on the provided data.\n\nIn the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we\u2019ll store the audio at. Next, we fetch the data and define some helper functions.\n\nFor this example, we\u2019ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and `numpy` representations of the sounds that we are working with.\n\n```py\nimport math\nimport os\n\nimport matplotlib.pyplot as plt\nimport requests\nimport torchaudio\nimport torch\n\n_SAMPLE_DIR = "_assets"\nSAMPLE_WAV_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav"\nSAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, "steam.wav")\n\nSAMPLE_RIR_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav"  # noqa: E501\nSAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, "rir.wav")\n\nSAMPLE_WAV_SPEECH_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"  # noqa: E501\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, "speech.wav")\n\nSAMPLE_NOISE_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav"  # noqa: E501\nSAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, "bg.wav")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\ndef _fetch_data():\n   uri = [(SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n           (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n           (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n           (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),]\n   for url, path in uri:\n       with open(path, "wb") as file_:\n           file_.write(requests.get(url).content)\n\n_fetch_data()\n\ndef _get_sample(path, resample=None):\n   effects = [["remix","1"]]\n   if resample:\n       effects.extend([\n           ["lowpass", f"{resample // 2}"],\n           ["rate", f"{resample}"]\n       ])\n   return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\ndef get_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n\ndef get_speech_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\ndef plot_waveform(waveform, sample_rate, title="Waveform", xlim=None, ylim=None):\n   waveform = waveform.numpy()\n   num_channels, num_frames = waveform.shape\n   time_axis = torch.arange(0, num_frames) / sample_rate\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].plot(time_axis, waveform[c], linewidth=1)\n       axes[c].grid(True)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n       if ylim:\n           axes[c].set_ylim(ylim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\ndef print_stats(waveform, sample_rate=None, src=None):\n   if src:\n       print("-"*10)\n       print(f"Source: {src}")\n       print("-"*10)\n   if sample_rate:\n       print(f"Sample Rate: {sample_rate}")\n   print("Dtype:", waveform.dtype)\n   print(f" - Max:     {waveform.max().item():6.3f}")\n   print(f" - Min:     {waveform.min().item():6.3f}")\n   print(f" - Mean:    {waveform.mean().item():6.3f}")\n   print(f" - Std Dev: {waveform.std().item():6.3f}")\n   print()\n   print(waveform)\n   print()\n\ndef plot_specgram(waveform, sample_rate, title="Spectrogram", xlim=None):\n   waveform = waveform.numpy()\n   num_channels, num_frames = waveform.shape\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].specgram(waveform[c], Fs=sample_rate)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\ndef get_rir_sample(*, resample=None, processed=False):\n   rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n   if not processed:\n       return rir_raw, sample_rate\n   rir = rir_raw[:, int(sample_rate*1.01) : int(sample_rate * 1.3)]\n   rir = rir / torch.norm(rir, p=2)\n   rir = torch.flip(rir, [1])\n   return rir, sample_rate\n\ndef get_noise_sample(*, resample=None):\n   return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n```\n\n## Using Sound Effects in Torchaudio\n\nNow that we\u2019ve set everything up, let\u2019s take a look at how to use PyTorch\u2019s `torchaudio` library to add sound effects. We\u2019re going to pass a list of list of strings (`List[List[Str]])` object to the `sox_effects.apply_effects_tensor` function from `torchaudio`.\n\nEach of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the [sox documentation](http://sox.sourceforge.net/sox.html). Note: this function returns two return values, the waveform and the new sample rate.\n\n```py\n# Load the data\nwaveform1, sample_rate1 = get_sample(resample=16000)\n\n# Define effects\neffects = [\n   ["lowpass", "-1", "300"],  # apply single-pole lowpass filter\n   ["speed", "0.8"],  # reduce the speed\n   # This only changes sample rate, so it is necessary to\n   # add `rate` effect with original sample rate after this.\n   ["rate", f"{sample_rate1}"],\n   ["reverb", "-w"],  # Reverbration gives some dramatic feeling\n]\n# Apply effects\nwaveform2, sample_rate2 = torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)\nprint_stats(waveform1, sample_rate=sample_rate1, src="Original")\nprint_stats(waveform2, sample_rate=sample_rate2, src="Effects Applied")\nplot_waveform(waveform1, sample_rate1, title="Original", xlim=(-0.1, 3.2))\nplot_specgram(waveform1, sample_rate1, title="Original", xlim=(0, 3.04))\nplot_waveform(waveform2, sample_rate2, title="Effects Applied", xlim=(-0.1, 3.2))\nplot_specgram(waveform2, sample_rate2, title="Effects Applied", xlim=(0, 3.04))\n```\n\nThe printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the \u201Cskinnier\u201D or quieter sections of the waveform.\n\n![Waveform and Spectrogram of Original and Augmented Audio Data](https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png)\n*Above: Original Waveform and Spectrogram + Added Effects from TorchAudio*\n\n## Adding Background Noise\n\nNow that we know how to add effects to audio using `torchaudio`, let\u2019s dive into some more specific use cases. If your model needs to be able to detect audio even when there\u2019s background noise, it\u2019s a good idea to add some background noise to your training data.\n\nIn the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we\u2019ll call our helper functions to get the speech and background noise and reshape the noise. After that, we\u2019ll use the `norm` function to normalize both the speech and the text to the [second order](https://pytorch.org/docs/stable/generated/torch.norm.html). Next, we\u2019ll define a list of decibels that we want to play the background noise at over the speech and create a \u201Cbackground noise\u201D version at each level.\n\n```py\nsample_rate = 8000\nspeech, _ = get_speech_sample(resample=sample_rate)\nnoise, _ = get_noise_sample(resample=sample_rate)\nnoise = noise[:, : speech.shape[1]]\n\nspeech_power = speech.norm(p=2)\nnoise_power = noise.norm(p=2)\n\nsnr_dbs = [20, 10, 3]\nnoisy_speeches = []\nfor snr_db in snr_dbs:\n   snr = math.exp(snr_db / 10)\n   scale = snr * noise_power / speech_power\n   noisy_speeches.append((scale * speech + noise) / 2)\n\nplot_waveform(noise, sample_rate, title="Background noise")\nplot_specgram(noise, sample_rate, title="Background noise")\n```\n\n![Waveform and Spectrogram of Noise Audio Data created by TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png)\n\nThe above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB `snr` means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.\n\n```py\n# background noise at certain levels\nsnr_db20, noisy_speech20 = snr_dbs[0], noisy_speeches[0]\nplot_waveform(noisy_speech20, sample_rate, title=f"SNR: {snr_db20} [dB]")\nplot_specgram(noisy_speech20, sample_rate, title=f"SNR: {snr_db20} [dB]")\n\nsnr_db10, noisy_speech10 = snr_dbs[1], noisy_speeches[1]\nplot_waveform(noisy_speech10, sample_rate, title=f"SNR: {snr_db10} [dB]")\nplot_specgram(noisy_speech10, sample_rate, title=f"SNR: {snr_db10} [dB]")\n\nsnr_db3, noisy_speech3 = snr_dbs[2], noisy_speeches[2]\nplot_waveform(noisy_speech3, sample_rate, title=f"SNR: {snr_db3} [dB]")\nplot_specgram(noisy_speech3, sample_rate, title=f"SNR: {snr_db3} [dB]")\n```\n\n![20 and 10 dB SNR added background audio data waveforms and spectrograms](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png)\n*Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio*\n\n![PyTorch generated waveform and spectrogram for 3 dB SNR background noise](https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png)\n*Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise*\n\n## Adding Room Reverberation\n\nSo far we\u2019ve applied audio effects and background noise at different noise levels. Let\u2019s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.\n\nTo add a room reverb, we\u2019re going to start by making a request for the audio from where it lives online using one of the functions we made above (`get_rir_sample`). We\u2019ll take a look at the waveform before we clip it to get the \u201Creverb\u201D of the sound, normalize it, and then flip the sound so that the reverb works correctly.\n\n```py\nsample_rate = 8000\n\nrir_raw, _ = get_rir_sample(resample=sample_rate)\n\nplot_waveform(rir_raw, sample_rate, title="Room Impulse Response (raw)", ylim=None)\nplot_specgram(rir_raw, sample_rate, title="Room Impulse Response (raw)")\n\nrir = rir_raw[:, int(sample_rate * 1.01) : int(sample_rate * 1.3)]\nrir = rir / torch.norm(rir, p=2)\nrir = torch.flip(rir, [1])\n\nprint_stats(rir)\nplot_waveform(rir, sample_rate, title="Room Impulse Response", ylim=None)\nplot_specgram(rir_raw, sample_rate, title="Room Impulse Response (raw)")\n```\n\n![Reverb audio data waveform and spectrogram with PyTorch](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png)\n*Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio*\n\nOnce we have the sound normalized and flipped, we\u2019re ready to use it to augment the existing audio. We will first use PyTorch to create a \u201Cpadding\u201D that uses the speech and the augmented sound. Then, we\u2019ll use PyTorch to apply the sound with a 1 dimensional convolution.\n\n```py\nspeech, _ = get_speech_sample(resample=sample_rate)\n\nspeech_ = torch.nn.functional.pad(speech, (rir.shape[1] - 1, 0))\naugmented = torch.nn.functional.conv1d(speech_[None, ...], rir[None, ...])[0]\n\nplot_waveform(speech, sample_rate, title="Original", ylim=None)\nplot_specgram(speech, sample_rate, title="Original")\nplay_audio(speech, sample_rate)\n\nplot_waveform(augmented, sample_rate, title="RIR Applied", ylim=None)\nplot_specgram(augmented, sample_rate, title="RIR Applied")\nplay_audio(augmented, sample_rate)\n```\n\n![Waveform and spectrogram for original and reverb\u2019d sound with PyTorch TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png)\n*Above: Visualizations for audio with reverb applied by TorchAudio*\n\nFrom the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.\n\n## Advanced Resampling of Audio Data with TorchAudio\n\nWe briefly mentioned how to resample data before using the `pydub` and the `sklearn` libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we\u2019ll cover how to resample data using low-pass, rolloff, and window filters.\n\nAs we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is `get_sine_sweep` which is what we\u2019ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.\n\n```py\nimport math\nimport torch\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio, display\n\n\nDEFAULT_OFFSET = 201\nSWEEP_MAX_SAMPLE_RATE = 48000\nDEFAULT_LOWPASS_FILTER_WIDTH = 6\nDEFAULT_ROLLOFF = 0.99\nDEFAULT_RESAMPLING_METHOD = "sinc_interpolation"\n\ndef _get_log_freq(sample_rate, max_sweep_rate, offset):\n   """Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n\n   offset is used to avoid negative infinity `log(offset + x)`.\n\n   """\n   start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n   return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n\ndef _get_inverse_log_freq(freq, sample_rate, offset):\n   """Find the time where the given frequency is given by _get_log_freq"""\n   half = sample_rate // 2\n   return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n\n\ndef _get_freq_ticks(sample_rate, offset, f_max):\n   # Given the original sample rate used for generating the sweep,\n   # find the x-axis value where the log-scale major frequency values fall in\n   time, freq = [], []\n   for exp in range(2, 5):\n       for v in range(1, 10):\n           f = v * 10 ** exp\n           if f < sample_rate // 2:\n               t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n               time.append(t)\n               freq.append(f)\n   t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n   time.append(t_max)\n   freq.append(f_max)\n   return time, freq\n\ndef get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n   max_sweep_rate = sample_rate\n   freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n   delta = 2 * math.pi * freq / sample_rate\n   cummulative = torch.cumsum(delta, dim=0)\n   signal = torch.sin(cummulative).unsqueeze(dim=0)\n   return signal\n\ndef plot_sweep(\n   waveform,\n   sample_rate,\n   title,\n   max_sweep_rate=SWEEP_MAX_SAMPLE_RATE,\n   offset=DEFAULT_OFFSET,\n):\n   x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n   y_ticks = [1000, 5000, 10000, 20000, sample_rate // 2]\n\n   time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n   freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n   freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n\n   figure, axis = plt.subplots(1, 1)\n   axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n   plt.xticks(time, freq_x)\n   plt.yticks(freq_y, freq_y)\n   axis.set_xlabel("Original Signal Frequency (Hz, log scale)")\n   axis.set_ylabel("Waveform Frequency (Hz)")\n   axis.xaxis.grid(True, alpha=0.67)\n   axis.yaxis.grid(True, alpha=0.67)\n   figure.suptitle(f"{title} (sample rate: {sample_rate} Hz)")\n   plt.show(block=True)\n\ndef plot_specgram(waveform, sample_rate, title="Spectrogram", xlim=None):\n   waveform = waveform.numpy()\n\n   num_channels, num_frames = waveform.shape\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].specgram(waveform[c], Fs=sample_rate)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n   figure.suptitle(title)\n   plt.show(block=False)\n```\n\nI put the two `torchaudio` imports here to clarify that these are the `T` and `F` letters we\u2019ll be using to pull functions from (as opposed to true and false!). We\u2019ll declare a sample rate and a resample rate, it doesn\u2019t really matter what these are, feel free to change these as it suits you.\n\nThe first thing we\u2019ll do is create a waveform using the `get_sine_sweep` function. Then, we\u2019ll do a resampling without passing any parameters. Next, we\u2019ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we\u2019ll need the functional `torchaudio` package.\n\nTechnically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio\u2019s default is 6 so our first and second resampling are the same. Larger values here result in \u201Csharper\u201D noise.\n\n```py\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nsample_rate = 48000\nresample_rate = 32000\n\nwaveform = get_sine_sweep(sample_rate)\nplot_sweep(waveform, sample_rate, title="Original Waveform")\n\nprint("basic resampling")\nresampler = T.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\nresampled_waveform = resampler(waveform)\nplot_sweep(resampled_waveform, resample_rate, title="Resampled Waveform")\n\nprint("lowpass resampling")\nlp6_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=6)\nplot_sweep(resampled_waveform, resample_rate, title="lowpass_filter_width=6")\n\nlp128_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=128)\nplot_sweep(resampled_waveform, resample_rate, title="lowpass_filter_width=128")\n```\n\n![Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png)\n*Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio*\n\nFilters are not the only thing we can use for resampling. In the example code below, we\u2019ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we\u2019ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.\n\n```py\nprint("using a window to resample")\nhann_window_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, resampling_method="sinc_interpolation")\nplot_sweep(resampled_waveform, resample_rate, title="Hann Window Default")\n\nkaiser_window_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, resampling_method="kaiser_window")\nplot_sweep(resampled_waveform, resample_rate, title="Kaiser Window Default")\n\nprint("user rollof to determine window")\nrolloff_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, rolloff=0.99)\nplot_sweep(resampled_waveform, resample_rate, title="rolloff=0.99")\n\nrolloff_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, rolloff=0.8)\nplot_sweep(resampled_waveform, resample_rate, title="rolloff=0.8")\n```\n\n![Resampling Audio Data with Windows and Rolloff filters](https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png)\n*Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio*\n\n## Audio Feature Extraction with PyTorch TorchAudio\n\nSo far we\u2019ve taken a look at how to use `torchaudio` in many ways to manipulate our audio data. Now let\u2019s take a look at how to do feature extraction with `torchaudio`. As we have in the two sections above, we\u2019ll start by setting up.\n\nOur setup functions will include functions to fetch the data as well as visualize it like the \u201Ceffects\u201D section above. We also add some functions for doing Mel scale buckets. We will use [Mel scale](https://en.wikipedia.org/wiki/Mel_scale) buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.\n\n```py\nimport os\n\nimport torch\nimport torchaudio\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nimport librosa\nimport matplotlib.pyplot as plt\nimport requests\n\n\n_SAMPLE_DIR = "_assets"\n\nSAMPLE_WAV_SPEECH_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"  # noqa: E501\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, "speech.wav")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\n\ndef _fetch_data():\n   uri = [\n       (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n   ]\n   for url, path in uri:\n       with open(path, "wb") as file_:\n           file_.write(requests.get(url).content)\n\n\n_fetch_data()\n\n\ndef _get_sample(path, resample=None):\n   effects = [["remix", "1"]]\n   if resample:\n       effects.extend(\n           [\n               ["lowpass", f"{resample // 2}"],\n               ["rate", f"{resample}"],\n           ]\n       )\n   return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\n\ndef get_speech_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\n\ndef plot_spectrogram(spec, title=None, ylabel="freq_bin", aspect="auto", xmax=None):\n   fig, axs = plt.subplots(1, 1)\n   axs.set_title(title or "Spectrogram (db)")\n   axs.set_ylabel(ylabel)\n   axs.set_xlabel("frame")\n   im = axs.imshow(librosa.power_to_db(spec), origin="lower", aspect=aspect)\n   if xmax:\n       axs.set_xlim((0, xmax))\n   fig.colorbar(im, ax=axs)\n   plt.show(block=False)\n\n\ndef plot_waveform(waveform, sample_rate, title="Waveform", xlim=None, ylim=None):\n   waveform = waveform.numpy()\n\n   num_channels, num_frames = waveform.shape\n   time_axis = torch.arange(0, num_frames) / sample_rate\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].plot(time_axis, waveform[c], linewidth=1)\n       axes[c].grid(True)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n       if ylim:\n           axes[c].set_ylim(ylim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\n\ndef plot_mel_fbank(fbank, title=None):\n   fig, axs = plt.subplots(1, 1)\n   axs.set_title(title or "Filter bank")\n   axs.imshow(fbank, aspect="auto")\n   axs.set_ylabel("frequency bin")\n   axs.set_xlabel("mel bin")\n   plt.show(block=False)\n```\n\nThe first thing we\u2019re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.\n\nWe\u2019ll define some constants before we create our spectrogram and reverse it. First, we want to define `n_fft`, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we\u2019ll call `torchaudio` to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we\u2019ll use the `GriffinLim` function from `torchaudio` with the same parameters we used above to turn the waveform into a spectrogram.\n\n```py\n# plot spectrogram\nwaveform, sample_rate = get_speech_sample()\n\nn_fft = 1024\nwin_length = None\nhop_length = 512\n\n# create spectrogram\ntorch.random.manual_seed(0)\nplot_waveform(waveform, sample_rate, title="Original")\n\nspec = T.Spectrogram(\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n)(waveform)\nplot_spectrogram(spec[0], title="torchaudio spec")\n\n# reverse spectrogram to waveform with griffinlim\ngriffin_lim = T.GriffinLim(\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n)\nwaveform = griffin_lim(spec)\nplot_waveform(waveform, sample_rate, title="Reconstructed")\n```\n\n![Waveform to Spectrogram and back with PyTorch](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png)\n*Above: Creating and reversing a spectrogram in PyTorch*\n\nLet\u2019s take a look at one of the more interesting things we can do with spectral features, [mel-frequency cepstrum](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum). The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we\u2019ll define a number of mel filterbanks (256), and a new sample rate to play with.\n\nThe first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we\u2019ll use that to get the mel spectrogram. Now, we\u2019re ready to get the coefficients. First we need to define how many coefficients we want, then we\u2019ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.\n\n```py\n# mel spectrogram\n# mel scale waveforms\n# mel scale bins\nn_mels = 256\nsample_rate = 6000\n\nmel_filters = F.melscale_fbanks(\n   int(n_fft // 2 + 1),\n   n_mels=n_mels,\n   f_min=0.0,\n   f_max=sample_rate / 2.0,\n   sample_rate=sample_rate,\n   norm="slaney",\n)\nplot_mel_fbank(mel_filters, "Mel Filter Bank - torchaudio")\n\n# mel spectrogram\nmel_spectrogram = T.MelSpectrogram(\n   sample_rate=sample_rate,\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n   center=True,\n   pad_mode="reflect",\n   power=2.0,\n   norm="slaney",\n   onesided=True,\n   n_mels=n_mels,\n   mel_scale="htk",\n)\n\nmelspec = mel_spectrogram(waveform)\nplot_spectrogram(melspec[0], title="MelSpectrogram - torchaudio", ylabel="mel freq")\n\nn_mfcc = 256\n\nmfcc_transform = T.MFCC(\n   sample_rate=sample_rate,\n   n_mfcc=n_mfcc,\n   melkwargs={\n       "n_fft": n_fft,\n       "n_mels": n_mels,\n       "hop_length": hop_length,\n       "mel_scale": "htk",\n   },\n)\n\nmfcc = mfcc_transform(waveform)\n\nplot_spectrogram(mfcc[0])\n```\n\n![Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png)\n*Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio*\n\n## In Summary\n\nIn this epic post, we covered the basics of how to use the `torchaudio` library from PyTorch. We saw that we can use `torchaudio` to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.\n\nTorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio\u2019s `functional` and `transform` libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.\n\nFinally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.', "html": '<p>PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, <a href="https://github.com/pytorch/audio">TorchAudio</a>. TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.</p>\n<p>In this post, we\u2019ll cover:</p>\n<ul>\n<li><a href="#setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</a></li>\n<li><a href="#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</a></li>\n<li><a href="#using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</a></li>\n<li><a href="#adding-background-noise">Adding Background Noise</a></li>\n<li><a href="#adding-room-reverberation">Adding Room Reverberation</a></li>\n<li><a href="#advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</a></li>\n<li><a href="#audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</a></li>\n<li><a href="#in-summary">In Summary</a></li>\n</ul>\n<h2 id="setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</h2>\n<p>At the time of writing, <code is:raw>torchaudio</code> is on version <code is:raw>0.11.0</code> and only works with Python versions 3.6 to 3.9. For this example, we\u2019ll be using Python 3.9. We\u2019ll also need to install some libraries before we dive in. The first libraries we\u2019ll need are <code is:raw>torch</code> and <code is:raw>torchaudio</code> from PyTorch. We\u2019ll be using <code is:raw>matplotlib</code> to plot our visual representations, <code is:raw>requests</code> to get the data, and <code is:raw>librosa</code> to do some more visual manipulations for spectrograms.</p>\n<p>To get started we\u2019ll pip install all of these into a new virtual environment. <a href="https://blog.deepgram.com/python-virtual-environments/">To start a virtual environment</a> run <code is:raw>python3 -m venv &lt;new environment name&gt;</code>. Then run <code is:raw>pip install torch torchaudio matplotlib requests librosa</code> and let <code is:raw>pip</code> install all the libraries necessary for this tutorial.</p>\n<h2 id="adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</h2>\n<p>Recently, we covered the basics of <a href="https://blog.deepgram.com/best-python-audio-manipulation-tools/">how to manipulate audio data in Python</a>. In this section we\u2019re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we\u2019ll go into specifics about how to add background noise at different sound levels and how to add room reverb.</p>\n<p>Before we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can <a href="#using-sound-effects-in-torchaudio">skip</a>. It would be good to understand this code if you\u2019d like to continue testing on the provided data.</p>\n<p>In the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we\u2019ll store the audio at. Next, we fetch the data and define some helper functions.</p>\n<p>For this example, we\u2019ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and <code is:raw>numpy</code> representations of the sounds that we are working with.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav&quot;</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;steam.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;rir.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;bg.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [(</span><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">),]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>\n<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>\n<span class="line"><span style="color: #C9D1D9">       effects.extend([</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">       ])</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">print_stats</span><span style="color: #C9D1D9">(waveform, sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, src</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> src:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Source: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">src</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> sample_rate:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Sample Rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Dtype:&quot;</span><span style="color: #C9D1D9">, waveform.dtype)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Max:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.max().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Min:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.min().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Mean:    </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.mean().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Std Dev: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.std().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_rir_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, processed</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir_raw, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> processed:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir_raw, sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir, sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_noise_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span></code></pre>\n<h2 id="using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</h2>\n<p>Now that we\u2019ve set everything up, let\u2019s take a look at how to use PyTorch\u2019s <code is:raw>torchaudio</code> library to add sound effects. We\u2019re going to pass a list of list of strings (<code is:raw>List[List[Str]])</code> object to the <code is:raw>sox_effects.apply_effects_tensor</code> function from <code is:raw>torchaudio</code>.</p>\n<p>Each of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the <a href="http://sox.sourceforge.net/sox.html">sox documentation</a>. Note: this function returns two return values, the waveform and the new sample rate.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># Load the data</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform1, sample_rate1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># Define effects</span></span>\n<span class="line"><span style="color: #C9D1D9">effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-1&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;300&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># apply single-pole lowpass filter</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;speed&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;0.8&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># reduce the speed</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># This only changes sample rate, so it is necessary to</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># add `rate` effect with original sample rate after this.</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate1</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;reverb&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-w&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># Reverbration gives some dramatic feeling</span></span>\n<span class="line"><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #8B949E"># Apply effects</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform2, sample_rate2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)</span></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(waveform1, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate1, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(waveform2, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate2, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span></code></pre>\n<p>The printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the \u201Cskinnier\u201D or quieter sections of the waveform.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png" alt="Waveform and Spectrogram of Original and Augmented Audio Data">\n<em>Above: Original Waveform and Spectrogram + Added Effects from TorchAudio</em></p>\n<h2 id="adding-background-noise">Adding Background Noise</h2>\n<p>Now that we know how to add effects to audio using <code is:raw>torchaudio</code>, let\u2019s dive into some more specific use cases. If your model needs to be able to detect audio even when there\u2019s background noise, it\u2019s a good idea to add some background noise to your training data.</p>\n<p>In the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we\u2019ll call our helper functions to get the speech and background noise and reshape the noise. After that, we\u2019ll use the <code is:raw>norm</code> function to normalize both the speech and the text to the <a href="https://pytorch.org/docs/stable/generated/torch.norm.html">second order</a>. Next, we\u2019ll define a list of decibels that we want to play the background noise at over the speech and create a \u201Cbackground noise\u201D version at each level.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>\n<span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_noise_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise[:, : speech.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">speech_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> speech.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_dbs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">20</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">noisy_speeches </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> snr_db </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> snr_dbs:</span></span>\n<span class="line"><span style="color: #C9D1D9">   snr </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.exp(snr_db </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   scale </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> noise_power </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> speech_power</span></span>\n<span class="line"><span style="color: #C9D1D9">   noisy_speeches.append((scale </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> speech </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> noise) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png" alt="Waveform and Spectrogram of Noise Audio Data created by TorchAudio"></p>\n<p>The above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB <code is:raw>snr</code> means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># background noise at certain levels</span></span>\n<span class="line"><span style="color: #C9D1D9">snr_db20, noisy_speech20 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_db10, noisy_speech10 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_db3, noisy_speech3 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png" alt="20 and 10 dB SNR added background audio data waveforms and spectrograms">\n<em>Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio</em></p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png" alt="PyTorch generated waveform and spectrogram for 3 dB SNR background noise">\n<em>Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise</em></p>\n<h2 id="adding-room-reverberation">Adding Room Reverberation</h2>\n<p>So far we\u2019ve applied audio effects and background noise at different noise levels. Let\u2019s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.</p>\n<p>To add a room reverb, we\u2019re going to start by making a request for the audio from where it lives online using one of the functions we made above (<code is:raw>get_rir_sample</code>). We\u2019ll take a look at the waveform before we clip it to get the \u201Creverb\u201D of the sound, normalize it, and then flip the sound so that the reverb works correctly.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rir_raw, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_rir_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(rir)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(rir, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png" alt="Reverb audio data waveform and spectrogram with PyTorch">\n<em>Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio</em></p>\n<p>Once we have the sound normalized and flipped, we\u2019re ready to use it to augment the existing audio. We will first use PyTorch to create a \u201Cpadding\u201D that uses the speech and the augmented sound. Then, we\u2019ll use PyTorch to apply the sound with a 1 dimensional convolution.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">speech_ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.pad(speech, (rir.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">augmented </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.conv1d(speech_[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">], rir[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">])[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">play_audio(speech, sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">play_audio(augmented, sample_rate)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png" alt="Waveform and spectrogram for original and reverb\u2019d sound with PyTorch TorchAudio">\n<em>Above: Visualizations for audio with reverb applied by TorchAudio</em></p>\n<p>From the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.</p>\n<h2 id="advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</h2>\n<p>We briefly mentioned how to resample data before using the <code is:raw>pydub</code> and the <code is:raw>sklearn</code> libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we\u2019ll cover how to resample data using low-pass, rolloff, and window filters.</p>\n<p>As we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is <code is:raw>get_sine_sweep</code> which is what we\u2019ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> IPython.display </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Audio, display</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">201</span></span>\n<span class="line"><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_LOWPASS_FILTER_WIDTH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_ROLLOFF</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.99</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_RESAMPLING_METHOD</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_log_freq</span><span style="color: #C9D1D9">(sample_rate, max_sweep_rate, offset):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #A5D6FF">   offset is used to avoid negative infinity `log(offset + x)`.</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #A5D6FF">   &quot;&quot;&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">   start, stop </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.log(offset), math.log(offset </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torch.exp(torch.linspace(start, stop, sample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">torch.double)) </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> offset</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_inverse_log_freq</span><span style="color: #C9D1D9">(freq, sample_rate, offset):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Find the time where the given frequency is given by _get_log_freq&quot;&quot;&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">   half </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> (math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> half </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset))</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_freq_ticks</span><span style="color: #C9D1D9">(sample_rate, offset, f_max):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Given the original sample rate used for generating the sweep,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># find the x-axis value where the log-scale major frequency values fall in</span></span>\n<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [], []</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> exp </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">           f </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">**</span><span style="color: #C9D1D9"> exp</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">               t </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">               time.append(t)</span></span>\n<span class="line"><span style="color: #C9D1D9">               freq.append(f)</span></span>\n<span class="line"><span style="color: #C9D1D9">   t_max </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f_max, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   time.append(t_max)</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq.append(f_max)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> time, freq</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sine_sweep</span><span style="color: #C9D1D9">(sample_rate, offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   max_sweep_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_log_freq(sample_rate, max_sweep_rate, offset)</span></span>\n<span class="line"><span style="color: #C9D1D9">   delta </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> math.pi </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   cummulative </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.cumsum(delta, </span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   signal </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.sin(cummulative).unsqueeze(</span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> signal</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_sweep</span><span style="color: #C9D1D9">(</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform,</span></span>\n<span class="line"><span style="color: #C9D1D9">   sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   title,</span></span>\n<span class="line"><span style="color: #C9D1D9">   max_sweep_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   x_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">   y_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_freq_ticks(max_sweep_rate, offset, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq_x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">else</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq]</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq_y </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> y_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.specgram(waveform[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].numpy(), </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.xticks(time, freq_x)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.yticks(freq_y, freq_y)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.set_xlabel(</span><span style="color: #A5D6FF">&quot;Original Signal Frequency (Hz, log scale)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.set_ylabel(</span><span style="color: #A5D6FF">&quot;Waveform Frequency (Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.xaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.yaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">title</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> (sample rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p>I put the two <code is:raw>torchaudio</code> imports here to clarify that these are the <code is:raw>T</code> and <code is:raw>F</code> letters we\u2019ll be using to pull functions from (as opposed to true and false!). We\u2019ll declare a sample rate and a resample rate, it doesn\u2019t really matter what these are, feel free to change these as it suits you.</p>\n<p>The first thing we\u2019ll do is create a waveform using the <code is:raw>get_sine_sweep</code> function. Then, we\u2019ll do a resampling without passing any parameters. Next, we\u2019ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we\u2019ll need the functional <code is:raw>torchaudio</code> package.</p>\n<p>Technically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio\u2019s default is 6 so our first and second resampling are the same. Larger values here result in \u201Csharper\u201D noise.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>\n<span class="line"><span style="color: #C9D1D9">resample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">32000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sine_sweep(sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;basic resampling&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">resampler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Resample(sample_rate, resample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">waveform.dtype)</span></span>\n<span class="line"><span style="color: #C9D1D9">resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> resampler(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Resampled Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;lowpass resampling&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">lp6_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">6</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=6&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">lp128_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">128</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=128&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png" alt="Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio">\n<em>Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio</em></p>\n<p>Filters are not the only thing we can use for resampling. In the example code below, we\u2019ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we\u2019ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;using a window to resample&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">hann_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Hann Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">kaiser_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;kaiser_window&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Kaiser Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;user rollof to determine window&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.99</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.99&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.8&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png" alt="Resampling Audio Data with Windows and Rolloff filters">\n<em>Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio</em></p>\n<h2 id="audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</h2>\n<p>So far we\u2019ve taken a look at how to use <code is:raw>torchaudio</code> in many ways to manipulate our audio data. Now let\u2019s take a look at how to do feature extraction with <code is:raw>torchaudio</code>. As we have in the two sections above, we\u2019ll start by setting up.</p>\n<p>Our setup functions will include functions to fetch the data as well as visualize it like the \u201Ceffects\u201D section above. We also add some functions for doing Mel scale buckets. We will use <a href="https://en.wikipedia.org/wiki/Mel_scale">Mel scale</a> buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> librosa</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">       (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">   ]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>\n<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>\n<span class="line"><span style="color: #C9D1D9">       effects.extend(</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span></span>\n<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">           ]</span></span>\n<span class="line"><span style="color: #C9D1D9">       )</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_spectrogram</span><span style="color: #C9D1D9">(spec, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;freq_bin&quot;</span><span style="color: #C9D1D9">, aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">, xmax</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Spectrogram (db)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(ylabel)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;frame&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   im </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> axs.imshow(librosa.power_to_db(spec), </span><span style="color: #FFA657">origin</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lower&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">aspect)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xmax:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axs.set_xlim((</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, xmax))</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig.colorbar(im, </span><span style="color: #FFA657">ax</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">axs)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_mel_fbank</span><span style="color: #C9D1D9">(fbank, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Filter bank&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.imshow(fbank, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(</span><span style="color: #A5D6FF">&quot;frequency bin&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;mel bin&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p>The first thing we\u2019re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.</p>\n<p>We\u2019ll define some constants before we create our spectrogram and reverse it. First, we want to define <code is:raw>n_fft</code>, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we\u2019ll call <code is:raw>torchaudio</code> to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we\u2019ll use the <code is:raw>GriffinLim</code> function from <code is:raw>torchaudio</code> with the same parameters we used above to turn the waveform into a spectrogram.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># plot spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">n_fft </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">win_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span></span>\n<span class="line"><span style="color: #C9D1D9">hop_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">512</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># create spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">torch.random.manual_seed(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">spec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Spectrogram(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">)(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(spec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;torchaudio spec&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># reverse spectrogram to waveform with griffinlim</span></span>\n<span class="line"><span style="color: #C9D1D9">griffin_lim </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.GriffinLim(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> griffin_lim(spec)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Reconstructed&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png" alt="Waveform to Spectrogram and back with PyTorch">\n<em>Above: Creating and reversing a spectrogram in PyTorch</em></p>\n<p>Let\u2019s take a look at one of the more interesting things we can do with spectral features, <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">mel-frequency cepstrum</a>. The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we\u2019ll define a number of mel filterbanks (256), and a new sample rate to play with.</p>\n<p>The first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we\u2019ll use that to get the mel spectrogram. Now, we\u2019re ready to get the coefficients. First we need to define how many coefficients we want, then we\u2019ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>\n<span class="line"><span style="color: #8B949E"># mel scale waveforms</span></span>\n<span class="line"><span style="color: #8B949E"># mel scale bins</span></span>\n<span class="line"><span style="color: #C9D1D9">n_mels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mel_filters </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.melscale_fbanks(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(n_fft </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_min</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_max</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_mel_fbank(mel_filters, </span><span style="color: #A5D6FF">&quot;Mel Filter Bank - torchaudio&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">mel_spectrogram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MelSpectrogram(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">center</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">pad_mode</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;reflect&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">power</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">onesided</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">mel_scale</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">melspec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mel_spectrogram(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(melspec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;MelSpectrogram - torchaudio&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mel freq&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">n_mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mfcc_transform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MFCC(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mfcc</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mfcc,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">melkwargs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">{</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_fft&quot;</span><span style="color: #C9D1D9">: n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_mels&quot;</span><span style="color: #C9D1D9">: n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;hop_length&quot;</span><span style="color: #C9D1D9">: hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;mel_scale&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   },</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mfcc_transform(waveform)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(mfcc[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">])</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png" alt="Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio">\n<em>Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio</em></p>\n<h2 id="in-summary">In Summary</h2>\n<p>In this epic post, we covered the basics of how to use the <code is:raw>torchaudio</code> library from PyTorch. We saw that we can use <code is:raw>torchaudio</code> to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.</p>\n<p>TorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio\u2019s <code is:raw>functional</code> and <code is:raw>transform</code> libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.</p>\n<p>Finally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.</p>' };
const frontmatter = { "title": "Introduction to PyTorch Audio Data via TorchAudio", "description": "Learn how to use TorchAudio to transform, augment, and extract features from audio data.", "date": "2022-06-27T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1656347792/blog/2022/06/pytorch-intro-with-torchaudio/Introduction-to-PyTorch-Audio-Data-via-TorchAudio%402x.jpg", "authors": ["yujian-tang"], "category": "tutorial", "tags": ["python", "pytorch", "torchaudio"], "seo": { "title": "Introduction to PyTorch Audio Data via TorchAudio", "description": "Learn how to use TorchAudio to transform, augment, and extract features from audio data." }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454102/blog/pytorch-intro-with-torchaudio/ograph.png" }, "shorturls": { "share": "https://dpgr.am/08d1281", "twitter": "https://dpgr.am/b0e6457", "linkedin": "https://dpgr.am/22478f3", "reddit": "https://dpgr.am/33e3a34", "facebook": "https://dpgr.am/7f0d64d" }, "astro": { "headings": [{ "depth": 2, "slug": "setting-up-pytorch-torchaudio-for-audio-data-augmentation", "text": "Setting up PyTorch TorchAudio for Audio Data Augmentation" }, { "depth": 2, "slug": "adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio", "text": "Adding Effects for Audio Data Augmentation with PyTorch TorchAudio" }, { "depth": 2, "slug": "using-sound-effects-in-torchaudio", "text": "Using Sound Effects in Torchaudio" }, { "depth": 2, "slug": "adding-background-noise", "text": "Adding Background Noise" }, { "depth": 2, "slug": "adding-room-reverberation", "text": "Adding Room Reverberation" }, { "depth": 2, "slug": "advanced-resampling-of-audio-data-with-torchaudio", "text": "Advanced Resampling of Audio Data with TorchAudio" }, { "depth": 2, "slug": "audio-feature-extraction-with-pytorch-torchaudio", "text": "Audio Feature Extraction with PyTorch TorchAudio" }, { "depth": 2, "slug": "in-summary", "text": "In Summary" }], "source": 'PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, [TorchAudio](https://github.com/pytorch/audio). TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.\n\nIn this post, we\'ll cover:\n\n* [Setting up PyTorch TorchAudio for Audio Data Augmentation](#setting-up-pytorch-torchaudio-for-audio-data-augmentation)\n* [Adding Effects for Audio Data Augmentation with PyTorch TorchAudio](#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio)\n* [Using Sound Effects in Torchaudio](#using-sound-effects-in-torchaudio)\n* [Adding Background Noise](#adding-background-noise)\n* [Adding Room Reverberation](#adding-room-reverberation)\n* [Advanced Resampling of Audio Data with TorchAudio](#advanced-resampling-of-audio-data-with-torchaudio)\n* [Audio Feature Extraction with PyTorch TorchAudio](#audio-feature-extraction-with-pytorch-torchaudio)\n* [In Summary](#in-summary)\n\n## Setting up PyTorch TorchAudio for Audio Data Augmentation\n\nAt the time of writing, `torchaudio` is on version `0.11.0` and only works with Python versions 3.6 to 3.9. For this example, we\u2019ll be using Python 3.9. We\u2019ll also need to install some libraries before we dive in. The first libraries we\u2019ll need are `torch` and `torchaudio` from PyTorch. We\u2019ll be using `matplotlib` to plot our visual representations, `requests` to get the data, and `librosa` to do some more visual manipulations for spectrograms.\n\nTo get started we\u2019ll pip install all of these into a new virtual environment. [To start a virtual environment](https://blog.deepgram.com/python-virtual-environments/) run `python3 -m venv <new environment name>`. Then run `pip install torch torchaudio matplotlib requests librosa` and let `pip` install all the libraries necessary for this tutorial.\n\n## Adding Effects for Audio Data Augmentation with PyTorch TorchAudio\n\nRecently, we covered the basics of [how to manipulate audio data in Python](https://blog.deepgram.com/best-python-audio-manipulation-tools/). In this section we\u2019re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we\u2019ll go into specifics about how to add background noise at different sound levels and how to add room reverb.\n\nBefore we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can [skip](#using-sound-effects-in-torchaudio). It would be good to understand this code if you\u2019d like to continue testing on the provided data.\n\nIn the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we\u2019ll store the audio at. Next, we fetch the data and define some helper functions.\n\nFor this example, we\u2019ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and `numpy` representations of the sounds that we are working with.\n\n```py\nimport math\nimport os\n\nimport matplotlib.pyplot as plt\nimport requests\nimport torchaudio\nimport torch\n\n_SAMPLE_DIR = "_assets"\nSAMPLE_WAV_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav"\nSAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, "steam.wav")\n\nSAMPLE_RIR_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav"  # noqa: E501\nSAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, "rir.wav")\n\nSAMPLE_WAV_SPEECH_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"  # noqa: E501\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, "speech.wav")\n\nSAMPLE_NOISE_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav"  # noqa: E501\nSAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, "bg.wav")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\ndef _fetch_data():\n   uri = [(SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n           (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n           (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n           (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),]\n   for url, path in uri:\n       with open(path, "wb") as file_:\n           file_.write(requests.get(url).content)\n\n_fetch_data()\n\ndef _get_sample(path, resample=None):\n   effects = [["remix","1"]]\n   if resample:\n       effects.extend([\n           ["lowpass", f"{resample // 2}"],\n           ["rate", f"{resample}"]\n       ])\n   return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\ndef get_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n\ndef get_speech_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\ndef plot_waveform(waveform, sample_rate, title="Waveform", xlim=None, ylim=None):\n   waveform = waveform.numpy()\n   num_channels, num_frames = waveform.shape\n   time_axis = torch.arange(0, num_frames) / sample_rate\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].plot(time_axis, waveform[c], linewidth=1)\n       axes[c].grid(True)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n       if ylim:\n           axes[c].set_ylim(ylim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\ndef print_stats(waveform, sample_rate=None, src=None):\n   if src:\n       print("-"*10)\n       print(f"Source: {src}")\n       print("-"*10)\n   if sample_rate:\n       print(f"Sample Rate: {sample_rate}")\n   print("Dtype:", waveform.dtype)\n   print(f" - Max:     {waveform.max().item():6.3f}")\n   print(f" - Min:     {waveform.min().item():6.3f}")\n   print(f" - Mean:    {waveform.mean().item():6.3f}")\n   print(f" - Std Dev: {waveform.std().item():6.3f}")\n   print()\n   print(waveform)\n   print()\n\ndef plot_specgram(waveform, sample_rate, title="Spectrogram", xlim=None):\n   waveform = waveform.numpy()\n   num_channels, num_frames = waveform.shape\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].specgram(waveform[c], Fs=sample_rate)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\ndef get_rir_sample(*, resample=None, processed=False):\n   rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n   if not processed:\n       return rir_raw, sample_rate\n   rir = rir_raw[:, int(sample_rate*1.01) : int(sample_rate * 1.3)]\n   rir = rir / torch.norm(rir, p=2)\n   rir = torch.flip(rir, [1])\n   return rir, sample_rate\n\ndef get_noise_sample(*, resample=None):\n   return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n```\n\n## Using Sound Effects in Torchaudio\n\nNow that we\u2019ve set everything up, let\u2019s take a look at how to use PyTorch\u2019s `torchaudio` library to add sound effects. We\u2019re going to pass a list of list of strings (`List[List[Str]])` object to the `sox_effects.apply_effects_tensor` function from `torchaudio`.\n\nEach of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the [sox documentation](http://sox.sourceforge.net/sox.html). Note: this function returns two return values, the waveform and the new sample rate.\n\n```py\n# Load the data\nwaveform1, sample_rate1 = get_sample(resample=16000)\n\n# Define effects\neffects = [\n   ["lowpass", "-1", "300"],  # apply single-pole lowpass filter\n   ["speed", "0.8"],  # reduce the speed\n   # This only changes sample rate, so it is necessary to\n   # add `rate` effect with original sample rate after this.\n   ["rate", f"{sample_rate1}"],\n   ["reverb", "-w"],  # Reverbration gives some dramatic feeling\n]\n# Apply effects\nwaveform2, sample_rate2 = torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)\nprint_stats(waveform1, sample_rate=sample_rate1, src="Original")\nprint_stats(waveform2, sample_rate=sample_rate2, src="Effects Applied")\nplot_waveform(waveform1, sample_rate1, title="Original", xlim=(-0.1, 3.2))\nplot_specgram(waveform1, sample_rate1, title="Original", xlim=(0, 3.04))\nplot_waveform(waveform2, sample_rate2, title="Effects Applied", xlim=(-0.1, 3.2))\nplot_specgram(waveform2, sample_rate2, title="Effects Applied", xlim=(0, 3.04))\n```\n\nThe printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the \u201Cskinnier\u201D or quieter sections of the waveform.\n\n![Waveform and Spectrogram of Original and Augmented Audio Data](https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png)\n*Above: Original Waveform and Spectrogram + Added Effects from TorchAudio*\n\n## Adding Background Noise\n\nNow that we know how to add effects to audio using `torchaudio`, let\u2019s dive into some more specific use cases. If your model needs to be able to detect audio even when there\u2019s background noise, it\u2019s a good idea to add some background noise to your training data.\n\nIn the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we\u2019ll call our helper functions to get the speech and background noise and reshape the noise. After that, we\u2019ll use the `norm` function to normalize both the speech and the text to the [second order](https://pytorch.org/docs/stable/generated/torch.norm.html). Next, we\u2019ll define a list of decibels that we want to play the background noise at over the speech and create a \u201Cbackground noise\u201D version at each level.\n\n```py\nsample_rate = 8000\nspeech, _ = get_speech_sample(resample=sample_rate)\nnoise, _ = get_noise_sample(resample=sample_rate)\nnoise = noise[:, : speech.shape[1]]\n\nspeech_power = speech.norm(p=2)\nnoise_power = noise.norm(p=2)\n\nsnr_dbs = [20, 10, 3]\nnoisy_speeches = []\nfor snr_db in snr_dbs:\n   snr = math.exp(snr_db / 10)\n   scale = snr * noise_power / speech_power\n   noisy_speeches.append((scale * speech + noise) / 2)\n\nplot_waveform(noise, sample_rate, title="Background noise")\nplot_specgram(noise, sample_rate, title="Background noise")\n```\n\n![Waveform and Spectrogram of Noise Audio Data created by TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png)\n\nThe above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB `snr` means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.\n\n```py\n# background noise at certain levels\nsnr_db20, noisy_speech20 = snr_dbs[0], noisy_speeches[0]\nplot_waveform(noisy_speech20, sample_rate, title=f"SNR: {snr_db20} [dB]")\nplot_specgram(noisy_speech20, sample_rate, title=f"SNR: {snr_db20} [dB]")\n\nsnr_db10, noisy_speech10 = snr_dbs[1], noisy_speeches[1]\nplot_waveform(noisy_speech10, sample_rate, title=f"SNR: {snr_db10} [dB]")\nplot_specgram(noisy_speech10, sample_rate, title=f"SNR: {snr_db10} [dB]")\n\nsnr_db3, noisy_speech3 = snr_dbs[2], noisy_speeches[2]\nplot_waveform(noisy_speech3, sample_rate, title=f"SNR: {snr_db3} [dB]")\nplot_specgram(noisy_speech3, sample_rate, title=f"SNR: {snr_db3} [dB]")\n```\n\n![20 and 10 dB SNR added background audio data waveforms and spectrograms](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png)\n*Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio*\n\n![PyTorch generated waveform and spectrogram for 3 dB SNR background noise](https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png)\n*Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise*\n\n## Adding Room Reverberation\n\nSo far we\u2019ve applied audio effects and background noise at different noise levels. Let\u2019s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.\n\nTo add a room reverb, we\u2019re going to start by making a request for the audio from where it lives online using one of the functions we made above (`get_rir_sample`). We\u2019ll take a look at the waveform before we clip it to get the \u201Creverb\u201D of the sound, normalize it, and then flip the sound so that the reverb works correctly.\n\n```py\nsample_rate = 8000\n\nrir_raw, _ = get_rir_sample(resample=sample_rate)\n\nplot_waveform(rir_raw, sample_rate, title="Room Impulse Response (raw)", ylim=None)\nplot_specgram(rir_raw, sample_rate, title="Room Impulse Response (raw)")\n\nrir = rir_raw[:, int(sample_rate * 1.01) : int(sample_rate * 1.3)]\nrir = rir / torch.norm(rir, p=2)\nrir = torch.flip(rir, [1])\n\nprint_stats(rir)\nplot_waveform(rir, sample_rate, title="Room Impulse Response", ylim=None)\nplot_specgram(rir_raw, sample_rate, title="Room Impulse Response (raw)")\n```\n\n![Reverb audio data waveform and spectrogram with PyTorch](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png)\n*Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio*\n\nOnce we have the sound normalized and flipped, we\u2019re ready to use it to augment the existing audio. We will first use PyTorch to create a \u201Cpadding\u201D that uses the speech and the augmented sound. Then, we\u2019ll use PyTorch to apply the sound with a 1 dimensional convolution.\n\n```py\nspeech, _ = get_speech_sample(resample=sample_rate)\n\nspeech_ = torch.nn.functional.pad(speech, (rir.shape[1] - 1, 0))\naugmented = torch.nn.functional.conv1d(speech_[None, ...], rir[None, ...])[0]\n\nplot_waveform(speech, sample_rate, title="Original", ylim=None)\nplot_specgram(speech, sample_rate, title="Original")\nplay_audio(speech, sample_rate)\n\nplot_waveform(augmented, sample_rate, title="RIR Applied", ylim=None)\nplot_specgram(augmented, sample_rate, title="RIR Applied")\nplay_audio(augmented, sample_rate)\n```\n\n![Waveform and spectrogram for original and reverb\u2019d sound with PyTorch TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png)\n*Above: Visualizations for audio with reverb applied by TorchAudio*\n\nFrom the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.\n\n## Advanced Resampling of Audio Data with TorchAudio\n\nWe briefly mentioned how to resample data before using the `pydub` and the `sklearn` libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we\u2019ll cover how to resample data using low-pass, rolloff, and window filters.\n\nAs we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is `get_sine_sweep` which is what we\u2019ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.\n\n```py\nimport math\nimport torch\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio, display\n\n\nDEFAULT_OFFSET = 201\nSWEEP_MAX_SAMPLE_RATE = 48000\nDEFAULT_LOWPASS_FILTER_WIDTH = 6\nDEFAULT_ROLLOFF = 0.99\nDEFAULT_RESAMPLING_METHOD = "sinc_interpolation"\n\ndef _get_log_freq(sample_rate, max_sweep_rate, offset):\n   """Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n\n   offset is used to avoid negative infinity `log(offset + x)`.\n\n   """\n   start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n   return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n\ndef _get_inverse_log_freq(freq, sample_rate, offset):\n   """Find the time where the given frequency is given by _get_log_freq"""\n   half = sample_rate // 2\n   return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n\n\ndef _get_freq_ticks(sample_rate, offset, f_max):\n   # Given the original sample rate used for generating the sweep,\n   # find the x-axis value where the log-scale major frequency values fall in\n   time, freq = [], []\n   for exp in range(2, 5):\n       for v in range(1, 10):\n           f = v * 10 ** exp\n           if f < sample_rate // 2:\n               t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n               time.append(t)\n               freq.append(f)\n   t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n   time.append(t_max)\n   freq.append(f_max)\n   return time, freq\n\ndef get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n   max_sweep_rate = sample_rate\n   freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n   delta = 2 * math.pi * freq / sample_rate\n   cummulative = torch.cumsum(delta, dim=0)\n   signal = torch.sin(cummulative).unsqueeze(dim=0)\n   return signal\n\ndef plot_sweep(\n   waveform,\n   sample_rate,\n   title,\n   max_sweep_rate=SWEEP_MAX_SAMPLE_RATE,\n   offset=DEFAULT_OFFSET,\n):\n   x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n   y_ticks = [1000, 5000, 10000, 20000, sample_rate // 2]\n\n   time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n   freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n   freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n\n   figure, axis = plt.subplots(1, 1)\n   axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n   plt.xticks(time, freq_x)\n   plt.yticks(freq_y, freq_y)\n   axis.set_xlabel("Original Signal Frequency (Hz, log scale)")\n   axis.set_ylabel("Waveform Frequency (Hz)")\n   axis.xaxis.grid(True, alpha=0.67)\n   axis.yaxis.grid(True, alpha=0.67)\n   figure.suptitle(f"{title} (sample rate: {sample_rate} Hz)")\n   plt.show(block=True)\n\ndef plot_specgram(waveform, sample_rate, title="Spectrogram", xlim=None):\n   waveform = waveform.numpy()\n\n   num_channels, num_frames = waveform.shape\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].specgram(waveform[c], Fs=sample_rate)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n   figure.suptitle(title)\n   plt.show(block=False)\n```\n\nI put the two `torchaudio` imports here to clarify that these are the `T` and `F` letters we\u2019ll be using to pull functions from (as opposed to true and false!). We\u2019ll declare a sample rate and a resample rate, it doesn\u2019t really matter what these are, feel free to change these as it suits you.\n\nThe first thing we\u2019ll do is create a waveform using the `get_sine_sweep` function. Then, we\u2019ll do a resampling without passing any parameters. Next, we\u2019ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we\u2019ll need the functional `torchaudio` package.\n\nTechnically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio\u2019s default is 6 so our first and second resampling are the same. Larger values here result in \u201Csharper\u201D noise.\n\n```py\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nsample_rate = 48000\nresample_rate = 32000\n\nwaveform = get_sine_sweep(sample_rate)\nplot_sweep(waveform, sample_rate, title="Original Waveform")\n\nprint("basic resampling")\nresampler = T.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\nresampled_waveform = resampler(waveform)\nplot_sweep(resampled_waveform, resample_rate, title="Resampled Waveform")\n\nprint("lowpass resampling")\nlp6_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=6)\nplot_sweep(resampled_waveform, resample_rate, title="lowpass_filter_width=6")\n\nlp128_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=128)\nplot_sweep(resampled_waveform, resample_rate, title="lowpass_filter_width=128")\n```\n\n![Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png)\n*Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio*\n\nFilters are not the only thing we can use for resampling. In the example code below, we\u2019ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we\u2019ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.\n\n```py\nprint("using a window to resample")\nhann_window_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, resampling_method="sinc_interpolation")\nplot_sweep(resampled_waveform, resample_rate, title="Hann Window Default")\n\nkaiser_window_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, resampling_method="kaiser_window")\nplot_sweep(resampled_waveform, resample_rate, title="Kaiser Window Default")\n\nprint("user rollof to determine window")\nrolloff_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, rolloff=0.99)\nplot_sweep(resampled_waveform, resample_rate, title="rolloff=0.99")\n\nrolloff_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, rolloff=0.8)\nplot_sweep(resampled_waveform, resample_rate, title="rolloff=0.8")\n```\n\n![Resampling Audio Data with Windows and Rolloff filters](https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png)\n*Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio*\n\n## Audio Feature Extraction with PyTorch TorchAudio\n\nSo far we\u2019ve taken a look at how to use `torchaudio` in many ways to manipulate our audio data. Now let\u2019s take a look at how to do feature extraction with `torchaudio`. As we have in the two sections above, we\u2019ll start by setting up.\n\nOur setup functions will include functions to fetch the data as well as visualize it like the \u201Ceffects\u201D section above. We also add some functions for doing Mel scale buckets. We will use [Mel scale](https://en.wikipedia.org/wiki/Mel_scale) buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.\n\n```py\nimport os\n\nimport torch\nimport torchaudio\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nimport librosa\nimport matplotlib.pyplot as plt\nimport requests\n\n\n_SAMPLE_DIR = "_assets"\n\nSAMPLE_WAV_SPEECH_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"  # noqa: E501\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, "speech.wav")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\n\ndef _fetch_data():\n   uri = [\n       (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n   ]\n   for url, path in uri:\n       with open(path, "wb") as file_:\n           file_.write(requests.get(url).content)\n\n\n_fetch_data()\n\n\ndef _get_sample(path, resample=None):\n   effects = [["remix", "1"]]\n   if resample:\n       effects.extend(\n           [\n               ["lowpass", f"{resample // 2}"],\n               ["rate", f"{resample}"],\n           ]\n       )\n   return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\n\ndef get_speech_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\n\ndef plot_spectrogram(spec, title=None, ylabel="freq_bin", aspect="auto", xmax=None):\n   fig, axs = plt.subplots(1, 1)\n   axs.set_title(title or "Spectrogram (db)")\n   axs.set_ylabel(ylabel)\n   axs.set_xlabel("frame")\n   im = axs.imshow(librosa.power_to_db(spec), origin="lower", aspect=aspect)\n   if xmax:\n       axs.set_xlim((0, xmax))\n   fig.colorbar(im, ax=axs)\n   plt.show(block=False)\n\n\ndef plot_waveform(waveform, sample_rate, title="Waveform", xlim=None, ylim=None):\n   waveform = waveform.numpy()\n\n   num_channels, num_frames = waveform.shape\n   time_axis = torch.arange(0, num_frames) / sample_rate\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].plot(time_axis, waveform[c], linewidth=1)\n       axes[c].grid(True)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n       if ylim:\n           axes[c].set_ylim(ylim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\n\ndef plot_mel_fbank(fbank, title=None):\n   fig, axs = plt.subplots(1, 1)\n   axs.set_title(title or "Filter bank")\n   axs.imshow(fbank, aspect="auto")\n   axs.set_ylabel("frequency bin")\n   axs.set_xlabel("mel bin")\n   plt.show(block=False)\n```\n\nThe first thing we\u2019re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.\n\nWe\u2019ll define some constants before we create our spectrogram and reverse it. First, we want to define `n_fft`, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we\u2019ll call `torchaudio` to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we\u2019ll use the `GriffinLim` function from `torchaudio` with the same parameters we used above to turn the waveform into a spectrogram.\n\n```py\n# plot spectrogram\nwaveform, sample_rate = get_speech_sample()\n\nn_fft = 1024\nwin_length = None\nhop_length = 512\n\n# create spectrogram\ntorch.random.manual_seed(0)\nplot_waveform(waveform, sample_rate, title="Original")\n\nspec = T.Spectrogram(\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n)(waveform)\nplot_spectrogram(spec[0], title="torchaudio spec")\n\n# reverse spectrogram to waveform with griffinlim\ngriffin_lim = T.GriffinLim(\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n)\nwaveform = griffin_lim(spec)\nplot_waveform(waveform, sample_rate, title="Reconstructed")\n```\n\n![Waveform to Spectrogram and back with PyTorch](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png)\n*Above: Creating and reversing a spectrogram in PyTorch*\n\nLet\u2019s take a look at one of the more interesting things we can do with spectral features, [mel-frequency cepstrum](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum). The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we\u2019ll define a number of mel filterbanks (256), and a new sample rate to play with.\n\nThe first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we\u2019ll use that to get the mel spectrogram. Now, we\u2019re ready to get the coefficients. First we need to define how many coefficients we want, then we\u2019ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.\n\n```py\n# mel spectrogram\n# mel scale waveforms\n# mel scale bins\nn_mels = 256\nsample_rate = 6000\n\nmel_filters = F.melscale_fbanks(\n   int(n_fft // 2 + 1),\n   n_mels=n_mels,\n   f_min=0.0,\n   f_max=sample_rate / 2.0,\n   sample_rate=sample_rate,\n   norm="slaney",\n)\nplot_mel_fbank(mel_filters, "Mel Filter Bank - torchaudio")\n\n# mel spectrogram\nmel_spectrogram = T.MelSpectrogram(\n   sample_rate=sample_rate,\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n   center=True,\n   pad_mode="reflect",\n   power=2.0,\n   norm="slaney",\n   onesided=True,\n   n_mels=n_mels,\n   mel_scale="htk",\n)\n\nmelspec = mel_spectrogram(waveform)\nplot_spectrogram(melspec[0], title="MelSpectrogram - torchaudio", ylabel="mel freq")\n\nn_mfcc = 256\n\nmfcc_transform = T.MFCC(\n   sample_rate=sample_rate,\n   n_mfcc=n_mfcc,\n   melkwargs={\n       "n_fft": n_fft,\n       "n_mels": n_mels,\n       "hop_length": hop_length,\n       "mel_scale": "htk",\n   },\n)\n\nmfcc = mfcc_transform(waveform)\n\nplot_spectrogram(mfcc[0])\n```\n\n![Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png)\n*Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio*\n\n## In Summary\n\nIn this epic post, we covered the basics of how to use the `torchaudio` library from PyTorch. We saw that we can use `torchaudio` to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.\n\nTorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio\u2019s `functional` and `transform` libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.\n\nFinally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.', "html": '<p>PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, <a href="https://github.com/pytorch/audio">TorchAudio</a>. TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.</p>\n<p>In this post, we\u2019ll cover:</p>\n<ul>\n<li><a href="#setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</a></li>\n<li><a href="#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</a></li>\n<li><a href="#using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</a></li>\n<li><a href="#adding-background-noise">Adding Background Noise</a></li>\n<li><a href="#adding-room-reverberation">Adding Room Reverberation</a></li>\n<li><a href="#advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</a></li>\n<li><a href="#audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</a></li>\n<li><a href="#in-summary">In Summary</a></li>\n</ul>\n<h2 id="setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</h2>\n<p>At the time of writing, <code is:raw>torchaudio</code> is on version <code is:raw>0.11.0</code> and only works with Python versions 3.6 to 3.9. For this example, we\u2019ll be using Python 3.9. We\u2019ll also need to install some libraries before we dive in. The first libraries we\u2019ll need are <code is:raw>torch</code> and <code is:raw>torchaudio</code> from PyTorch. We\u2019ll be using <code is:raw>matplotlib</code> to plot our visual representations, <code is:raw>requests</code> to get the data, and <code is:raw>librosa</code> to do some more visual manipulations for spectrograms.</p>\n<p>To get started we\u2019ll pip install all of these into a new virtual environment. <a href="https://blog.deepgram.com/python-virtual-environments/">To start a virtual environment</a> run <code is:raw>python3 -m venv &lt;new environment name&gt;</code>. Then run <code is:raw>pip install torch torchaudio matplotlib requests librosa</code> and let <code is:raw>pip</code> install all the libraries necessary for this tutorial.</p>\n<h2 id="adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</h2>\n<p>Recently, we covered the basics of <a href="https://blog.deepgram.com/best-python-audio-manipulation-tools/">how to manipulate audio data in Python</a>. In this section we\u2019re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we\u2019ll go into specifics about how to add background noise at different sound levels and how to add room reverb.</p>\n<p>Before we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can <a href="#using-sound-effects-in-torchaudio">skip</a>. It would be good to understand this code if you\u2019d like to continue testing on the provided data.</p>\n<p>In the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we\u2019ll store the audio at. Next, we fetch the data and define some helper functions.</p>\n<p>For this example, we\u2019ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and <code is:raw>numpy</code> representations of the sounds that we are working with.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav&quot;</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;steam.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;rir.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;bg.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [(</span><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">),]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>\n<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>\n<span class="line"><span style="color: #C9D1D9">       effects.extend([</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">       ])</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">print_stats</span><span style="color: #C9D1D9">(waveform, sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, src</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> src:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Source: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">src</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> sample_rate:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Sample Rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Dtype:&quot;</span><span style="color: #C9D1D9">, waveform.dtype)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Max:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.max().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Min:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.min().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Mean:    </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.mean().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Std Dev: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.std().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_rir_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, processed</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir_raw, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> processed:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir_raw, sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir, sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_noise_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span></code></pre>\n<h2 id="using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</h2>\n<p>Now that we\u2019ve set everything up, let\u2019s take a look at how to use PyTorch\u2019s <code is:raw>torchaudio</code> library to add sound effects. We\u2019re going to pass a list of list of strings (<code is:raw>List[List[Str]])</code> object to the <code is:raw>sox_effects.apply_effects_tensor</code> function from <code is:raw>torchaudio</code>.</p>\n<p>Each of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the <a href="http://sox.sourceforge.net/sox.html">sox documentation</a>. Note: this function returns two return values, the waveform and the new sample rate.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># Load the data</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform1, sample_rate1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># Define effects</span></span>\n<span class="line"><span style="color: #C9D1D9">effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-1&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;300&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># apply single-pole lowpass filter</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;speed&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;0.8&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># reduce the speed</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># This only changes sample rate, so it is necessary to</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># add `rate` effect with original sample rate after this.</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate1</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;reverb&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-w&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># Reverbration gives some dramatic feeling</span></span>\n<span class="line"><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #8B949E"># Apply effects</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform2, sample_rate2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)</span></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(waveform1, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate1, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(waveform2, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate2, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span></code></pre>\n<p>The printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the \u201Cskinnier\u201D or quieter sections of the waveform.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png" alt="Waveform and Spectrogram of Original and Augmented Audio Data">\n<em>Above: Original Waveform and Spectrogram + Added Effects from TorchAudio</em></p>\n<h2 id="adding-background-noise">Adding Background Noise</h2>\n<p>Now that we know how to add effects to audio using <code is:raw>torchaudio</code>, let\u2019s dive into some more specific use cases. If your model needs to be able to detect audio even when there\u2019s background noise, it\u2019s a good idea to add some background noise to your training data.</p>\n<p>In the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we\u2019ll call our helper functions to get the speech and background noise and reshape the noise. After that, we\u2019ll use the <code is:raw>norm</code> function to normalize both the speech and the text to the <a href="https://pytorch.org/docs/stable/generated/torch.norm.html">second order</a>. Next, we\u2019ll define a list of decibels that we want to play the background noise at over the speech and create a \u201Cbackground noise\u201D version at each level.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>\n<span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_noise_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise[:, : speech.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">speech_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> speech.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_dbs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">20</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">noisy_speeches </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> snr_db </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> snr_dbs:</span></span>\n<span class="line"><span style="color: #C9D1D9">   snr </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.exp(snr_db </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   scale </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> noise_power </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> speech_power</span></span>\n<span class="line"><span style="color: #C9D1D9">   noisy_speeches.append((scale </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> speech </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> noise) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png" alt="Waveform and Spectrogram of Noise Audio Data created by TorchAudio"></p>\n<p>The above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB <code is:raw>snr</code> means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># background noise at certain levels</span></span>\n<span class="line"><span style="color: #C9D1D9">snr_db20, noisy_speech20 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_db10, noisy_speech10 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_db3, noisy_speech3 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png" alt="20 and 10 dB SNR added background audio data waveforms and spectrograms">\n<em>Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio</em></p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png" alt="PyTorch generated waveform and spectrogram for 3 dB SNR background noise">\n<em>Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise</em></p>\n<h2 id="adding-room-reverberation">Adding Room Reverberation</h2>\n<p>So far we\u2019ve applied audio effects and background noise at different noise levels. Let\u2019s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.</p>\n<p>To add a room reverb, we\u2019re going to start by making a request for the audio from where it lives online using one of the functions we made above (<code is:raw>get_rir_sample</code>). We\u2019ll take a look at the waveform before we clip it to get the \u201Creverb\u201D of the sound, normalize it, and then flip the sound so that the reverb works correctly.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rir_raw, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_rir_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(rir)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(rir, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png" alt="Reverb audio data waveform and spectrogram with PyTorch">\n<em>Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio</em></p>\n<p>Once we have the sound normalized and flipped, we\u2019re ready to use it to augment the existing audio. We will first use PyTorch to create a \u201Cpadding\u201D that uses the speech and the augmented sound. Then, we\u2019ll use PyTorch to apply the sound with a 1 dimensional convolution.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">speech_ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.pad(speech, (rir.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">augmented </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.conv1d(speech_[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">], rir[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">])[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">play_audio(speech, sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">play_audio(augmented, sample_rate)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png" alt="Waveform and spectrogram for original and reverb\u2019d sound with PyTorch TorchAudio">\n<em>Above: Visualizations for audio with reverb applied by TorchAudio</em></p>\n<p>From the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.</p>\n<h2 id="advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</h2>\n<p>We briefly mentioned how to resample data before using the <code is:raw>pydub</code> and the <code is:raw>sklearn</code> libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we\u2019ll cover how to resample data using low-pass, rolloff, and window filters.</p>\n<p>As we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is <code is:raw>get_sine_sweep</code> which is what we\u2019ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> IPython.display </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Audio, display</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">201</span></span>\n<span class="line"><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_LOWPASS_FILTER_WIDTH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_ROLLOFF</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.99</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_RESAMPLING_METHOD</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_log_freq</span><span style="color: #C9D1D9">(sample_rate, max_sweep_rate, offset):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #A5D6FF">   offset is used to avoid negative infinity `log(offset + x)`.</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #A5D6FF">   &quot;&quot;&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">   start, stop </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.log(offset), math.log(offset </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torch.exp(torch.linspace(start, stop, sample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">torch.double)) </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> offset</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_inverse_log_freq</span><span style="color: #C9D1D9">(freq, sample_rate, offset):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Find the time where the given frequency is given by _get_log_freq&quot;&quot;&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">   half </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> (math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> half </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset))</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_freq_ticks</span><span style="color: #C9D1D9">(sample_rate, offset, f_max):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Given the original sample rate used for generating the sweep,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># find the x-axis value where the log-scale major frequency values fall in</span></span>\n<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [], []</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> exp </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">           f </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">**</span><span style="color: #C9D1D9"> exp</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">               t </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">               time.append(t)</span></span>\n<span class="line"><span style="color: #C9D1D9">               freq.append(f)</span></span>\n<span class="line"><span style="color: #C9D1D9">   t_max </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f_max, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   time.append(t_max)</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq.append(f_max)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> time, freq</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sine_sweep</span><span style="color: #C9D1D9">(sample_rate, offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   max_sweep_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_log_freq(sample_rate, max_sweep_rate, offset)</span></span>\n<span class="line"><span style="color: #C9D1D9">   delta </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> math.pi </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   cummulative </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.cumsum(delta, </span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   signal </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.sin(cummulative).unsqueeze(</span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> signal</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_sweep</span><span style="color: #C9D1D9">(</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform,</span></span>\n<span class="line"><span style="color: #C9D1D9">   sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   title,</span></span>\n<span class="line"><span style="color: #C9D1D9">   max_sweep_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   x_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">   y_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_freq_ticks(max_sweep_rate, offset, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq_x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">else</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq]</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq_y </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> y_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.specgram(waveform[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].numpy(), </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.xticks(time, freq_x)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.yticks(freq_y, freq_y)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.set_xlabel(</span><span style="color: #A5D6FF">&quot;Original Signal Frequency (Hz, log scale)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.set_ylabel(</span><span style="color: #A5D6FF">&quot;Waveform Frequency (Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.xaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.yaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">title</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> (sample rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p>I put the two <code is:raw>torchaudio</code> imports here to clarify that these are the <code is:raw>T</code> and <code is:raw>F</code> letters we\u2019ll be using to pull functions from (as opposed to true and false!). We\u2019ll declare a sample rate and a resample rate, it doesn\u2019t really matter what these are, feel free to change these as it suits you.</p>\n<p>The first thing we\u2019ll do is create a waveform using the <code is:raw>get_sine_sweep</code> function. Then, we\u2019ll do a resampling without passing any parameters. Next, we\u2019ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we\u2019ll need the functional <code is:raw>torchaudio</code> package.</p>\n<p>Technically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio\u2019s default is 6 so our first and second resampling are the same. Larger values here result in \u201Csharper\u201D noise.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>\n<span class="line"><span style="color: #C9D1D9">resample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">32000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sine_sweep(sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;basic resampling&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">resampler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Resample(sample_rate, resample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">waveform.dtype)</span></span>\n<span class="line"><span style="color: #C9D1D9">resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> resampler(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Resampled Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;lowpass resampling&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">lp6_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">6</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=6&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">lp128_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">128</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=128&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png" alt="Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio">\n<em>Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio</em></p>\n<p>Filters are not the only thing we can use for resampling. In the example code below, we\u2019ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we\u2019ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;using a window to resample&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">hann_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Hann Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">kaiser_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;kaiser_window&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Kaiser Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;user rollof to determine window&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.99</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.99&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.8&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png" alt="Resampling Audio Data with Windows and Rolloff filters">\n<em>Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio</em></p>\n<h2 id="audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</h2>\n<p>So far we\u2019ve taken a look at how to use <code is:raw>torchaudio</code> in many ways to manipulate our audio data. Now let\u2019s take a look at how to do feature extraction with <code is:raw>torchaudio</code>. As we have in the two sections above, we\u2019ll start by setting up.</p>\n<p>Our setup functions will include functions to fetch the data as well as visualize it like the \u201Ceffects\u201D section above. We also add some functions for doing Mel scale buckets. We will use <a href="https://en.wikipedia.org/wiki/Mel_scale">Mel scale</a> buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> librosa</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">       (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">   ]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>\n<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>\n<span class="line"><span style="color: #C9D1D9">       effects.extend(</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span></span>\n<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">           ]</span></span>\n<span class="line"><span style="color: #C9D1D9">       )</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_spectrogram</span><span style="color: #C9D1D9">(spec, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;freq_bin&quot;</span><span style="color: #C9D1D9">, aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">, xmax</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Spectrogram (db)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(ylabel)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;frame&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   im </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> axs.imshow(librosa.power_to_db(spec), </span><span style="color: #FFA657">origin</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lower&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">aspect)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xmax:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axs.set_xlim((</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, xmax))</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig.colorbar(im, </span><span style="color: #FFA657">ax</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">axs)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_mel_fbank</span><span style="color: #C9D1D9">(fbank, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Filter bank&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.imshow(fbank, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(</span><span style="color: #A5D6FF">&quot;frequency bin&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;mel bin&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p>The first thing we\u2019re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.</p>\n<p>We\u2019ll define some constants before we create our spectrogram and reverse it. First, we want to define <code is:raw>n_fft</code>, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we\u2019ll call <code is:raw>torchaudio</code> to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we\u2019ll use the <code is:raw>GriffinLim</code> function from <code is:raw>torchaudio</code> with the same parameters we used above to turn the waveform into a spectrogram.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># plot spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">n_fft </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">win_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span></span>\n<span class="line"><span style="color: #C9D1D9">hop_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">512</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># create spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">torch.random.manual_seed(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">spec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Spectrogram(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">)(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(spec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;torchaudio spec&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># reverse spectrogram to waveform with griffinlim</span></span>\n<span class="line"><span style="color: #C9D1D9">griffin_lim </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.GriffinLim(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> griffin_lim(spec)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Reconstructed&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png" alt="Waveform to Spectrogram and back with PyTorch">\n<em>Above: Creating and reversing a spectrogram in PyTorch</em></p>\n<p>Let\u2019s take a look at one of the more interesting things we can do with spectral features, <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">mel-frequency cepstrum</a>. The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we\u2019ll define a number of mel filterbanks (256), and a new sample rate to play with.</p>\n<p>The first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we\u2019ll use that to get the mel spectrogram. Now, we\u2019re ready to get the coefficients. First we need to define how many coefficients we want, then we\u2019ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>\n<span class="line"><span style="color: #8B949E"># mel scale waveforms</span></span>\n<span class="line"><span style="color: #8B949E"># mel scale bins</span></span>\n<span class="line"><span style="color: #C9D1D9">n_mels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mel_filters </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.melscale_fbanks(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(n_fft </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_min</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_max</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_mel_fbank(mel_filters, </span><span style="color: #A5D6FF">&quot;Mel Filter Bank - torchaudio&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">mel_spectrogram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MelSpectrogram(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">center</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">pad_mode</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;reflect&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">power</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">onesided</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">mel_scale</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">melspec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mel_spectrogram(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(melspec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;MelSpectrogram - torchaudio&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mel freq&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">n_mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mfcc_transform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MFCC(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mfcc</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mfcc,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">melkwargs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">{</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_fft&quot;</span><span style="color: #C9D1D9">: n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_mels&quot;</span><span style="color: #C9D1D9">: n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;hop_length&quot;</span><span style="color: #C9D1D9">: hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;mel_scale&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   },</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mfcc_transform(waveform)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(mfcc[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">])</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png" alt="Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio">\n<em>Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio</em></p>\n<h2 id="in-summary">In Summary</h2>\n<p>In this epic post, we covered the basics of how to use the <code is:raw>torchaudio</code> library from PyTorch. We saw that we can use <code is:raw>torchaudio</code> to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.</p>\n<p>TorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio\u2019s <code is:raw>functional</code> and <code is:raw>transform</code> libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.</p>\n<p>Finally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/pytorch-intro-with-torchaudio/index.md" };
function rawContent() {
  return 'PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, [TorchAudio](https://github.com/pytorch/audio). TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.\n\nIn this post, we\'ll cover:\n\n* [Setting up PyTorch TorchAudio for Audio Data Augmentation](#setting-up-pytorch-torchaudio-for-audio-data-augmentation)\n* [Adding Effects for Audio Data Augmentation with PyTorch TorchAudio](#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio)\n* [Using Sound Effects in Torchaudio](#using-sound-effects-in-torchaudio)\n* [Adding Background Noise](#adding-background-noise)\n* [Adding Room Reverberation](#adding-room-reverberation)\n* [Advanced Resampling of Audio Data with TorchAudio](#advanced-resampling-of-audio-data-with-torchaudio)\n* [Audio Feature Extraction with PyTorch TorchAudio](#audio-feature-extraction-with-pytorch-torchaudio)\n* [In Summary](#in-summary)\n\n## Setting up PyTorch TorchAudio for Audio Data Augmentation\n\nAt the time of writing, `torchaudio` is on version `0.11.0` and only works with Python versions 3.6 to 3.9. For this example, we\u2019ll be using Python 3.9. We\u2019ll also need to install some libraries before we dive in. The first libraries we\u2019ll need are `torch` and `torchaudio` from PyTorch. We\u2019ll be using `matplotlib` to plot our visual representations, `requests` to get the data, and `librosa` to do some more visual manipulations for spectrograms.\n\nTo get started we\u2019ll pip install all of these into a new virtual environment. [To start a virtual environment](https://blog.deepgram.com/python-virtual-environments/) run `python3 -m venv <new environment name>`. Then run `pip install torch torchaudio matplotlib requests librosa` and let `pip` install all the libraries necessary for this tutorial.\n\n## Adding Effects for Audio Data Augmentation with PyTorch TorchAudio\n\nRecently, we covered the basics of [how to manipulate audio data in Python](https://blog.deepgram.com/best-python-audio-manipulation-tools/). In this section we\u2019re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we\u2019ll go into specifics about how to add background noise at different sound levels and how to add room reverb.\n\nBefore we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can [skip](#using-sound-effects-in-torchaudio). It would be good to understand this code if you\u2019d like to continue testing on the provided data.\n\nIn the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we\u2019ll store the audio at. Next, we fetch the data and define some helper functions.\n\nFor this example, we\u2019ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and `numpy` representations of the sounds that we are working with.\n\n```py\nimport math\nimport os\n\nimport matplotlib.pyplot as plt\nimport requests\nimport torchaudio\nimport torch\n\n_SAMPLE_DIR = "_assets"\nSAMPLE_WAV_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav"\nSAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, "steam.wav")\n\nSAMPLE_RIR_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav"  # noqa: E501\nSAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, "rir.wav")\n\nSAMPLE_WAV_SPEECH_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"  # noqa: E501\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, "speech.wav")\n\nSAMPLE_NOISE_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav"  # noqa: E501\nSAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, "bg.wav")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\ndef _fetch_data():\n   uri = [(SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n           (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n           (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n           (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),]\n   for url, path in uri:\n       with open(path, "wb") as file_:\n           file_.write(requests.get(url).content)\n\n_fetch_data()\n\ndef _get_sample(path, resample=None):\n   effects = [["remix","1"]]\n   if resample:\n       effects.extend([\n           ["lowpass", f"{resample // 2}"],\n           ["rate", f"{resample}"]\n       ])\n   return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\ndef get_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n\ndef get_speech_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\ndef plot_waveform(waveform, sample_rate, title="Waveform", xlim=None, ylim=None):\n   waveform = waveform.numpy()\n   num_channels, num_frames = waveform.shape\n   time_axis = torch.arange(0, num_frames) / sample_rate\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].plot(time_axis, waveform[c], linewidth=1)\n       axes[c].grid(True)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n       if ylim:\n           axes[c].set_ylim(ylim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\ndef print_stats(waveform, sample_rate=None, src=None):\n   if src:\n       print("-"*10)\n       print(f"Source: {src}")\n       print("-"*10)\n   if sample_rate:\n       print(f"Sample Rate: {sample_rate}")\n   print("Dtype:", waveform.dtype)\n   print(f" - Max:     {waveform.max().item():6.3f}")\n   print(f" - Min:     {waveform.min().item():6.3f}")\n   print(f" - Mean:    {waveform.mean().item():6.3f}")\n   print(f" - Std Dev: {waveform.std().item():6.3f}")\n   print()\n   print(waveform)\n   print()\n\ndef plot_specgram(waveform, sample_rate, title="Spectrogram", xlim=None):\n   waveform = waveform.numpy()\n   num_channels, num_frames = waveform.shape\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].specgram(waveform[c], Fs=sample_rate)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\ndef get_rir_sample(*, resample=None, processed=False):\n   rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n   if not processed:\n       return rir_raw, sample_rate\n   rir = rir_raw[:, int(sample_rate*1.01) : int(sample_rate * 1.3)]\n   rir = rir / torch.norm(rir, p=2)\n   rir = torch.flip(rir, [1])\n   return rir, sample_rate\n\ndef get_noise_sample(*, resample=None):\n   return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n```\n\n## Using Sound Effects in Torchaudio\n\nNow that we\u2019ve set everything up, let\u2019s take a look at how to use PyTorch\u2019s `torchaudio` library to add sound effects. We\u2019re going to pass a list of list of strings (`List[List[Str]])` object to the `sox_effects.apply_effects_tensor` function from `torchaudio`.\n\nEach of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the [sox documentation](http://sox.sourceforge.net/sox.html). Note: this function returns two return values, the waveform and the new sample rate.\n\n```py\n# Load the data\nwaveform1, sample_rate1 = get_sample(resample=16000)\n\n# Define effects\neffects = [\n   ["lowpass", "-1", "300"],  # apply single-pole lowpass filter\n   ["speed", "0.8"],  # reduce the speed\n   # This only changes sample rate, so it is necessary to\n   # add `rate` effect with original sample rate after this.\n   ["rate", f"{sample_rate1}"],\n   ["reverb", "-w"],  # Reverbration gives some dramatic feeling\n]\n# Apply effects\nwaveform2, sample_rate2 = torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)\nprint_stats(waveform1, sample_rate=sample_rate1, src="Original")\nprint_stats(waveform2, sample_rate=sample_rate2, src="Effects Applied")\nplot_waveform(waveform1, sample_rate1, title="Original", xlim=(-0.1, 3.2))\nplot_specgram(waveform1, sample_rate1, title="Original", xlim=(0, 3.04))\nplot_waveform(waveform2, sample_rate2, title="Effects Applied", xlim=(-0.1, 3.2))\nplot_specgram(waveform2, sample_rate2, title="Effects Applied", xlim=(0, 3.04))\n```\n\nThe printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the \u201Cskinnier\u201D or quieter sections of the waveform.\n\n![Waveform and Spectrogram of Original and Augmented Audio Data](https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png)\n*Above: Original Waveform and Spectrogram + Added Effects from TorchAudio*\n\n## Adding Background Noise\n\nNow that we know how to add effects to audio using `torchaudio`, let\u2019s dive into some more specific use cases. If your model needs to be able to detect audio even when there\u2019s background noise, it\u2019s a good idea to add some background noise to your training data.\n\nIn the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we\u2019ll call our helper functions to get the speech and background noise and reshape the noise. After that, we\u2019ll use the `norm` function to normalize both the speech and the text to the [second order](https://pytorch.org/docs/stable/generated/torch.norm.html). Next, we\u2019ll define a list of decibels that we want to play the background noise at over the speech and create a \u201Cbackground noise\u201D version at each level.\n\n```py\nsample_rate = 8000\nspeech, _ = get_speech_sample(resample=sample_rate)\nnoise, _ = get_noise_sample(resample=sample_rate)\nnoise = noise[:, : speech.shape[1]]\n\nspeech_power = speech.norm(p=2)\nnoise_power = noise.norm(p=2)\n\nsnr_dbs = [20, 10, 3]\nnoisy_speeches = []\nfor snr_db in snr_dbs:\n   snr = math.exp(snr_db / 10)\n   scale = snr * noise_power / speech_power\n   noisy_speeches.append((scale * speech + noise) / 2)\n\nplot_waveform(noise, sample_rate, title="Background noise")\nplot_specgram(noise, sample_rate, title="Background noise")\n```\n\n![Waveform and Spectrogram of Noise Audio Data created by TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png)\n\nThe above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB `snr` means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.\n\n```py\n# background noise at certain levels\nsnr_db20, noisy_speech20 = snr_dbs[0], noisy_speeches[0]\nplot_waveform(noisy_speech20, sample_rate, title=f"SNR: {snr_db20} [dB]")\nplot_specgram(noisy_speech20, sample_rate, title=f"SNR: {snr_db20} [dB]")\n\nsnr_db10, noisy_speech10 = snr_dbs[1], noisy_speeches[1]\nplot_waveform(noisy_speech10, sample_rate, title=f"SNR: {snr_db10} [dB]")\nplot_specgram(noisy_speech10, sample_rate, title=f"SNR: {snr_db10} [dB]")\n\nsnr_db3, noisy_speech3 = snr_dbs[2], noisy_speeches[2]\nplot_waveform(noisy_speech3, sample_rate, title=f"SNR: {snr_db3} [dB]")\nplot_specgram(noisy_speech3, sample_rate, title=f"SNR: {snr_db3} [dB]")\n```\n\n![20 and 10 dB SNR added background audio data waveforms and spectrograms](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png)\n*Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio*\n\n![PyTorch generated waveform and spectrogram for 3 dB SNR background noise](https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png)\n*Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise*\n\n## Adding Room Reverberation\n\nSo far we\u2019ve applied audio effects and background noise at different noise levels. Let\u2019s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.\n\nTo add a room reverb, we\u2019re going to start by making a request for the audio from where it lives online using one of the functions we made above (`get_rir_sample`). We\u2019ll take a look at the waveform before we clip it to get the \u201Creverb\u201D of the sound, normalize it, and then flip the sound so that the reverb works correctly.\n\n```py\nsample_rate = 8000\n\nrir_raw, _ = get_rir_sample(resample=sample_rate)\n\nplot_waveform(rir_raw, sample_rate, title="Room Impulse Response (raw)", ylim=None)\nplot_specgram(rir_raw, sample_rate, title="Room Impulse Response (raw)")\n\nrir = rir_raw[:, int(sample_rate * 1.01) : int(sample_rate * 1.3)]\nrir = rir / torch.norm(rir, p=2)\nrir = torch.flip(rir, [1])\n\nprint_stats(rir)\nplot_waveform(rir, sample_rate, title="Room Impulse Response", ylim=None)\nplot_specgram(rir_raw, sample_rate, title="Room Impulse Response (raw)")\n```\n\n![Reverb audio data waveform and spectrogram with PyTorch](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png)\n*Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio*\n\nOnce we have the sound normalized and flipped, we\u2019re ready to use it to augment the existing audio. We will first use PyTorch to create a \u201Cpadding\u201D that uses the speech and the augmented sound. Then, we\u2019ll use PyTorch to apply the sound with a 1 dimensional convolution.\n\n```py\nspeech, _ = get_speech_sample(resample=sample_rate)\n\nspeech_ = torch.nn.functional.pad(speech, (rir.shape[1] - 1, 0))\naugmented = torch.nn.functional.conv1d(speech_[None, ...], rir[None, ...])[0]\n\nplot_waveform(speech, sample_rate, title="Original", ylim=None)\nplot_specgram(speech, sample_rate, title="Original")\nplay_audio(speech, sample_rate)\n\nplot_waveform(augmented, sample_rate, title="RIR Applied", ylim=None)\nplot_specgram(augmented, sample_rate, title="RIR Applied")\nplay_audio(augmented, sample_rate)\n```\n\n![Waveform and spectrogram for original and reverb\u2019d sound with PyTorch TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png)\n*Above: Visualizations for audio with reverb applied by TorchAudio*\n\nFrom the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.\n\n## Advanced Resampling of Audio Data with TorchAudio\n\nWe briefly mentioned how to resample data before using the `pydub` and the `sklearn` libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we\u2019ll cover how to resample data using low-pass, rolloff, and window filters.\n\nAs we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is `get_sine_sweep` which is what we\u2019ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.\n\n```py\nimport math\nimport torch\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio, display\n\n\nDEFAULT_OFFSET = 201\nSWEEP_MAX_SAMPLE_RATE = 48000\nDEFAULT_LOWPASS_FILTER_WIDTH = 6\nDEFAULT_ROLLOFF = 0.99\nDEFAULT_RESAMPLING_METHOD = "sinc_interpolation"\n\ndef _get_log_freq(sample_rate, max_sweep_rate, offset):\n   """Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n\n   offset is used to avoid negative infinity `log(offset + x)`.\n\n   """\n   start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n   return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n\ndef _get_inverse_log_freq(freq, sample_rate, offset):\n   """Find the time where the given frequency is given by _get_log_freq"""\n   half = sample_rate // 2\n   return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n\n\ndef _get_freq_ticks(sample_rate, offset, f_max):\n   # Given the original sample rate used for generating the sweep,\n   # find the x-axis value where the log-scale major frequency values fall in\n   time, freq = [], []\n   for exp in range(2, 5):\n       for v in range(1, 10):\n           f = v * 10 ** exp\n           if f < sample_rate // 2:\n               t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n               time.append(t)\n               freq.append(f)\n   t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n   time.append(t_max)\n   freq.append(f_max)\n   return time, freq\n\ndef get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n   max_sweep_rate = sample_rate\n   freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n   delta = 2 * math.pi * freq / sample_rate\n   cummulative = torch.cumsum(delta, dim=0)\n   signal = torch.sin(cummulative).unsqueeze(dim=0)\n   return signal\n\ndef plot_sweep(\n   waveform,\n   sample_rate,\n   title,\n   max_sweep_rate=SWEEP_MAX_SAMPLE_RATE,\n   offset=DEFAULT_OFFSET,\n):\n   x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n   y_ticks = [1000, 5000, 10000, 20000, sample_rate // 2]\n\n   time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n   freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n   freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n\n   figure, axis = plt.subplots(1, 1)\n   axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n   plt.xticks(time, freq_x)\n   plt.yticks(freq_y, freq_y)\n   axis.set_xlabel("Original Signal Frequency (Hz, log scale)")\n   axis.set_ylabel("Waveform Frequency (Hz)")\n   axis.xaxis.grid(True, alpha=0.67)\n   axis.yaxis.grid(True, alpha=0.67)\n   figure.suptitle(f"{title} (sample rate: {sample_rate} Hz)")\n   plt.show(block=True)\n\ndef plot_specgram(waveform, sample_rate, title="Spectrogram", xlim=None):\n   waveform = waveform.numpy()\n\n   num_channels, num_frames = waveform.shape\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].specgram(waveform[c], Fs=sample_rate)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n   figure.suptitle(title)\n   plt.show(block=False)\n```\n\nI put the two `torchaudio` imports here to clarify that these are the `T` and `F` letters we\u2019ll be using to pull functions from (as opposed to true and false!). We\u2019ll declare a sample rate and a resample rate, it doesn\u2019t really matter what these are, feel free to change these as it suits you.\n\nThe first thing we\u2019ll do is create a waveform using the `get_sine_sweep` function. Then, we\u2019ll do a resampling without passing any parameters. Next, we\u2019ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we\u2019ll need the functional `torchaudio` package.\n\nTechnically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio\u2019s default is 6 so our first and second resampling are the same. Larger values here result in \u201Csharper\u201D noise.\n\n```py\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nsample_rate = 48000\nresample_rate = 32000\n\nwaveform = get_sine_sweep(sample_rate)\nplot_sweep(waveform, sample_rate, title="Original Waveform")\n\nprint("basic resampling")\nresampler = T.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\nresampled_waveform = resampler(waveform)\nplot_sweep(resampled_waveform, resample_rate, title="Resampled Waveform")\n\nprint("lowpass resampling")\nlp6_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=6)\nplot_sweep(resampled_waveform, resample_rate, title="lowpass_filter_width=6")\n\nlp128_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=128)\nplot_sweep(resampled_waveform, resample_rate, title="lowpass_filter_width=128")\n```\n\n![Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png)\n*Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio*\n\nFilters are not the only thing we can use for resampling. In the example code below, we\u2019ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we\u2019ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.\n\n```py\nprint("using a window to resample")\nhann_window_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, resampling_method="sinc_interpolation")\nplot_sweep(resampled_waveform, resample_rate, title="Hann Window Default")\n\nkaiser_window_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, resampling_method="kaiser_window")\nplot_sweep(resampled_waveform, resample_rate, title="Kaiser Window Default")\n\nprint("user rollof to determine window")\nrolloff_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, rolloff=0.99)\nplot_sweep(resampled_waveform, resample_rate, title="rolloff=0.99")\n\nrolloff_resampled_waveform = F.resample(waveform, sample_rate, resample_rate, rolloff=0.8)\nplot_sweep(resampled_waveform, resample_rate, title="rolloff=0.8")\n```\n\n![Resampling Audio Data with Windows and Rolloff filters](https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png)\n*Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio*\n\n## Audio Feature Extraction with PyTorch TorchAudio\n\nSo far we\u2019ve taken a look at how to use `torchaudio` in many ways to manipulate our audio data. Now let\u2019s take a look at how to do feature extraction with `torchaudio`. As we have in the two sections above, we\u2019ll start by setting up.\n\nOur setup functions will include functions to fetch the data as well as visualize it like the \u201Ceffects\u201D section above. We also add some functions for doing Mel scale buckets. We will use [Mel scale](https://en.wikipedia.org/wiki/Mel_scale) buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.\n\n```py\nimport os\n\nimport torch\nimport torchaudio\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nimport librosa\nimport matplotlib.pyplot as plt\nimport requests\n\n\n_SAMPLE_DIR = "_assets"\n\nSAMPLE_WAV_SPEECH_URL = "https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"  # noqa: E501\nSAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, "speech.wav")\n\nos.makedirs(_SAMPLE_DIR, exist_ok=True)\n\n\ndef _fetch_data():\n   uri = [\n       (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n   ]\n   for url, path in uri:\n       with open(path, "wb") as file_:\n           file_.write(requests.get(url).content)\n\n\n_fetch_data()\n\n\ndef _get_sample(path, resample=None):\n   effects = [["remix", "1"]]\n   if resample:\n       effects.extend(\n           [\n               ["lowpass", f"{resample // 2}"],\n               ["rate", f"{resample}"],\n           ]\n       )\n   return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n\n\ndef get_speech_sample(*, resample=None):\n   return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n\n\ndef plot_spectrogram(spec, title=None, ylabel="freq_bin", aspect="auto", xmax=None):\n   fig, axs = plt.subplots(1, 1)\n   axs.set_title(title or "Spectrogram (db)")\n   axs.set_ylabel(ylabel)\n   axs.set_xlabel("frame")\n   im = axs.imshow(librosa.power_to_db(spec), origin="lower", aspect=aspect)\n   if xmax:\n       axs.set_xlim((0, xmax))\n   fig.colorbar(im, ax=axs)\n   plt.show(block=False)\n\n\ndef plot_waveform(waveform, sample_rate, title="Waveform", xlim=None, ylim=None):\n   waveform = waveform.numpy()\n\n   num_channels, num_frames = waveform.shape\n   time_axis = torch.arange(0, num_frames) / sample_rate\n\n   figure, axes = plt.subplots(num_channels, 1)\n   if num_channels == 1:\n       axes = [axes]\n   for c in range(num_channels):\n       axes[c].plot(time_axis, waveform[c], linewidth=1)\n       axes[c].grid(True)\n       if num_channels > 1:\n           axes[c].set_ylabel(f"Channel {c+1}")\n       if xlim:\n           axes[c].set_xlim(xlim)\n       if ylim:\n           axes[c].set_ylim(ylim)\n   figure.suptitle(title)\n   plt.show(block=False)\n\n\ndef plot_mel_fbank(fbank, title=None):\n   fig, axs = plt.subplots(1, 1)\n   axs.set_title(title or "Filter bank")\n   axs.imshow(fbank, aspect="auto")\n   axs.set_ylabel("frequency bin")\n   axs.set_xlabel("mel bin")\n   plt.show(block=False)\n```\n\nThe first thing we\u2019re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.\n\nWe\u2019ll define some constants before we create our spectrogram and reverse it. First, we want to define `n_fft`, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we\u2019ll call `torchaudio` to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we\u2019ll use the `GriffinLim` function from `torchaudio` with the same parameters we used above to turn the waveform into a spectrogram.\n\n```py\n# plot spectrogram\nwaveform, sample_rate = get_speech_sample()\n\nn_fft = 1024\nwin_length = None\nhop_length = 512\n\n# create spectrogram\ntorch.random.manual_seed(0)\nplot_waveform(waveform, sample_rate, title="Original")\n\nspec = T.Spectrogram(\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n)(waveform)\nplot_spectrogram(spec[0], title="torchaudio spec")\n\n# reverse spectrogram to waveform with griffinlim\ngriffin_lim = T.GriffinLim(\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n)\nwaveform = griffin_lim(spec)\nplot_waveform(waveform, sample_rate, title="Reconstructed")\n```\n\n![Waveform to Spectrogram and back with PyTorch](https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png)\n*Above: Creating and reversing a spectrogram in PyTorch*\n\nLet\u2019s take a look at one of the more interesting things we can do with spectral features, [mel-frequency cepstrum](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum). The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we\u2019ll define a number of mel filterbanks (256), and a new sample rate to play with.\n\nThe first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we\u2019ll use that to get the mel spectrogram. Now, we\u2019re ready to get the coefficients. First we need to define how many coefficients we want, then we\u2019ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.\n\n```py\n# mel spectrogram\n# mel scale waveforms\n# mel scale bins\nn_mels = 256\nsample_rate = 6000\n\nmel_filters = F.melscale_fbanks(\n   int(n_fft // 2 + 1),\n   n_mels=n_mels,\n   f_min=0.0,\n   f_max=sample_rate / 2.0,\n   sample_rate=sample_rate,\n   norm="slaney",\n)\nplot_mel_fbank(mel_filters, "Mel Filter Bank - torchaudio")\n\n# mel spectrogram\nmel_spectrogram = T.MelSpectrogram(\n   sample_rate=sample_rate,\n   n_fft=n_fft,\n   win_length=win_length,\n   hop_length=hop_length,\n   center=True,\n   pad_mode="reflect",\n   power=2.0,\n   norm="slaney",\n   onesided=True,\n   n_mels=n_mels,\n   mel_scale="htk",\n)\n\nmelspec = mel_spectrogram(waveform)\nplot_spectrogram(melspec[0], title="MelSpectrogram - torchaudio", ylabel="mel freq")\n\nn_mfcc = 256\n\nmfcc_transform = T.MFCC(\n   sample_rate=sample_rate,\n   n_mfcc=n_mfcc,\n   melkwargs={\n       "n_fft": n_fft,\n       "n_mels": n_mels,\n       "hop_length": hop_length,\n       "mel_scale": "htk",\n   },\n)\n\nmfcc = mfcc_transform(waveform)\n\nplot_spectrogram(mfcc[0])\n```\n\n![Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio](https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png)\n*Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio*\n\n## In Summary\n\nIn this epic post, we covered the basics of how to use the `torchaudio` library from PyTorch. We saw that we can use `torchaudio` to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.\n\nTorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio\u2019s `functional` and `transform` libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.\n\nFinally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.';
}
function compiledContent() {
  return '<p>PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, <a href="https://github.com/pytorch/audio">TorchAudio</a>. TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.</p>\n<p>In this post, we\u2019ll cover:</p>\n<ul>\n<li><a href="#setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</a></li>\n<li><a href="#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</a></li>\n<li><a href="#using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</a></li>\n<li><a href="#adding-background-noise">Adding Background Noise</a></li>\n<li><a href="#adding-room-reverberation">Adding Room Reverberation</a></li>\n<li><a href="#advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</a></li>\n<li><a href="#audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</a></li>\n<li><a href="#in-summary">In Summary</a></li>\n</ul>\n<h2 id="setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</h2>\n<p>At the time of writing, <code is:raw>torchaudio</code> is on version <code is:raw>0.11.0</code> and only works with Python versions 3.6 to 3.9. For this example, we\u2019ll be using Python 3.9. We\u2019ll also need to install some libraries before we dive in. The first libraries we\u2019ll need are <code is:raw>torch</code> and <code is:raw>torchaudio</code> from PyTorch. We\u2019ll be using <code is:raw>matplotlib</code> to plot our visual representations, <code is:raw>requests</code> to get the data, and <code is:raw>librosa</code> to do some more visual manipulations for spectrograms.</p>\n<p>To get started we\u2019ll pip install all of these into a new virtual environment. <a href="https://blog.deepgram.com/python-virtual-environments/">To start a virtual environment</a> run <code is:raw>python3 -m venv &lt;new environment name&gt;</code>. Then run <code is:raw>pip install torch torchaudio matplotlib requests librosa</code> and let <code is:raw>pip</code> install all the libraries necessary for this tutorial.</p>\n<h2 id="adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</h2>\n<p>Recently, we covered the basics of <a href="https://blog.deepgram.com/best-python-audio-manipulation-tools/">how to manipulate audio data in Python</a>. In this section we\u2019re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we\u2019ll go into specifics about how to add background noise at different sound levels and how to add room reverb.</p>\n<p>Before we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can <a href="#using-sound-effects-in-torchaudio">skip</a>. It would be good to understand this code if you\u2019d like to continue testing on the provided data.</p>\n<p>In the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we\u2019ll store the audio at. Next, we fetch the data and define some helper functions.</p>\n<p>For this example, we\u2019ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and <code is:raw>numpy</code> representations of the sounds that we are working with.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav&quot;</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;steam.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;rir.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;bg.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [(</span><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">),]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>\n<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>\n<span class="line"><span style="color: #C9D1D9">       effects.extend([</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">       ])</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">print_stats</span><span style="color: #C9D1D9">(waveform, sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, src</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> src:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Source: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">src</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> sample_rate:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Sample Rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Dtype:&quot;</span><span style="color: #C9D1D9">, waveform.dtype)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Max:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.max().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Min:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.min().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Mean:    </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.mean().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Std Dev: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.std().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_rir_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, processed</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir_raw, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> processed:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir_raw, sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir, sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_noise_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span></code></pre>\n<h2 id="using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</h2>\n<p>Now that we\u2019ve set everything up, let\u2019s take a look at how to use PyTorch\u2019s <code is:raw>torchaudio</code> library to add sound effects. We\u2019re going to pass a list of list of strings (<code is:raw>List[List[Str]])</code> object to the <code is:raw>sox_effects.apply_effects_tensor</code> function from <code is:raw>torchaudio</code>.</p>\n<p>Each of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the <a href="http://sox.sourceforge.net/sox.html">sox documentation</a>. Note: this function returns two return values, the waveform and the new sample rate.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># Load the data</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform1, sample_rate1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># Define effects</span></span>\n<span class="line"><span style="color: #C9D1D9">effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-1&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;300&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># apply single-pole lowpass filter</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;speed&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;0.8&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># reduce the speed</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># This only changes sample rate, so it is necessary to</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># add `rate` effect with original sample rate after this.</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate1</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;reverb&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-w&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># Reverbration gives some dramatic feeling</span></span>\n<span class="line"><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #8B949E"># Apply effects</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform2, sample_rate2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)</span></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(waveform1, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate1, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(waveform2, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate2, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span></code></pre>\n<p>The printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the \u201Cskinnier\u201D or quieter sections of the waveform.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png" alt="Waveform and Spectrogram of Original and Augmented Audio Data">\n<em>Above: Original Waveform and Spectrogram + Added Effects from TorchAudio</em></p>\n<h2 id="adding-background-noise">Adding Background Noise</h2>\n<p>Now that we know how to add effects to audio using <code is:raw>torchaudio</code>, let\u2019s dive into some more specific use cases. If your model needs to be able to detect audio even when there\u2019s background noise, it\u2019s a good idea to add some background noise to your training data.</p>\n<p>In the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we\u2019ll call our helper functions to get the speech and background noise and reshape the noise. After that, we\u2019ll use the <code is:raw>norm</code> function to normalize both the speech and the text to the <a href="https://pytorch.org/docs/stable/generated/torch.norm.html">second order</a>. Next, we\u2019ll define a list of decibels that we want to play the background noise at over the speech and create a \u201Cbackground noise\u201D version at each level.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>\n<span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_noise_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise[:, : speech.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">speech_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> speech.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">noise_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_dbs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">20</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">noisy_speeches </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> snr_db </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> snr_dbs:</span></span>\n<span class="line"><span style="color: #C9D1D9">   snr </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.exp(snr_db </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   scale </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> noise_power </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> speech_power</span></span>\n<span class="line"><span style="color: #C9D1D9">   noisy_speeches.append((scale </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> speech </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> noise) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png" alt="Waveform and Spectrogram of Noise Audio Data created by TorchAudio"></p>\n<p>The above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB <code is:raw>snr</code> means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># background noise at certain levels</span></span>\n<span class="line"><span style="color: #C9D1D9">snr_db20, noisy_speech20 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_db10, noisy_speech10 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">snr_db3, noisy_speech3 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png" alt="20 and 10 dB SNR added background audio data waveforms and spectrograms">\n<em>Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio</em></p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png" alt="PyTorch generated waveform and spectrogram for 3 dB SNR background noise">\n<em>Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise</em></p>\n<h2 id="adding-room-reverberation">Adding Room Reverberation</h2>\n<p>So far we\u2019ve applied audio effects and background noise at different noise levels. Let\u2019s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.</p>\n<p>To add a room reverb, we\u2019re going to start by making a request for the audio from where it lives online using one of the functions we made above (<code is:raw>get_rir_sample</code>). We\u2019ll take a look at the waveform before we clip it to get the \u201Creverb\u201D of the sound, normalize it, and then flip the sound so that the reverb works correctly.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rir_raw, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_rir_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">print_stats(rir)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(rir, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png" alt="Reverb audio data waveform and spectrogram with PyTorch">\n<em>Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio</em></p>\n<p>Once we have the sound normalized and flipped, we\u2019re ready to use it to augment the existing audio. We will first use PyTorch to create a \u201Cpadding\u201D that uses the speech and the augmented sound. Then, we\u2019ll use PyTorch to apply the sound with a 1 dimensional convolution.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">speech_ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.pad(speech, (rir.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">augmented </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.conv1d(speech_[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">], rir[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">])[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">play_audio(speech, sample_rate)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_specgram(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">play_audio(augmented, sample_rate)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png" alt="Waveform and spectrogram for original and reverb\u2019d sound with PyTorch TorchAudio">\n<em>Above: Visualizations for audio with reverb applied by TorchAudio</em></p>\n<p>From the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.</p>\n<h2 id="advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</h2>\n<p>We briefly mentioned how to resample data before using the <code is:raw>pydub</code> and the <code is:raw>sklearn</code> libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we\u2019ll cover how to resample data using low-pass, rolloff, and window filters.</p>\n<p>As we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is <code is:raw>get_sine_sweep</code> which is what we\u2019ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> IPython.display </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Audio, display</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">201</span></span>\n<span class="line"><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_LOWPASS_FILTER_WIDTH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_ROLLOFF</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.99</span></span>\n<span class="line"><span style="color: #79C0FF">DEFAULT_RESAMPLING_METHOD</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_log_freq</span><span style="color: #C9D1D9">(sample_rate, max_sweep_rate, offset):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #A5D6FF">   offset is used to avoid negative infinity `log(offset + x)`.</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #A5D6FF">   &quot;&quot;&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">   start, stop </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.log(offset), math.log(offset </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torch.exp(torch.linspace(start, stop, sample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">torch.double)) </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> offset</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_inverse_log_freq</span><span style="color: #C9D1D9">(freq, sample_rate, offset):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Find the time where the given frequency is given by _get_log_freq&quot;&quot;&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">   half </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> (math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> half </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset))</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_freq_ticks</span><span style="color: #C9D1D9">(sample_rate, offset, f_max):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Given the original sample rate used for generating the sweep,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># find the x-axis value where the log-scale major frequency values fall in</span></span>\n<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [], []</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> exp </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">           f </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">**</span><span style="color: #C9D1D9"> exp</span></span>\n<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">               t </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">               time.append(t)</span></span>\n<span class="line"><span style="color: #C9D1D9">               freq.append(f)</span></span>\n<span class="line"><span style="color: #C9D1D9">   t_max </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f_max, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   time.append(t_max)</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq.append(f_max)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> time, freq</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sine_sweep</span><span style="color: #C9D1D9">(sample_rate, offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   max_sweep_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_log_freq(sample_rate, max_sweep_rate, offset)</span></span>\n<span class="line"><span style="color: #C9D1D9">   delta </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> math.pi </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"><span style="color: #C9D1D9">   cummulative </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.cumsum(delta, </span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   signal </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.sin(cummulative).unsqueeze(</span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> signal</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_sweep</span><span style="color: #C9D1D9">(</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform,</span></span>\n<span class="line"><span style="color: #C9D1D9">   sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   title,</span></span>\n<span class="line"><span style="color: #C9D1D9">   max_sweep_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   x_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"><span style="color: #C9D1D9">   y_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_freq_ticks(max_sweep_rate, offset, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq_x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">else</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq]</span></span>\n<span class="line"><span style="color: #C9D1D9">   freq_y </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> y_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.specgram(waveform[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].numpy(), </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.xticks(time, freq_x)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.yticks(freq_y, freq_y)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.set_xlabel(</span><span style="color: #A5D6FF">&quot;Original Signal Frequency (Hz, log scale)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.set_ylabel(</span><span style="color: #A5D6FF">&quot;Waveform Frequency (Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.xaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axis.yaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">title</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> (sample rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p>I put the two <code is:raw>torchaudio</code> imports here to clarify that these are the <code is:raw>T</code> and <code is:raw>F</code> letters we\u2019ll be using to pull functions from (as opposed to true and false!). We\u2019ll declare a sample rate and a resample rate, it doesn\u2019t really matter what these are, feel free to change these as it suits you.</p>\n<p>The first thing we\u2019ll do is create a waveform using the <code is:raw>get_sine_sweep</code> function. Then, we\u2019ll do a resampling without passing any parameters. Next, we\u2019ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we\u2019ll need the functional <code is:raw>torchaudio</code> package.</p>\n<p>Technically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio\u2019s default is 6 so our first and second resampling are the same. Larger values here result in \u201Csharper\u201D noise.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>\n<span class="line"><span style="color: #C9D1D9">resample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">32000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sine_sweep(sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;basic resampling&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">resampler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Resample(sample_rate, resample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">waveform.dtype)</span></span>\n<span class="line"><span style="color: #C9D1D9">resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> resampler(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Resampled Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;lowpass resampling&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">lp6_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">6</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=6&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">lp128_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">128</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=128&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png" alt="Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio">\n<em>Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio</em></p>\n<p>Filters are not the only thing we can use for resampling. In the example code below, we\u2019ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we\u2019ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;using a window to resample&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">hann_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Hann Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">kaiser_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;kaiser_window&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Kaiser Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;user rollof to determine window&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.99</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.99&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.8&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png" alt="Resampling Audio Data with Windows and Rolloff filters">\n<em>Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio</em></p>\n<h2 id="audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</h2>\n<p>So far we\u2019ve taken a look at how to use <code is:raw>torchaudio</code> in many ways to manipulate our audio data. Now let\u2019s take a look at how to do feature extraction with <code is:raw>torchaudio</code>. As we have in the two sections above, we\u2019ll start by setting up.</p>\n<p>Our setup functions will include functions to fetch the data as well as visualize it like the \u201Ceffects\u201D section above. We also add some functions for doing Mel scale buckets. We will use <a href="https://en.wikipedia.org/wiki/Mel_scale">Mel scale</a> buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> librosa</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>\n<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>\n<span class="line"><span style="color: #C9D1D9">       (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">   ]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>\n<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>\n<span class="line"><span style="color: #C9D1D9">       effects.extend(</span></span>\n<span class="line"><span style="color: #C9D1D9">           [</span></span>\n<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>\n<span class="line"><span style="color: #C9D1D9">           ]</span></span>\n<span class="line"><span style="color: #C9D1D9">       )</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_spectrogram</span><span style="color: #C9D1D9">(spec, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;freq_bin&quot;</span><span style="color: #C9D1D9">, aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">, xmax</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Spectrogram (db)&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(ylabel)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;frame&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   im </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> axs.imshow(librosa.power_to_db(spec), </span><span style="color: #FFA657">origin</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lower&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">aspect)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xmax:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axs.set_xlim((</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, xmax))</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig.colorbar(im, </span><span style="color: #FFA657">ax</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">axs)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>\n<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>\n<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>\n<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_mel_fbank</span><span style="color: #C9D1D9">(fbank, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>\n<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Filter bank&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.imshow(fbank, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(</span><span style="color: #A5D6FF">&quot;frequency bin&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;mel bin&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p>The first thing we\u2019re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.</p>\n<p>We\u2019ll define some constants before we create our spectrogram and reverse it. First, we want to define <code is:raw>n_fft</code>, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we\u2019ll call <code is:raw>torchaudio</code> to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we\u2019ll use the <code is:raw>GriffinLim</code> function from <code is:raw>torchaudio</code> with the same parameters we used above to turn the waveform into a spectrogram.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># plot spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">n_fft </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">win_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span></span>\n<span class="line"><span style="color: #C9D1D9">hop_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">512</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># create spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">torch.random.manual_seed(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">spec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Spectrogram(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">)(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(spec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;torchaudio spec&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># reverse spectrogram to waveform with griffinlim</span></span>\n<span class="line"><span style="color: #C9D1D9">griffin_lim </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.GriffinLim(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> griffin_lim(spec)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Reconstructed&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png" alt="Waveform to Spectrogram and back with PyTorch">\n<em>Above: Creating and reversing a spectrogram in PyTorch</em></p>\n<p>Let\u2019s take a look at one of the more interesting things we can do with spectral features, <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">mel-frequency cepstrum</a>. The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we\u2019ll define a number of mel filterbanks (256), and a new sample rate to play with.</p>\n<p>The first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we\u2019ll use that to get the mel spectrogram. Now, we\u2019re ready to get the coefficients. First we need to define how many coefficients we want, then we\u2019ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>\n<span class="line"><span style="color: #8B949E"># mel scale waveforms</span></span>\n<span class="line"><span style="color: #8B949E"># mel scale bins</span></span>\n<span class="line"><span style="color: #C9D1D9">n_mels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6000</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mel_filters </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.melscale_fbanks(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(n_fft </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_min</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_max</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_mel_fbank(mel_filters, </span><span style="color: #A5D6FF">&quot;Mel Filter Bank - torchaudio&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>\n<span class="line"><span style="color: #C9D1D9">mel_spectrogram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MelSpectrogram(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">center</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">pad_mode</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;reflect&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">power</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">onesided</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">mel_scale</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">melspec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mel_spectrogram(waveform)</span></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(melspec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;MelSpectrogram - torchaudio&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mel freq&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">n_mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mfcc_transform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MFCC(</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mfcc</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mfcc,</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">melkwargs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">{</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_fft&quot;</span><span style="color: #C9D1D9">: n_fft,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_mels&quot;</span><span style="color: #C9D1D9">: n_mels,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;hop_length&quot;</span><span style="color: #C9D1D9">: hop_length,</span></span>\n<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;mel_scale&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">   },</span></span>\n<span class="line"><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mfcc_transform(waveform)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">plot_spectrogram(mfcc[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">])</span></span></code></pre>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png" alt="Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio">\n<em>Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio</em></p>\n<h2 id="in-summary">In Summary</h2>\n<p>In this epic post, we covered the basics of how to use the <code is:raw>torchaudio</code> library from PyTorch. We saw that we can use <code is:raw>torchaudio</code> to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.</p>\n<p>TorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio\u2019s <code is:raw>functional</code> and <code is:raw>transform</code> libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.</p>\n<p>Finally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/pytorch-intro-with-torchaudio/index.md", "https://blog.deepgram.com/", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>PyTorch is one of the leading machine learning frameworks in Python. Recently, PyTorch released an updated version of their framework for working with audio data, <a href="https://github.com/pytorch/audio">TorchAudio</a>. TorchAudio supports more than just using audio data for machine learning. It also supports the data transformations, augmentations, and feature extractions needed to use audio data for your machine learning models.</p>
<p>In this post, we’ll cover:</p>
<ul>
<li><a href="#setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</a></li>
<li><a href="#adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</a></li>
<li><a href="#using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</a></li>
<li><a href="#adding-background-noise">Adding Background Noise</a></li>
<li><a href="#adding-room-reverberation">Adding Room Reverberation</a></li>
<li><a href="#advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</a></li>
<li><a href="#audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</a></li>
<li><a href="#in-summary">In Summary</a></li>
</ul>
<h2 id="setting-up-pytorch-torchaudio-for-audio-data-augmentation">Setting up PyTorch TorchAudio for Audio Data Augmentation</h2>
<p>At the time of writing, <code>torchaudio</code> is on version <code>0.11.0</code> and only works with Python versions 3.6 to 3.9. For this example, we’ll be using Python 3.9. We’ll also need to install some libraries before we dive in. The first libraries we’ll need are <code>torch</code> and <code>torchaudio</code> from PyTorch. We’ll be using <code>matplotlib</code> to plot our visual representations, <code>requests</code> to get the data, and <code>librosa</code> to do some more visual manipulations for spectrograms.</p>
<p>To get started we’ll pip install all of these into a new virtual environment. <a href="https://blog.deepgram.com/python-virtual-environments/">To start a virtual environment</a> run <code>python3 -m venv &lt;new environment name&gt;</code>. Then run <code>pip install torch torchaudio matplotlib requests librosa</code> and let <code>pip</code> install all the libraries necessary for this tutorial.</p>
<h2 id="adding-effects-for-audio-data-augmentation-with-pytorch-torchaudio">Adding Effects for Audio Data Augmentation with PyTorch TorchAudio</h2>
<p>Recently, we covered the basics of <a href="https://blog.deepgram.com/best-python-audio-manipulation-tools/">how to manipulate audio data in Python</a>. In this section we’re going to cover the basics of how to pass sound effect options to TorchAudio. Then, we’ll go into specifics about how to add background noise at different sound levels and how to add room reverb.</p>
<p>Before we get into that, we have to set some stuff up. This section of code is entirely auxiliary code that you can <a href="#using-sound-effects-in-torchaudio">skip</a>. It would be good to understand this code if you’d like to continue testing on the provided data.</p>
<p>In the code block below, we first import all the libraries we need. Then, we define the URLs where the audio data is stored and the local paths we’ll store the audio at. Next, we fetch the data and define some helper functions.</p>
<p>For this example, we’ll define functions to get a noise, speech, and reverb sample. We will also define functions to plot the waveform, spectrogram, and <code>numpy</code> representations of the sounds that we are working with.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav&quot;</span></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;steam.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;rir.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;bg.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [(</span><span style="color: #79C0FF">SAMPLE_WAV_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_RIR_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">           (</span><span style="color: #79C0FF">SAMPLE_NOISE_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">),]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>
<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">,</span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>
<span class="line"><span style="color: #C9D1D9">       effects.extend([</span></span>
<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>
<span class="line"><span style="color: #C9D1D9">           [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">       ])</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>
<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>
<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>
<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>
<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">print_stats</span><span style="color: #C9D1D9">(waveform, sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, src</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> src:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Source: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">src</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;-&quot;</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> sample_rate:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Sample Rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Dtype:&quot;</span><span style="color: #C9D1D9">, waveform.dtype)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Max:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.max().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Min:     </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.min().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Mean:    </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.mean().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot; - Std Dev: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">waveform.std().item()</span><span style="color: #FF7B72">:6.3f</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(waveform)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>
<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>
<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>
<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>
<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_rir_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, processed</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   rir_raw, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_RIR_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> processed:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir_raw, sample_rate</span></span>
<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>
<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> rir, sample_rate</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_noise_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_NOISE_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span></code></pre>
<h2 id="using-sound-effects-in-torchaudio">Using Sound Effects in Torchaudio</h2>
<p>Now that we’ve set everything up, let’s take a look at how to use PyTorch’s <code>torchaudio</code> library to add sound effects. We’re going to pass a list of list of strings (<code>List[List[Str]])</code> object to the <code>sox_effects.apply_effects_tensor</code> function from <code>torchaudio</code>.</p>
<p>Each of the internal lists in our list of lists contains a set of strings defining an effect. The first string in the sequence indicates the effect and the next entries indicate the parameters around how to apply that effect. In the example below we show how to add a lowpass filter, augment the speed, and add some reverb. For a full list of sound effect options available, check out the <a href="http://sox.sourceforge.net/sox.html">sox documentation</a>. Note: this function returns two return values, the waveform and the new sample rate.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># Load the data</span></span>
<span class="line"><span style="color: #C9D1D9">waveform1, sample_rate1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># Define effects</span></span>
<span class="line"><span style="color: #C9D1D9">effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>
<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-1&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;300&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># apply single-pole lowpass filter</span></span>
<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;speed&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;0.8&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># reduce the speed</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># This only changes sample rate, so it is necessary to</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># add \`rate\` effect with original sample rate after this.</span></span>
<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate1</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>
<span class="line"><span style="color: #C9D1D9">   [</span><span style="color: #A5D6FF">&quot;reverb&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;-w&quot;</span><span style="color: #C9D1D9">],  </span><span style="color: #8B949E"># Reverbration gives some dramatic feeling</span></span>
<span class="line"><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #8B949E"># Apply effects</span></span>
<span class="line"><span style="color: #C9D1D9">waveform2, sample_rate2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)</span></span>
<span class="line"><span style="color: #C9D1D9">print_stats(waveform1, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate1, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">print_stats(waveform2, </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate2, </span><span style="color: #FFA657">src</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform1, sample_rate1, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">0.1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.2</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(waveform2, sample_rate2, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Effects Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">xlim</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3.04</span><span style="color: #C9D1D9">))</span></span></code></pre>
<p>The printout from plotting the waveforms and spectrograms are below. Notice that adding the reverb necessitates a multichannel waveform to produce that effect. You can see the difference in the waveform and spectrogram from the effects. Lowering the speed lengthened the sound. Adding a filter compresses some of the sound (visible in the spectrogram). Finally, the reverb adds noise we can see reflected mainly in the “skinnier” or quieter sections of the waveform.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655980723/blog/2022/06/pytorch-intro-with-torchaudio/1.png" alt="Waveform and Spectrogram of Original and Augmented Audio Data">
<em>Above: Original Waveform and Spectrogram + Added Effects from TorchAudio</em></p>
<h2 id="adding-background-noise">Adding Background Noise</h2>
<p>Now that we know how to add effects to audio using <code>torchaudio</code>, let’s dive into some more specific use cases. If your model needs to be able to detect audio even when there’s background noise, it’s a good idea to add some background noise to your training data.</p>
<p>In the example below, we will start by declaring a sample rate (8000 is a pretty typical rate). Next, we’ll call our helper functions to get the speech and background noise and reshape the noise. After that, we’ll use the <code>norm</code> function to normalize both the speech and the text to the <a href="https://pytorch.org/docs/stable/generated/torch.norm.html">second order</a>. Next, we’ll define a list of decibels that we want to play the background noise at over the speech and create a “background noise” version at each level.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>
<span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">noise, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_noise_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">noise </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise[:, : speech.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">speech_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> speech.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">noise_power </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> noise.norm(</span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">snr_dbs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">20</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">noisy_speeches </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> snr_db </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> snr_dbs:</span></span>
<span class="line"><span style="color: #C9D1D9">   snr </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.exp(snr_db </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   scale </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> noise_power </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> speech_power</span></span>
<span class="line"><span style="color: #C9D1D9">   noisy_speeches.append((scale </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> speech </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> noise) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(noise, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Background noise&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/2.png" alt="Waveform and Spectrogram of Noise Audio Data created by TorchAudio"></p>
<p>The above pictures show the waveform and the spectrogram of the background noise. We have already created all the noise speech audio data clips in the code above. The code below prints all of them out so we can see what the data looks like at different levels of audio. Note that the 20dB <code>snr</code> means that the signal (speech) to noise (background noise) ratio is at 20 dB, not that the noise is being played at 20 db.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># background noise at certain levels</span></span>
<span class="line"><span style="color: #C9D1D9">snr_db20, noisy_speech20 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech20, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db20</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">snr_db10, noisy_speech10 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech10, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db10</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">snr_db3, noisy_speech3 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> snr_dbs[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">], noisy_speeches[</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(noisy_speech3, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;SNR: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">snr_db3</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> [dB]&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/3.png" alt="20 and 10 dB SNR added background audio data waveforms and spectrograms">
<em>Above: 20 and 10 dB SNR added background noise visualizations via PyTorch TorchAudio</em></p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/4.png" alt="PyTorch generated waveform and spectrogram for 3 dB SNR background noise">
<em>Above: 3 dB signal to noise ratio waveform and spectrogram for added background noise</em></p>
<h2 id="adding-room-reverberation">Adding Room Reverberation</h2>
<p>So far we’ve applied audio effects and background noise at different noise levels. Let’s also take a look at how to add a reverb. Adding reverb to an audio clip gives the impression that the audio has been recorded in an echo-y room. You can do this to make it seem like a presentation you gave to your computer was actually given to an audience in a theater.</p>
<p>To add a room reverb, we’re going to start by making a request for the audio from where it lives online using one of the functions we made above (<code>get_rir_sample</code>). We’ll take a look at the waveform before we clip it to get the “reverb” of the sound, normalize it, and then flip the sound so that the reverb works correctly.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">8000</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">rir_raw, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_rir_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir_raw[:, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.01</span><span style="color: #C9D1D9">) : </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1.3</span><span style="color: #C9D1D9">)]</span></span>
<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> rir </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> torch.norm(rir, </span><span style="color: #FFA657">p</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">rir </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.flip(rir, [</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">])</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">print_stats(rir)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(rir, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(rir_raw, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Room Impulse Response (raw)&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/5.png" alt="Reverb audio data waveform and spectrogram with PyTorch">
<em>Above: Original and augmented reverb sound visualizations from PyTorch TorchAudio</em></p>
<p>Once we have the sound normalized and flipped, we’re ready to use it to augment the existing audio. We will first use PyTorch to create a “padding” that uses the speech and the augmented sound. Then, we’ll use PyTorch to apply the sound with a 1 dimensional convolution.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">speech, _ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample(</span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">speech_ </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.pad(speech, (rir.shape[</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">] </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">augmented </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.nn.functional.conv1d(speech_[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">], rir[</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">...</span><span style="color: #C9D1D9">])[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(speech, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">play_audio(speech, sample_rate)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_specgram(augmented, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;RIR Applied&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">play_audio(augmented, sample_rate)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/6.png" alt="Waveform and spectrogram for original and reverb’d sound with PyTorch TorchAudio">
<em>Above: Visualizations for audio with reverb applied by TorchAudio</em></p>
<p>From the printout above we can see that adding the room reverb adds echo like sounds to the waveform. We can also see that the spectrogram is less defined than it would be for a crisp, next-to-the-mic sound.</p>
<h2 id="advanced-resampling-of-audio-data-with-torchaudio">Advanced Resampling of Audio Data with TorchAudio</h2>
<p>We briefly mentioned how to resample data before using the <code>pydub</code> and the <code>sklearn</code> libraries. TorchAudio also lets you easily resample audio data using multiple methods. In this section, we’ll cover how to resample data using low-pass, rolloff, and window filters.</p>
<p>As we have done above, we need to set up a bunch of helper functions before we get into actually resampling the data. Many of these setup functions serve the same functions as the ones above. The one here to pay attention to is <code>get_sine_sweep</code> which is what we’ll be using instead of an existing audio file. All the other functions like getting ticks and reverse log frequencies are for plotting the data.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> math</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> IPython.display </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Audio, display</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">201</span></span>
<span class="line"><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>
<span class="line"><span style="color: #79C0FF">DEFAULT_LOWPASS_FILTER_WIDTH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6</span></span>
<span class="line"><span style="color: #79C0FF">DEFAULT_ROLLOFF</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0.99</span></span>
<span class="line"><span style="color: #79C0FF">DEFAULT_RESAMPLING_METHOD</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_log_freq</span><span style="color: #C9D1D9">(sample_rate, max_sweep_rate, offset):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #A5D6FF">   offset is used to avoid negative infinity \`log(offset + x)\`.</span></span>
<span class="line"></span>
<span class="line"><span style="color: #A5D6FF">   &quot;&quot;&quot;</span></span>
<span class="line"><span style="color: #C9D1D9">   start, stop </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> math.log(offset), math.log(offset </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torch.exp(torch.linspace(start, stop, sample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">torch.double)) </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> offset</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_inverse_log_freq</span><span style="color: #C9D1D9">(freq, sample_rate, offset):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #A5D6FF">&quot;&quot;&quot;Find the time where the given frequency is given by _get_log_freq&quot;&quot;&quot;</span></span>
<span class="line"><span style="color: #C9D1D9">   half </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> (math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> math.log(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> half </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> offset))</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_freq_ticks</span><span style="color: #C9D1D9">(sample_rate, offset, f_max):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># Given the original sample rate used for generating the sweep,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #8B949E"># find the x-axis value where the log-scale major frequency values fall in</span></span>
<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [], []</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> exp </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">           f </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> v </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">**</span><span style="color: #C9D1D9"> exp</span></span>
<span class="line"><span style="color: #C9D1D9">           </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">               t </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>
<span class="line"><span style="color: #C9D1D9">               time.append(t)</span></span>
<span class="line"><span style="color: #C9D1D9">               freq.append(f)</span></span>
<span class="line"><span style="color: #C9D1D9">   t_max </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_inverse_log_freq(f_max, sample_rate, offset) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>
<span class="line"><span style="color: #C9D1D9">   time.append(t_max)</span></span>
<span class="line"><span style="color: #C9D1D9">   freq.append(f_max)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> time, freq</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_sine_sweep</span><span style="color: #C9D1D9">(sample_rate, offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   max_sweep_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_rate</span></span>
<span class="line"><span style="color: #C9D1D9">   freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_log_freq(sample_rate, max_sweep_rate, offset)</span></span>
<span class="line"><span style="color: #C9D1D9">   delta </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> math.pi </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>
<span class="line"><span style="color: #C9D1D9">   cummulative </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.cumsum(delta, </span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   signal </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.sin(cummulative).unsqueeze(</span><span style="color: #FFA657">dim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> signal</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_sweep</span><span style="color: #C9D1D9">(</span></span>
<span class="line"><span style="color: #C9D1D9">   waveform,</span></span>
<span class="line"><span style="color: #C9D1D9">   sample_rate,</span></span>
<span class="line"><span style="color: #C9D1D9">   title,</span></span>
<span class="line"><span style="color: #C9D1D9">   max_sweep_rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">SWEEP_MAX_SAMPLE_RATE</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   offset</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">DEFAULT_OFFSET</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   x_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">500</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>
<span class="line"><span style="color: #C9D1D9">   y_ticks </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">5000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">10000</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">20000</span><span style="color: #C9D1D9">, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   time, freq </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> _get_freq_ticks(max_sweep_rate, offset, sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   freq_x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> x_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> max_sweep_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">else</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq]</span></span>
<span class="line"><span style="color: #C9D1D9">   freq_y </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [f </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> freq </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&gt;=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> y_ticks </span><span style="color: #FF7B72">and</span><span style="color: #C9D1D9"> f </span><span style="color: #FF7B72">&lt;=</span><span style="color: #C9D1D9"> sample_rate </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   figure, axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axis.specgram(waveform[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">].numpy(), </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.xticks(time, freq_x)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.yticks(freq_y, freq_y)</span></span>
<span class="line"><span style="color: #C9D1D9">   axis.set_xlabel(</span><span style="color: #A5D6FF">&quot;Original Signal Frequency (Hz, log scale)&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axis.set_ylabel(</span><span style="color: #A5D6FF">&quot;Waveform Frequency (Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axis.xaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axis.yaxis.grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">alpha</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.67</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   figure.suptitle(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">title</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> (sample rate: </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">sample_rate</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF"> Hz)&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_specgram</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Spectrogram&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>
<span class="line"><span style="color: #C9D1D9">       axes[c].specgram(waveform[c], </span><span style="color: #FFA657">Fs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>
<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p>I put the two <code>torchaudio</code> imports here to clarify that these are the <code>T</code> and <code>F</code> letters we’ll be using to pull functions from (as opposed to true and false!). We’ll declare a sample rate and a resample rate, it doesn’t really matter what these are, feel free to change these as it suits you.</p>
<p>The first thing we’ll do is create a waveform using the <code>get_sine_sweep</code> function. Then, we’ll do a resampling without passing any parameters. Next, we’ll take a look at what the sweeps look like when we use a low pass filter width parameter. For this, we’ll need the functional <code>torchaudio</code> package.</p>
<p>Technically, there are infinite frequencies, so a low pass filter cuts off sound below a certain frequency. The low pass filter width determines the window size of this filter. Torchaudio’s default is 6 so our first and second resampling are the same. Larger values here result in “sharper” noise.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>
<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">48000</span></span>
<span class="line"><span style="color: #C9D1D9">resample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">32000</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_sine_sweep(sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;basic resampling&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">resampler </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Resample(sample_rate, resample_rate, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">waveform.dtype)</span></span>
<span class="line"><span style="color: #C9D1D9">resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> resampler(waveform)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Resampled Waveform&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;lowpass resampling&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">lp6_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">6</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=6&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">lp128_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">lowpass_filter_width</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">128</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lowpass_filter_width=128&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/7.png" alt="Basic and Low-Pass Filter Spectrograms from PyTorch TorchAudio">
<em>Above: Basic and Low Pass Filter Example Spectrogram from TorchAudio</em></p>
<p>Filters are not the only thing we can use for resampling. In the example code below, we’ll be using both the default Hann window and the Kaiser window. Both windows serve as ways to automatically filter. Using rolloff for resampling achieves the same goals. In our examples, we’ll take a rolloff of 0.99 and 0.8. A rolloff represents what proportion of the audio will be attenuated.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;using a window to resample&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">hann_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;sinc_interpolation&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Hann Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">kaiser_window_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">resampling_method</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;kaiser_window&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Kaiser Window Default&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;user rollof to determine window&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.99</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.99&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">rolloff_resampled_waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.resample(waveform, sample_rate, resample_rate, </span><span style="color: #FFA657">rolloff</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_sweep(resampled_waveform, resample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;rolloff=0.8&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982112/blog/2022/06/pytorch-intro-with-torchaudio/8.png" alt="Resampling Audio Data with Windows and Rolloff filters">
<em>Above: Windowed and Rolloff parameter resampling visualizations from TorchAudio</em></p>
<h2 id="audio-feature-extraction-with-pytorch-torchaudio">Audio Feature Extraction with PyTorch TorchAudio</h2>
<p>So far we’ve taken a look at how to use <code>torchaudio</code> in many ways to manipulate our audio data. Now let’s take a look at how to do feature extraction with <code>torchaudio</code>. As we have in the two sections above, we’ll start by setting up.</p>
<p>Our setup functions will include functions to fetch the data as well as visualize it like the “effects” section above. We also add some functions for doing Mel scale buckets. We will use <a href="https://en.wikipedia.org/wiki/Mel_scale">Mel scale</a> buckets to make Mel-frequency cepstral coefficients (MFCC), these coefficients represent audio timbre.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torch</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.functional </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> F</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> torchaudio.transforms </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> T</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> librosa</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> matplotlib.pyplot </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> plt</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> requests</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;_assets&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav&quot;</span><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># noqa: E501</span></span>
<span class="line"><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> os.path.join(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;speech.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">os.makedirs(</span><span style="color: #79C0FF">_SAMPLE_DIR</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">exist_ok</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_fetch_data</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">   uri </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [</span></span>
<span class="line"><span style="color: #C9D1D9">       (</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_URL</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">   ]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> url, path </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> uri:</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(path, </span><span style="color: #A5D6FF">&quot;wb&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> file_:</span></span>
<span class="line"><span style="color: #C9D1D9">           file_.write(requests.get(url).content)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">_fetch_data()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">_get_sample</span><span style="color: #C9D1D9">(path, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   effects </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [[</span><span style="color: #A5D6FF">&quot;remix&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;1&quot;</span><span style="color: #C9D1D9">]]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> resample:</span></span>
<span class="line"><span style="color: #C9D1D9">       effects.extend(</span></span>
<span class="line"><span style="color: #C9D1D9">           [</span></span>
<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;lowpass&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>
<span class="line"><span style="color: #C9D1D9">               [</span><span style="color: #A5D6FF">&quot;rate&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">resample</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">],</span></span>
<span class="line"><span style="color: #C9D1D9">           ]</span></span>
<span class="line"><span style="color: #C9D1D9">       )</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> torchaudio.sox_effects.apply_effects_file(path, </span><span style="color: #FFA657">effects</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">effects)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">get_speech_sample</span><span style="color: #C9D1D9">(</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">, resample</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> _get_sample(</span><span style="color: #79C0FF">SAMPLE_WAV_SPEECH_PATH</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">resample</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">resample)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_spectrogram</span><span style="color: #C9D1D9">(spec, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;freq_bin&quot;</span><span style="color: #C9D1D9">, aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">, xmax</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Spectrogram (db)&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(ylabel)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;frame&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   im </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> axs.imshow(librosa.power_to_db(spec), </span><span style="color: #FFA657">origin</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;lower&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">aspect)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xmax:</span></span>
<span class="line"><span style="color: #C9D1D9">       axs.set_xlim((</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, xmax))</span></span>
<span class="line"><span style="color: #C9D1D9">   fig.colorbar(im, </span><span style="color: #FFA657">ax</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">axs)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_waveform</span><span style="color: #C9D1D9">(waveform, sample_rate, title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Waveform&quot;</span><span style="color: #C9D1D9">, xlim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">, ylim</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.numpy()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   num_channels, num_frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> waveform.shape</span></span>
<span class="line"><span style="color: #C9D1D9">   time_axis </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> torch.arange(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, num_frames) </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> sample_rate</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">   figure, axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(num_channels, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">==</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">       axes </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> [axes]</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> c </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(num_channels):</span></span>
<span class="line"><span style="color: #C9D1D9">       axes[c].plot(time_axis, waveform[c], </span><span style="color: #FFA657">linewidth</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       axes[c].grid(</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> num_channels </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylabel(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Channel </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">c</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> xlim:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_xlim(xlim)</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> ylim:</span></span>
<span class="line"><span style="color: #C9D1D9">           axes[c].set_ylim(ylim)</span></span>
<span class="line"><span style="color: #C9D1D9">   figure.suptitle(title)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">plot_mel_fbank</span><span style="color: #C9D1D9">(fbank, title</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">None</span><span style="color: #C9D1D9">):</span></span>
<span class="line"><span style="color: #C9D1D9">   fig, axs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> plt.subplots(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.set_title(title </span><span style="color: #FF7B72">or</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;Filter bank&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.imshow(fbank, </span><span style="color: #FFA657">aspect</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;auto&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.set_ylabel(</span><span style="color: #A5D6FF">&quot;frequency bin&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   axs.set_xlabel(</span><span style="color: #A5D6FF">&quot;mel bin&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">   plt.show(</span><span style="color: #FFA657">block</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p>The first thing we’re going to do here is plot the spectrogram and reverse it. The waveform to spectrogram and then back again. Why is converting a waveform to a spectrogram useful for feature extraction? This representation is helpful for extracting spectral features like frequency, timbre, density, rolloff, and more.</p>
<p>We’ll define some constants before we create our spectrogram and reverse it. First, we want to define <code>n_fft</code>, the size of the fast fourier transform, then the window length (the size of the window) and the hop length (the distance between short-time fourier transforms). Then, we’ll call <code>torchaudio</code> to transform our waveform into a spectrogram. To turn a spectrogram back into a waveform, we’ll use the <code>GriffinLim</code> function from <code>torchaudio</code> with the same parameters we used above to turn the waveform into a spectrogram.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># plot spectrogram</span></span>
<span class="line"><span style="color: #C9D1D9">waveform, sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> get_speech_sample()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">n_fft </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>
<span class="line"><span style="color: #C9D1D9">win_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">None</span></span>
<span class="line"><span style="color: #C9D1D9">hop_length </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">512</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># create spectrogram</span></span>
<span class="line"><span style="color: #C9D1D9">torch.random.manual_seed(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Original&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">spec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.Spectrogram(</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>
<span class="line"><span style="color: #C9D1D9">)(waveform)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_spectrogram(spec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;torchaudio spec&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># reverse spectrogram to waveform with griffinlim</span></span>
<span class="line"><span style="color: #C9D1D9">griffin_lim </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.GriffinLim(</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>
<span class="line"><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">waveform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> griffin_lim(spec)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_waveform(waveform, sample_rate, </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;Reconstructed&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982113/blog/2022/06/pytorch-intro-with-torchaudio/9.png" alt="Waveform to Spectrogram and back with PyTorch">
<em>Above: Creating and reversing a spectrogram in PyTorch</em></p>
<p>Let’s take a look at one of the more interesting things we can do with spectral features, <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">mel-frequency cepstrum</a>. The mel-frequency ceptrsal coefficients (MFCC) represent the timbre of the audio. Before we get started getting these feature coefficients, we’ll define a number of mel filterbanks (256), and a new sample rate to play with.</p>
<p>The first thing we need for MFCC is getting the mel filterbanks. Once we get mel filter banks, we’ll use that to get the mel spectrogram. Now, we’re ready to get the coefficients. First we need to define how many coefficients we want, then we’ll use the mel filterbanks and the mel spectrogram to create an MFCC diagram. This is what our mel spectrogram looks like when reduced to the number of coefficients we specified above.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>
<span class="line"><span style="color: #8B949E"># mel scale waveforms</span></span>
<span class="line"><span style="color: #8B949E"># mel scale bins</span></span>
<span class="line"><span style="color: #C9D1D9">n_mels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>
<span class="line"><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">6000</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">mel_filters </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> F.melscale_fbanks(</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(n_fft </span><span style="color: #FF7B72">//</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_min</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.0</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">f_max</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate </span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_mel_fbank(mel_filters, </span><span style="color: #A5D6FF">&quot;Mel Filter Bank - torchaudio&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># mel spectrogram</span></span>
<span class="line"><span style="color: #C9D1D9">mel_spectrogram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MelSpectrogram(</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_fft</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_fft,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">win_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">win_length,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">hop_length</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">hop_length,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">center</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">pad_mode</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;reflect&quot;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">power</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">2.0</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">norm</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;slaney&quot;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">onesided</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mels</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mels,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">mel_scale</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">melspec </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mel_spectrogram(waveform)</span></span>
<span class="line"><span style="color: #C9D1D9">plot_spectrogram(melspec[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">], </span><span style="color: #FFA657">title</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;MelSpectrogram - torchaudio&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">ylabel</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mel freq&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">n_mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">256</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">mfcc_transform </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> T.MFCC(</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">sample_rate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">sample_rate,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">n_mfcc</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">n_mfcc,</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FFA657">melkwargs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">{</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_fft&quot;</span><span style="color: #C9D1D9">: n_fft,</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;n_mels&quot;</span><span style="color: #C9D1D9">: n_mels,</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;hop_length&quot;</span><span style="color: #C9D1D9">: hop_length,</span></span>
<span class="line"><span style="color: #C9D1D9">       </span><span style="color: #A5D6FF">&quot;mel_scale&quot;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&quot;htk&quot;</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">   },</span></span>
<span class="line"><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">mfcc </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> mfcc_transform(waveform)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">plot_spectrogram(mfcc[</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">])</span></span></code></pre>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1655982114/blog/2022/06/pytorch-intro-with-torchaudio/10.png" alt="Mel-scale buckets and mel-frequency cepstrum coefficient plots from TorchAudio">
<em>Above: MFCC Feature Extraction of Audio Data with PyTorch TorchAudio</em></p>
<h2 id="in-summary">In Summary</h2>
<p>In this epic post, we covered the basics of how to use the <code>torchaudio</code> library from PyTorch. We saw that we can use <code>torchaudio</code> to do detailed and sophisticated audio manipulation. The specific examples we went over are adding sound effects, background noise, and room reverb.</p>
<p>TorchAudio also provides other audio manipulation methods as well, such as advanced resampling. In our resampling examples, we showed how to use multiple functions and parameters from TorchAudio’s <code>functional</code> and <code>transform</code> libraries to resample with different filters. We used low-pass filters, roll off filters, and window filters.</p>
<p>Finally, we covered how to use TorchAudio for feature extraction. We showed how to create a spectrogram to get spectral features, reverse that spectrogram with the Griffin-Lim formula, and how to create and use mel-scale bins to get mel-frequency cepstral coefficients (MFCC) features.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/pytorch-intro-with-torchaudio/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
