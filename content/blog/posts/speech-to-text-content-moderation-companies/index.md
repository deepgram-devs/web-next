---
title: "How Speech-to-Text Supports Content Moderation Companies"
description: "Many content moderation companies specialize in assessing text—but with automatic speech recognition, they can also look at audio and video."
date: 2022-08-24
cover: 
authors:
  - chris-doty
category: speech-trends
tags:
  - voice-strategy
seo:
  title: "How Speech-to-Text Supports Content Moderation Companies"
  description: "Many content moderation companies specialize in assessing text—but with automatic speech recognition, they can also look at audio and video."
shorturls:
  share: https://dpgr.am/10cd3e5
  twitter: https://dpgr.am/fee8ffa
  linkedin: https://dpgr.am/f9e4ea2
  reddit: https://dpgr.am/787b78f
  facebook: https://dpgr.am/008c4f0
og:
  image: 
---

Content moderation companies and departments work hard to keep offensive language out of video games, off platforms like forums, out of ad campaigns, and more. Most content moderation looks specifically at text, meaning that videos and audio chats can slip past the moderation efforts that a company might have in place-or else be extremely expensive, hiring multiple people to review this kind of content. That's where content moderation with speech-to-text comes in-by converting speech to text, the same processes that apply to written content can be applied to spoken content, providing additional options for moderation. To get started, let's look at what content moderation is and how it typically works, before we dive into some of the benefits of content moderation and how AI-powered automatic speech recognition solutions like Deepgram can help.

## What is Content Moderation?

Content Moderation refers to the process of monitoring user-generated content online and ensuring that it complies with any site rules and relevant laws. For example, companies like [Spectrum Labs](https://www.spectrumlabsai.com/) use artificial intelligence to identify problematic content like sexually charged messages, hate speech, radicalization, bullying, scams, grooming, and more. Moderation is used in a variety of different contexts, from social media sites to advertising platforms to video games. Any company that needs to ensure that the content that's being created and shared via its service has a need for some kind of content moderation. That moderation can come in a few different forms, including:

*   **Pre-moderation:** All content is reviewed before it's allowed to go live.
*   **Post-moderation:** Content is allowed to go live, but is still reviewed after being posted.
*   **Reactive moderation:** Content is only reviewed when it's flagged by other users as potentially problematic.
*   **Distributed moderation:** Content is upvoted or downvoted based on user feedback, and shown or hidden based on that voting, rather than the decision of moderators.

Additionally, moderation can happen in several different ways. In the most basic forms, humans review content to make sure that it complies with any relevant guidelines. But this process can be time consuming and tedious-and, in some cases, simply not possible with the amount of content that gets created. That's where automatic moderation comes in. Automatic moderation occurs without a human intervening, and can be as simple as removing content that contains words from a pre-specified list, or as complex as training a neural network for AI content moderation. Automatic moderation is especially relevant when we talk about automatic speech recognition for media monitoring, because, as mentioned above, once the audio has been turned into text, the same rules and filters can be applied to it as would have been applied to written content. But before we get to the benefits of content moderation and how STT can help, let's explore some of the most common use cases for content moderation.

## Top 5 Use Cases for Content Moderation

Content moderation is used for a variety of different use cases across different industries, some of which might surprise you-let's take a look at the top five use cases for content moderation.

### 1\. Gaming

Online gaming communities aren't often known as friendliest of places. With content moderation, game companies can work towards creating friendlier, more welcoming communities.

### 2\. Forums and Social Media

Sites that rely on user-generated content-from forums like Reddit to social media like Facebook-rely on content moderation to review what's posted, ensuring it follows site guidelines.

### 3\. Advertising

Advertising platforms have a vested interest in making sure that any ad served through their platform complies with their guidelines and any relevant laws. Content moderation reviews user-created ads to make sure that they're all above board.

### 4\. Ecommerce

Content moderation can serve a number of purposes for ecommerce platforms, from making sure that illegal or prohibited items aren't listed and sold to making sure that customer product reviews aren't offensive or spam.

### 5\. Health and Finance

Although they might not be the first things that come to mind when you think of content moderation, the health care and finance industries can make use of content moderation technologies. With lots of personal identifiable information (PII) and the need for HIPAA compliance, content moderation companies like [Private AI](https://www.private-ai.com/) can help to clean and process data to remove identifying information before the data is used for other purposes.

<whitepaperpromo whitepaper="latest"></whitepaperpromo>



## Benefits of Content Moderation

There are a number of benefits that come from using content moderation for your company. Here are a few of the biggest impacts that content moderation can have.

### Protect Your Brand...

Whether it's on a social media platform, in a video game, or on an ad, using content moderation ensures that what users experience is what they expect. For example, if a company says that they support the LBGTQ+ community, but you regularly find bigotted language used on their site, you're unlikely to believe them. Content moderation can help ensure that the face a company presents to the world reflects their values and beliefs.

### ... and Your Users

Content moderation also helps protect your brand by creating inclusive communities, spaces where everyone can feel safe. By monitoring what's posted by users and flagging or removing offensive or hateful content so that all users feel welcome.

### Better Understand Your Customers

Although you might think of content moderation as simply removing public-facing content, the process of analyzing everything posted can give you insights into your users. It can help you understand how they're feeling and what they're posting about (whether that content ultimately ends up being removed or not), giving you new insight into how to interact with them, what they're looking for, and even how they're feeling (see the section "Sentiment Analysis" below).

### Avoid Legal Troubles

Depending on what you're moderating, it's possible that users could be posting content that doesn't just run afoul of your own guidelines, but also of relevant local laws or others who hold copyrights to the content being posted. Content moderation efforts allow you to catch this content so that you aren't exposing yourself to possible legal action.

## How Speech-to-Text Supports Content Moderation Companies

Whenever you're choosing a speech-to-text solution, you want to make sure that it supports your specific needs. If you're interested in content moderation using STT, that means you need something that works quickly, returning transcripts in real time if you want to do pre-moderation or any kind of content evaluation before something is posted or is live. That's because [AI-powered automatic speech recognition](https://blog.deepgram.com/deep-learning-speech-recognition/) is faster than the alternatives, enabling real-time monitoring and removal of content that violates your guidelines. While many companies today rely on post-moderation or reactive moderation-especially for audio and video-with real-time STT, these media can also be pre-moderated. Let's take a look at some of the specific ways that AI-powered STT solutions like Deepgram can support content moderation companies and departments.

### Unlocks New Moderation Channels

A lot of automatic moderation today happens based on text, with other options used for audio and video. But with an AI-powered STT solution that can turn speech into text in real time, you can use the same automated process you employ for text, opening new industries and potential customers. For example, [Modulate's](https://www.modulate.ai/) [TodMox](https://www.modulate.ai/tox-mod) product is a full-coverage voice moderation solution-something that it simply isn't possible to build without advanced automatic speech recognition solutions.

### Cost Savings

As mentioned in the introduction, it's certainly possible to moderate video and audio with a person in the loop-but if your users are generating large amounts of content, it can become cost-prohibitive. With AI-powered speech-to-text, though, this content can be moderated quickly and easily-and more cheaply.

### Sentiment Analysis

If you're only working with text, you can do some basic sentiment analysis to see what the tone of user-generated content is-positive or negative. But with the addition of audio streams, you can [add emotion recognition](https://blog.deepgram.com/sentiment-analysis-emotion-regulation-difference/) to the mix, getting even more insight into how customers are feeling than would be possible from pure text or human moderators.

## Wrapping Up

Now that you've had a chance to consider some of the most common use cases and benefits of content moderation, as well as the ways that AI-powered STT solutions can help, why not give Deepgram a try? You can [sign up for a free trial and get $150 in free credits](https://console.deepgram.com/signup). Or, [reach out to our team](https://deepgram.com/contact-us/) and we're happy to talk through what you're building and how we can help you succeed.
